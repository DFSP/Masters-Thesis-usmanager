
. Descoberta e comunicaçao entre microserviços

A adoção de técnicas de desenvolvimento de software baseada em microserviços pode melhorar significamente a qualidade da entrega de software. Não só devido à rapidez de desenvolvimento, como também à agilidade associada ao uso de microserviços para compor aplicações. 
Mas, o facto dos microserviços poderem estar a ser executados num grande número de locais diferentes, e em constante mudança, torna a descoberta de microserviços e a necessidade de comunicação e coordenação entre os mesmos num problema complexo, contribuindo para que uma aplicação relativamente complexa, tenha uma complexidade operacional ainda maior quando composta por microserviços.

Para auxiliar na descoberta e comunicação entre microserviços, e assim mitigar a complexidade operacional de aplicações composta por microserviços, surgiram soluções como: o Service Registry {subcapitulo ...} {citação https://microservices.io/patterns/service-registry.html} usado no trabalho realizado anteriormente {citação dissertação}, o API Gateway {subcapitulo ...} {citação ...}, e o mais recente, Service Mesh {subcapitulo ...} {citação 08705911}.
São analisadas e comparadas as três soluções, de modo a perceber quais parecem mais promissoras para serem incluidas no sistema, considerando as caracteristicas da solução e as necessidades do nosso sistema.


	- Service Registry

    O Service Registry permite armazenar a informação sobre os serviços, as suas instâncias e localizações. O registo de uma instância pode ser feita de duas formas, por auto registo {citação https://microservices.io/patterns/self-registration.html}, ou por registo de terceiros {citação https://microservices.io/patterns/3rd-party-registration.html}. Ambos os tipos de registos são suportados no sistema atual.
    Sempre que seja necessário comunicar com um serviço, é consultado o Service Registry para se ter conhecimento de uma instância desse serviço, e respetiva localização. Após esse passo, a instância pode ser contactada diretamente.
    O sistema atual usa o Netflix Eureka {https://github.com/Netflix/eureka} como Service Registry. Entre outras soluções práticas estão o etcd {https://github.com/etcd-io/etcd}, o Consul {https://www.consul.io/}, e o Apache Zookeeper {https://zookeeper.apache.org/}.
    Uma das principais desvantagens desta solução é a necessidade de incluir parte do código para suportar a descoberta das instâncias na lógica da própria aplicação.

								{ fig serviceRegistry da dissertação andre carrusca?}


	- API Gateway

	Os microserviços têm APIs individuais, normalmente mais especificas ao serviço que disponibilizam. Isto quer dizer que, um cliente ao aceder às funcionalidades de uma aplicação composta por microserviços, terá que potencialmente aceder à API de vários microserviços. 
	Os acessos à API individual de cada microserviço devem ser transparentes para o cliente, não só porque o número de instâncias dos microserviços e a sua localização pode mudar, mas também porque um microserviço pode até mesmo deixar de existir.
	A solução passa por implementar um API Gateway no sistema, que permite criar um ponto único de acesso, e assim evitar que o acesso à API individual de cada microserviços seja feita e gerida pelos clientes. 
	Para além de ser um ponto único de acesso, o API Gateway permite ainda expor uma API especifica a cada cliente, e incluir segurança ao verificar a autorização do cliente que faz o pedido.
	O API Gateway deve ser usado em conjunto com um Service Registry para descobrir as instâncias ativas do serviços.

					{ fig arquiteturaAPIGateway de https://microservices.io/patterns/apigateway.html?}


    - Service Mesh

    O Service Mesh é um conceito recente que descreve a comunicação entre serviços usando uma 
	camada de infraestrutura dedicada, responsável pela entrega confiável de pedidos através da topologia de serviços que compõem uma aplicação. Na prática, um Service Mesh é normalmente implementado como um conjunto de proxies leves que são lançados juntamente com o código da aplicação, mas sem que a aplicação tenha conhecimento. Desta forma, é possivel existir comunicação entre serviços sem ser necessário alterar o código da aplicação. 
	
									{ fig arquiteturaServiceMesh 08705911}

	A ilustração na {fig ...} permite facilmente perceber o conceito de Service Mesh. É possivel ver que cada proxy corresponde a um serviço, sendo responsável pelo controlo da comunicação entre os serviços.
	É também possivel ver uma separação lógica entre o plano de controlo e o plano de dados. Enquanto que o plano de controlo gere e configura os componentes do Service Mesh, o plano de dados é responsável por fornecer as funcionalidades que o Service Mesh garante, nomeadamente:

	1. Descoberta de serviços. Ao aceder a um registo com as instâncias ativas dos serviços.
	2. Balanceamento da carga. Ao usar o registo das instâncias ativas e a monitorização de trafego, é possivel haver um redirecionamento inteligente dos pedidos.
	3. Tolerança a falhas. Ao garantir o redirecionamento dos pedidos para uma instância ativa do serviço.
	4. Monitorização de trafego. Ao captar todo o trafego transmitido entre os serviços, conseguindo assim gerar relatórios de utilização e desempenho.
	5. Quebra de circuito. Ao impedir o acesso a um serviço sobrecarregado, e assim evitar sobrecarregar outros serviços ou partes da aplicação.
	6. Autenticação e controlo de acesso. Ao impor politicas de autenticação e acesso na comunicação entre serviços.

	Começam a existir várias soluções que colocam em prática o conceito de Service Mesh. Entre as mais desenvolvidas estão o Istio {subcapitulo...} {citação https://istio.io/} e o Linkerd {subcapitulo...} {citação https://linkerd.io/}.

		- Istio

		Istio é um Service Mesh que permite gerir uma arquitetura distribuida de microserviços, uniformizando a forma de unir, controlar, proteger, e monitorizar os microserviços. Está desenhado para ser independente da plataforma onde executa, suportando vários ambientes, como o Kubernetes {https://kubernetes.io/}, o Consul {https://www.consul.io/}, o Nomad {https://www.nomadproject.io/} ou máquinas virtuais individuais.

											{ fig arquiteturaIstio }

		É possivel ver a sua arquitetura na {fig arquiteturaIstio}.
		No plano de dados estão:
		- Um Conjunto de proxies, designado Envoy, cada um lançado juntamente a um microserviço, como sidecar.
		- E ainda o Mixer, que faz a ligação entre o plano de dados e o plano de controlo, tendo a função de impor controlo e politicas de acesso, bem como obter telemetria de todo o service mesh.
		No plano de controlo encontram-se três componentes que gerem e configuram o Envoy e o Mixer:
		- O Pilot, com capacidade para permitir descoberta de serviços por parte do Envoy, e gestão de trafego para possibilitar routing inteligente.
		- O Citadel, que permite definir regras de controlo e autenticação para controlar e limitar o acesso ao serviço mesh, ou a certos microserviços.
		- E o Galley é o componente que gere a validação da configuração, o processamento e a distribuição do sistema.

Istio control plane consists of four main services: Pilot, Mixer, Citadel, and the API server.
Istio’s API server (based on Kubernetes’ API server) provides key functions such as configuration management and Role-Based Access Control. The API server requires an etcd cluster as a persistent store.



You can also choose to prioritize your load balancing pools based on geographic location. Visit the operations guide for more information on the locality load balancing feature. https://istio.io/docs/ops/traffic-management/locality-load-balancing/




		O Istio suporta todas as funcionalidades descritas no final do {subcapitulo ...}, e, sendo um projeto open-source, com licença Apache 2.0 {footnote ...}, é possivel, caso necessário, adaptar as suas funcionalidades às necessidades do nosso sistema. No entanto, ainda é um projeto muito recente e em constante evolução, o que pode implicar que não esteja totalmente pronto para ser integrado no sistema.

https://istio.io/docs/setup/kubernetes/install/kubernetes/#deploy-your-application:
	When you deploy your application using kubectl apply, the Istio sidecar injector will automatically inject Envoy containers into your application pods if they are started in namespaces labeled with istio-injection=enabled:
	$ kubectl label namespace <namespace> istio-injection=enabled
	$ kubectl create -n <namespace> -f <your-app-spec>.yaml
	In namespaces without the istio-injection label, you can use istioctl kube-inject to manually inject Envoy containers in your application pods before deploying them:
	$ istioctl kube-inject -f <your-app-spec>.yaml | kubectl apply -f -

https://istio.io/docs/examples/bookinfo/: 
	To run the sample with Istio requires no changes to the application itself. Instead, we simply need to configure and run the services in an Istio-enabled environment, with Envoy sidecars injected along side each service.
All of the microservices will be packaged with an Envoy sidecar that intercepts incoming and outgoing calls for the services, providing the hooks needed to externally control, via the Istio control plane, routing, telemetry collection, and policy enforcement for the application as a whole.


		- Linkerd //TODO

		Conduit juntou-se ao linkerd na versão 2.0
		Linkerd is more stable in our hands-on experimental study and we believe it is production-ready. 

Considerando as caracteristicas, funcionalidades e limitações das três soluções: API Gateway, Service Registry e Service Mesh, concluiu-se que o melhor para incluir no nosso sistema seria o Service Mesh.
Não só devido às funcionalidades que garante, descritas no final do {subcapitulo ...}, mas também porque permite a descoberta e comunicação entre microserviços sem ser necessário modificar o código das aplicações.
Das duas soluções que colocam em prática o conceito de Service Mesh, descritas no {subcapitulo ...}, e após a análise das suas funcionalidades, caracteristicas e limitações, o Linkerd é aquela que garante uma estabilidade maior.

No futuro espera-se a integração de uma tecnologia que permita a interoperabilidade entre as diferentes soluções de Service Mesh, de modo a evitar a dependência a uma única implementação. Uma solução que está atualmente em desenvolvimento é a Service Mesh Interface (SMI) {https://cloudblogs.microsoft.com/opensource/2019/05/21/service-mesh-interface-smi-release/}, que define um conjunto de APIs comuns e portáveis.


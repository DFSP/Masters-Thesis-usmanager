[2020-07-29 01:02:36,720] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 01:02:36,727] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 01:02:36,740] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 01:02:36,767] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:02:37,105] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:02:37,106] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:37,106] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:37,106] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:37,106] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:37,107] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:02:37,291] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:02:37,291] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:37,291] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,172] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:02:38,172] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,172] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,173] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,174] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,175] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,176] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:02:38,177] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,177] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,177] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,177] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,178] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,179] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:02:38,180] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,180] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:02:38,180] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:02:38,181] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:02:38,181] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:02:38,181] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,181] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,181] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:02:38,191] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 01:02:38,193] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 01:02:38,197] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 01:02:38,241] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,241] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:02:38,242] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:02:38,242] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:02:38,242] INFO Kafka startTimeMs: 1595980958241 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:02:38,473] INFO Kafka cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 01:02:38,491] INFO Logging initialized @2059ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 01:02:38,543] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 01:02:38,543] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 01:02:38,549] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 01:02:38,571] INFO Started http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 01:02:38,572] INFO Started @2140ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 01:02:38,589] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:02:38,589] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 01:02:38,589] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:02:38,589] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 01:02:38,589] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:02:38,590] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 01:02:38,597] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:02:38,598] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:02:38,598] INFO Kafka startTimeMs: 1595980958597 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:02:38,690] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:02:38,692] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:02:38,697] INFO Kafka Connect standalone worker initialization took 1975ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 01:02:38,697] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 01:02:38,698] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 01:02:38,698] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 01:02:38,699] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 01:02:38,707] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 01:02:38,708] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 01:02:38,708] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 01:02:38,753] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 01:02:38,826] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 01:02:38,826] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 01:02:38,827] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 01:02:39,261] INFO Started o.e.j.s.ServletContextHandler@76304b46{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 01:02:39,262] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 01:02:39,262] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 01:02:39,282] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 01:02:39,288] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:02:39,288] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:02:39,289] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 01:02:39,292] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 01:02:39,293] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 01:02:39,294] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:02:39,294] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:02:39,295] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 01:02:39,296] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 01:02:39,298] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:02:39,298] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:02:39,299] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 01:02:39,299] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 01:02:39,299] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:02:39,299] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 01:02:39,299] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:02:39,299] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 01:02:39,300] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 01:02:39,303] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 01:02:39,303] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:02:39,303] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:02:39,310] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 01:02:39,343] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:02:39,343] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:02:39,343] INFO Kafka startTimeMs: 1595980959342 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:02:39,349] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 01:02:39,350] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): COMPONENT_TYPES (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 01:02:39,350] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 01:02:39,350] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker-db
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 01:02:39,355] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:02:39,356] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 01:02:39,372] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 01:02:39,373] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 01:02:39,374] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:02:39,380] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 01:02:39,381] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:02:39,384] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-671809c3-397d-4fa9-941c-2ff63740c961=Assignment(partitions=[COMPONENT_TYPES-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 01:02:39,387] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 01:02:39,390] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 01:02:39,397] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 01:02:39,406] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition COMPONENT_TYPES-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 01:02:39,450] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:02:39,577] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 01:02:39,605] INFO Checking Generic dialect for existence of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:548)
[2020-07-29 01:02:39,609] INFO Using Generic dialect TABLE "COMPONENT_TYPES" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:556)
[2020-07-29 01:02:39,611] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: null (INT64) type doesn't have a mapping to the SQL database column type (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: null (INT64) type doesn't have a mapping to the SQL database column type
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getSqlType(GenericDatabaseDialect.java:1818)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.writeColumnSpec(GenericDatabaseDialect.java:1734)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.lambda$writeColumnsSpec$33(GenericDatabaseDialect.java:1723)
	at io.confluent.connect.jdbc.util.ExpressionBuilder.append(ExpressionBuilder.java:558)
	at io.confluent.connect.jdbc.util.ExpressionBuilder$BasicListBuilder.of(ExpressionBuilder.java:597)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.writeColumnsSpec(GenericDatabaseDialect.java:1725)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.buildCreateTableStatement(GenericDatabaseDialect.java:1648)
	at io.confluent.connect.jdbc.sink.DbStructure.create(DbStructure.java:92)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:62)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:123)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 01:02:39,613] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: null (INT64) type doesn't have a mapping to the SQL database column type
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getSqlType(GenericDatabaseDialect.java:1818)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.writeColumnSpec(GenericDatabaseDialect.java:1734)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.lambda$writeColumnsSpec$33(GenericDatabaseDialect.java:1723)
	at io.confluent.connect.jdbc.util.ExpressionBuilder.append(ExpressionBuilder.java:558)
	at io.confluent.connect.jdbc.util.ExpressionBuilder$BasicListBuilder.of(ExpressionBuilder.java:597)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.writeColumnsSpec(GenericDatabaseDialect.java:1725)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.buildCreateTableStatement(GenericDatabaseDialect.java:1648)
	at io.confluent.connect.jdbc.sink.DbStructure.create(DbStructure.java:92)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:62)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:123)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 01:02:39,614] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 01:02:39,614] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 01:02:39,614] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:02:39,624] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 01:02:39,624] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-671809c3-397d-4fa9-941c-2ff63740c961 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 01:02:46,993] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 01:02:46,993] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 01:02:47,000] INFO Stopped http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 01:02:47,001] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 01:02:47,001] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 01:02:47,002] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 01:02:47,002] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 01:02:47,004] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 01:02:47,004] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 01:02:47,004] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 01:02:47,004] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 01:02:47,005] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 01:02:47,006] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 01:02:47,006] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 01:03:22,270] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 01:03:22,276] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 01:03:22,280] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 01:03:22,300] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:03:22,612] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:03:22,613] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:22,614] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:22,614] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:22,614] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:22,615] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:03:22,789] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:03:22,789] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:22,789] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,652] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:03:23,653] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,653] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,654] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,655] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,658] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,659] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,660] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:03:23,661] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,661] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,661] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,661] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,661] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,661] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,662] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,663] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,664] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,664] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,664] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,664] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:03:23,664] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,664] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:03:23,664] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:03:23,664] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:03:23,665] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:03:23,665] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,665] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,665] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:03:23,677] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 01:03:23,677] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 01:03:23,681] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 01:03:23,729] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,729] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,729] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,729] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,729] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,729] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,730] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:03:23,730] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:03:23,730] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:03:23,730] INFO Kafka startTimeMs: 1595981003730 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:03:23,953] INFO Kafka cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 01:03:23,969] INFO Logging initialized @1982ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 01:03:24,016] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 01:03:24,016] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 01:03:24,023] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 01:03:24,043] INFO Started http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 01:03:24,043] INFO Started @2057ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 01:03:24,060] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:03:24,060] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 01:03:24,061] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:03:24,061] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 01:03:24,061] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:03:24,061] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 01:03:24,070] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:03:24,070] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:03:24,070] INFO Kafka startTimeMs: 1595981004069 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:03:24,166] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:03:24,167] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:03:24,173] INFO Kafka Connect standalone worker initialization took 1901ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 01:03:24,173] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 01:03:24,174] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 01:03:24,174] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 01:03:24,175] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 01:03:24,182] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 01:03:24,182] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 01:03:24,182] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 01:03:24,221] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 01:03:24,295] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 01:03:24,295] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 01:03:24,296] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 01:03:24,748] INFO Started o.e.j.s.ServletContextHandler@76304b46{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 01:03:24,748] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 01:03:24,748] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 01:03:24,768] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 01:03:24,774] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:03:24,775] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:03:24,775] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 01:03:24,777] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 01:03:24,778] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 01:03:24,779] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:03:24,779] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:03:24,780] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 01:03:24,781] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 01:03:24,783] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:03:24,783] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:03:24,784] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 01:03:24,784] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 01:03:24,785] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:03:24,785] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 01:03:24,785] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:03:24,785] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 01:03:24,785] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 01:03:24,789] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 01:03:24,789] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:03:24,789] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:03:24,808] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 01:03:24,851] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:03:24,851] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:03:24,852] INFO Kafka startTimeMs: 1595981004851 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:03:24,861] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 01:03:24,861] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): COMPONENT_TYPES (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 01:03:24,862] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 01:03:24,862] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker-db
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 01:03:24,866] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:03:24,867] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 01:03:24,883] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 01:03:24,884] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 01:03:24,885] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:03:24,892] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 01:03:24,892] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:03:24,895] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-863ba052-084a-4183-a05c-c4c6850ce3a5=Assignment(partitions=[COMPONENT_TYPES-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 01:03:24,898] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 01:03:24,901] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 01:03:24,910] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 01:03:24,920] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition COMPONENT_TYPES-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 01:03:24,966] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:03:25,112] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 01:03:25,139] INFO Checking Generic dialect for existence of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:548)
[2020-07-29 01:03:25,144] INFO Using Generic dialect TABLE "COMPONENT_TYPES" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:556)
[2020-07-29 01:03:25,206] INFO Checking Generic dialect for type of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:818)
[2020-07-29 01:03:25,208] INFO Setting metadata for table "COMPONENT_TYPES" to Table{name='"COMPONENT_TYPES"', type=TABLE columns=[Column{'TYPE', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'ID', isPrimaryKey=true, allowsNull=false, sqlType=BIGINT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 01:03:25,220] WARN Write of 12 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1298)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:457)
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:427)
	at org.h2.message.DbException.get(DbException.java:205)
	at org.h2.message.DbException.get(DbException.java:181)
	at org.h2.mvstore.db.MVPrimaryIndex.add(MVPrimaryIndex.java:131)
	at org.h2.mvstore.db.MVTable.addRow(MVTable.java:546)
	at org.h2.command.dml.Insert.insertRows(Insert.java:180)
	at org.h2.command.dml.Insert.update(Insert.java:132)
	at org.h2.command.CommandContainer.update(CommandContainer.java:133)
	at org.h2.command.Command.executeUpdate(Command.java:267)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:200)
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1280)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
[2020-07-29 01:03:25,224] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:03:25,238] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:03:25,239] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 01:03:28,241] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:03:28,252] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 01:03:28,254] INFO Checking Generic dialect for existence of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:548)
[2020-07-29 01:03:28,255] INFO Using Generic dialect TABLE "COMPONENT_TYPES" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:556)
[2020-07-29 01:03:28,276] INFO Checking Generic dialect for type of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:818)
[2020-07-29 01:03:28,278] INFO Setting metadata for table "COMPONENT_TYPES" to Table{name='"COMPONENT_TYPES"', type=TABLE columns=[Column{'TYPE', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'ID', isPrimaryKey=true, allowsNull=false, sqlType=BIGINT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 01:03:28,281] WARN Write of 12 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1298)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:457)
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:427)
	at org.h2.message.DbException.get(DbException.java:205)
	at org.h2.message.DbException.get(DbException.java:181)
	at org.h2.mvstore.db.MVPrimaryIndex.add(MVPrimaryIndex.java:131)
	at org.h2.mvstore.db.MVTable.addRow(MVTable.java:546)
	at org.h2.command.dml.Insert.insertRows(Insert.java:180)
	at org.h2.command.dml.Insert.update(Insert.java:132)
	at org.h2.command.CommandContainer.update(CommandContainer.java:133)
	at org.h2.command.Command.executeUpdate(Command.java:267)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:200)
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1280)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
[2020-07-29 01:03:28,282] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:03:28,502] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:03:28,502] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 01:03:29,121] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 01:03:29,121] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 01:03:29,130] INFO Stopped http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 01:03:29,131] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 01:03:29,132] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 01:03:29,132] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 01:03:29,133] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 01:03:29,133] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 01:03:29,133] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 01:03:29,134] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-863ba052-084a-4183-a05c-c4c6850ce3a5 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 01:03:29,139] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 01:03:29,139] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 01:03:29,139] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 01:03:29,140] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 01:03:29,140] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 01:03:29,140] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 01:03:29,140] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 01:05:11,717] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 01:05:11,722] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 01:05:11,726] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 01:05:11,745] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:05:12,074] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:12,074] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:12,075] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:12,075] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:12,075] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:12,076] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:05:12,265] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:12,265] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:12,265] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,746] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:13,747] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,747] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,748] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,749] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,750] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,751] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:13,752] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,752] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,753] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,754] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,755] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:13,755] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,756] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:13,756] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:13,756] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:13,756] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:13,756] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,756] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,756] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:13,770] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 01:05:13,771] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 01:05:13,776] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 01:05:13,898] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,898] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,898] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,898] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,898] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,899] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,899] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:13,899] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:13,899] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:13,899] INFO Kafka startTimeMs: 1595981113899 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:14,694] INFO Kafka cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 01:05:14,808] INFO Logging initialized @3386ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 01:05:14,905] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 01:05:14,905] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 01:05:14,912] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 01:05:15,193] INFO Started http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 01:05:15,193] INFO Started @3771ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 01:05:15,214] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:15,215] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 01:05:15,215] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:15,215] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 01:05:15,215] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:15,215] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 01:05:15,226] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:15,226] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:15,226] INFO Kafka startTimeMs: 1595981115226 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:15,393] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:15,395] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:15,411] INFO Kafka Connect standalone worker initialization took 3694ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 01:05:15,412] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 01:05:15,413] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 01:05:15,414] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 01:05:15,415] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 01:05:15,425] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 01:05:15,426] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 01:05:15,426] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 01:05:15,468] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 01:05:15,534] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 01:05:15,534] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 01:05:15,535] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 01:05:16,315] INFO Started o.e.j.s.ServletContextHandler@76304b46{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 01:05:16,315] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 01:05:16,315] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 01:05:16,340] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master-db
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [COMPONENT_TYPES]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 01:05:16,765] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 01:05:16,772] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:05:16,773] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [ID]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = ID
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:16,773] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 01:05:16,775] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 01:05:16,776] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 01:05:16,776] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master-db
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [COMPONENT_TYPES]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 01:05:16,777] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:05:16,812] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 01:05:16,813] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 01:05:16,814] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 01:05:16,814] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [ID]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = ID
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:16,831] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 01:05:16,834] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:05:16,834] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [ID]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = ID
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:16,835] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 01:05:16,836] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 01:05:16,836] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:16,836] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 01:05:16,836] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:16,836] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 01:05:16,837] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 01:05:16,841] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 01:05:16,847] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 01:05:16,868] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:16,868] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:16,869] INFO Kafka startTimeMs: 1595981116868 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:16,876] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 01:05:16,877] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 01:05:16,878] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master-db
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [COMPONENT_TYPES]
	tables = ["MANAGER-MASTER-DB"."PUBLIC"."COMPONENT_TYPES"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 01:05:16,879] INFO Using JDBC dialect Generic (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 01:05:16,880] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:05:16,881] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 01:05:16,923] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 01:05:16,923] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 01:05:16,924] INFO Begin using SQL query: SELECT * FROM "MANAGER-MASTER-DB"."PUBLIC"."COMPONENT_TYPES" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 01:05:23,032] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 01:05:23,032] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 01:05:23,041] INFO Stopped http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 01:05:23,042] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 01:05:23,046] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 01:05:23,046] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 01:05:23,047] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 01:05:23,047] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 01:05:23,138] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 01:05:23,138] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:05:23,138] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 01:05:23,139] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 01:05:23,148] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 9 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 01:05:23,149] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 01:05:23,155] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 01:05:23,155] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 01:05:23,155] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 01:05:23,156] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:05:23,156] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 01:05:23,156] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 01:05:23,157] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 01:05:23,157] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 01:05:23,158] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 01:05:23,158] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 01:05:25,644] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 01:05:25,652] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 01:05:25,664] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 01:05:25,693] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:05:25,985] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:25,986] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:25,986] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:25,986] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:25,986] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:25,987] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 01:05:26,129] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:26,130] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,130] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,997] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 01:05:26,997] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,997] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,998] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:26,999] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,000] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,001] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,002] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 01:05:27,003] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,004] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,005] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,006] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,007] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,008] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,008] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,008] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:27,008] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,008] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:27,009] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:27,009] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:27,009] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 01:05:27,009] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,009] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,009] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 01:05:27,020] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 01:05:27,020] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 01:05:27,023] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 01:05:27,068] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,068] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,068] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,069] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,069] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,069] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,069] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 01:05:27,069] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:27,069] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:27,069] INFO Kafka startTimeMs: 1595981127069 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:27,297] INFO Kafka cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 01:05:27,314] INFO Logging initialized @2201ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 01:05:27,373] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 01:05:27,373] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 01:05:27,386] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 01:05:27,416] INFO Started http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 01:05:27,416] INFO Started @2303ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 01:05:27,432] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:27,432] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 01:05:27,432] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:27,432] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 01:05:27,433] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 01:05:27,433] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 01:05:27,441] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:27,442] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:27,442] INFO Kafka startTimeMs: 1595981127441 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:27,537] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:27,538] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:27,544] INFO Kafka Connect standalone worker initialization took 1897ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 01:05:27,544] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 01:05:27,545] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 01:05:27,545] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 01:05:27,546] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 01:05:27,552] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 01:05:27,552] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 01:05:27,552] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 01:05:27,588] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 01:05:27,657] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 01:05:27,658] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 01:05:27,659] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 01:05:28,057] INFO Started o.e.j.s.ServletContextHandler@76304b46{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 01:05:28,058] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 01:05:28,058] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 01:05:28,106] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 01:05:28,112] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:05:28,112] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:28,113] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 01:05:28,116] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 01:05:28,116] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 01:05:28,117] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:05:28,117] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:28,118] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 01:05:28,119] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 01:05:28,120] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 01:05:28,121] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:28,122] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 01:05:28,122] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 01:05:28,122] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:28,122] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 01:05:28,122] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 01:05:28,123] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 01:05:28,123] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 01:05:28,126] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 01:05:28,126] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 01:05:28,126] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [COMPONENT_TYPES]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 01:05:28,133] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 01:05:28,166] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 01:05:28,166] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 01:05:28,166] INFO Kafka startTimeMs: 1595981128166 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 01:05:28,173] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 01:05:28,173] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): COMPONENT_TYPES (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 01:05:28,173] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 01:05:28,174] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:h2:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker-db
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 01:05:28,178] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:05:28,178] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 01:05:28,195] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: 2jhXLHcvSSW-JUC7oenkXg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 01:05:28,196] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 01:05:28,197] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:05:28,204] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 01:05:28,204] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 01:05:28,208] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 5: {connector-consumer-jdbc-sink-0-4c8fec6a-3030-4367-86f4-9ba603b7a586=Assignment(partitions=[COMPONENT_TYPES-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 01:05:28,211] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 01:05:28,214] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 01:05:28,221] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 01:05:28,229] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition COMPONENT_TYPES-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 01:05:28,277] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:05:28,432] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 01:05:28,456] INFO Checking Generic dialect for existence of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:548)
[2020-07-29 01:05:28,460] INFO Using Generic dialect TABLE "COMPONENT_TYPES" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:556)
[2020-07-29 01:05:28,502] INFO Checking Generic dialect for type of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:818)
[2020-07-29 01:05:28,504] INFO Setting metadata for table "COMPONENT_TYPES" to Table{name='"COMPONENT_TYPES"', type=TABLE columns=[Column{'TYPE', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'ID', isPrimaryKey=true, allowsNull=false, sqlType=BIGINT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 01:05:28,513] WARN Write of 18 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1298)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:457)
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:427)
	at org.h2.message.DbException.get(DbException.java:205)
	at org.h2.message.DbException.get(DbException.java:181)
	at org.h2.mvstore.db.MVPrimaryIndex.add(MVPrimaryIndex.java:131)
	at org.h2.mvstore.db.MVTable.addRow(MVTable.java:546)
	at org.h2.command.dml.Insert.insertRows(Insert.java:180)
	at org.h2.command.dml.Insert.update(Insert.java:132)
	at org.h2.command.CommandContainer.update(CommandContainer.java:133)
	at org.h2.command.Command.executeUpdate(Command.java:267)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:200)
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1280)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
[2020-07-29 01:05:28,518] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:05:28,536] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:05:28,536] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 01:05:31,538] INFO Attempting to open connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 01:05:31,546] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 01:05:31,563] INFO Checking Generic dialect for existence of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:548)
[2020-07-29 01:05:31,566] INFO Using Generic dialect TABLE "COMPONENT_TYPES" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:556)
[2020-07-29 01:05:31,608] INFO Checking Generic dialect for type of TABLE "COMPONENT_TYPES" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:818)
[2020-07-29 01:05:31,609] INFO Setting metadata for table "COMPONENT_TYPES" to Table{name='"COMPONENT_TYPES"', type=TABLE columns=[Column{'TYPE', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'ID', isPrimaryKey=true, allowsNull=false, sqlType=BIGINT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 01:05:31,614] WARN Write of 18 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1298)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:457)
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:427)
	at org.h2.message.DbException.get(DbException.java:205)
	at org.h2.message.DbException.get(DbException.java:181)
	at org.h2.mvstore.db.MVPrimaryIndex.add(MVPrimaryIndex.java:131)
	at org.h2.mvstore.db.MVTable.addRow(MVTable.java:546)
	at org.h2.command.dml.Insert.insertRows(Insert.java:180)
	at org.h2.command.dml.Insert.update(Insert.java:132)
	at org.h2.command.CommandContainer.update(CommandContainer.java:133)
	at org.h2.command.Command.executeUpdate(Command.java:267)
	at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:200)
	at org.h2.jdbc.JdbcPreparedStatement.executeBatch(JdbcPreparedStatement.java:1280)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
[2020-07-29 01:05:31,616] INFO Closing connection #1 to Generic (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 01:05:31,827] INFO Initializing writer using SQL dialect: GenericDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 01:05:31,828] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.h2.jdbc.JdbcBatchUpdateException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [65, 'CONTAINER']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [64, 'SERVICE']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]
org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Unique index or primary key violation: "PRIMARY KEY ON PUBLIC.COMPONENT_TYPES(ID) [63, 'HOST']"; SQL statement:
INSERT INTO "COMPONENT_TYPES"("ID","TYPE") VALUES(?,?) [23505-199]

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 01:05:32,538] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 01:05:32,538] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 01:05:32,545] INFO Stopped http_8083@1c98290c{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 01:05:32,545] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 01:05:32,546] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 01:05:32,547] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 01:05:32,547] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 01:05:32,548] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 01:05:32,548] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions COMPONENT_TYPES-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 01:05:32,549] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-4c8fec6a-3030-4367-86f4-9ba603b7a586 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 01:05:32,558] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 01:05:32,559] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 01:05:32,559] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 01:05:32,559] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 01:05:32,560] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 01:05:32,560] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 01:05:32,560] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)

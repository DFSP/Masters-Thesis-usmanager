[2020-07-29 17:00:03,973] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:03,976] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:03,977] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:00:13,978] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:13,978] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:13,980] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:00:23,980] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:23,980] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:23,982] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:00:33,983] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:33,983] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:33,985] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:00:43,985] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:43,985] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:43,987] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:00:53,988] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:00:53,988] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:00:53,989] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:03,990] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:03,990] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:03,991] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:13,991] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:13,992] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:13,993] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:23,994] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:23,994] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:23,996] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:33,996] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:33,997] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:33,998] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:43,999] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:43,999] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:44,001] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:01:54,001] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:01:54,001] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:01:54,003] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:04,003] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:04,003] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:04,004] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:14,005] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:14,005] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:14,006] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:24,007] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:24,007] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:24,009] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:34,009] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:34,010] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:34,011] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:44,012] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:44,012] INFO WorkerSourceTask{id=jdbc-source-0} flushing 1 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:44,016] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:02:54,017] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:02:54,018] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:02:54,019] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:04,020] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:04,021] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:04,022] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:14,023] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:14,024] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:14,025] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:24,026] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:24,026] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:24,028] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:34,028] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:34,029] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:34,030] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:44,030] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:44,030] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:44,031] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:03:54,032] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:03:54,032] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:03:54,033] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:04,033] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:04,034] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:04,035] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:14,035] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:14,036] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:14,037] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:24,037] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:24,037] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:24,038] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:34,039] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:34,039] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:34,040] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:44,041] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:44,041] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:44,043] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:04:54,043] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:04:54,043] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:04:54,044] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:04,045] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:04,045] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:04,046] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:14,046] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:14,046] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:14,047] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:24,048] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:24,048] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:24,049] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:34,050] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:34,050] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:34,051] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:44,051] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:44,052] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:44,053] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:05:54,053] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:05:54,053] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:05:54,055] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:04,055] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:04,055] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:04,056] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:14,056] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:14,057] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:14,058] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:24,058] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:24,059] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:24,060] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:34,061] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:34,061] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:34,062] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:44,062] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:44,063] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:44,064] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:06:54,064] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:06:54,064] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:06:54,065] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:04,066] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:04,066] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:04,067] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:14,067] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:14,068] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:14,068] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:24,069] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:24,069] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:24,070] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:34,070] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:34,070] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:34,071] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:44,072] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:44,072] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:44,073] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:07:54,073] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:07:54,073] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:07:54,074] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:04,074] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:04,074] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:04,075] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:14,076] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:14,076] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:14,076] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:24,077] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:24,077] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:24,078] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:34,079] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:34,079] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:34,080] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:44,080] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:44,081] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:44,082] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:08:54,082] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:08:54,082] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:08:54,083] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:04,083] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:04,084] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:04,085] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:14,085] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:14,085] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:14,086] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:24,086] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:24,086] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:24,087] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:34,088] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:34,088] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:34,089] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:44,089] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:44,089] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:44,090] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:09:54,091] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:09:54,091] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:09:54,092] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:04,093] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:04,093] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:04,093] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:14,094] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:14,094] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:14,095] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:24,095] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:24,095] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:24,096] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:34,097] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:34,097] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:34,097] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:44,098] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:44,098] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:44,099] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:10:54,099] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:10:54,099] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:10:54,100] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:04,101] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:04,101] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:04,102] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:14,102] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:14,102] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:14,103] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:24,104] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:24,104] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:24,105] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:34,105] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:34,105] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:34,106] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:44,106] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:44,107] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:44,107] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:11:54,108] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:11:54,108] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:11:54,109] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:04,109] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:04,109] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:04,110] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:14,110] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:14,110] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:14,111] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:24,111] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:24,111] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:24,112] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:34,112] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:34,113] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:34,114] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:44,114] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:44,114] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:44,115] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:12:54,115] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:12:54,115] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:12:54,116] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:04,116] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:04,116] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:04,117] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:14,117] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:14,118] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:14,118] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:24,119] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:24,119] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:24,120] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:34,121] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:34,121] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:34,122] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:44,122] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:44,122] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:44,123] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:13:54,124] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:13:54,124] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:13:54,125] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:04,125] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:04,125] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:04,126] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:14,126] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:14,126] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:14,127] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:24,127] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:24,128] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:24,129] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:34,129] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:34,129] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:34,130] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:44,130] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:44,131] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:44,131] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:14:54,131] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:14:54,132] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:14:54,133] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:04,133] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:04,133] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:04,134] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:14,134] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:14,135] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:14,136] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:24,136] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:24,137] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:24,138] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:34,138] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:34,138] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:34,139] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:44,140] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:44,140] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:44,141] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:15:54,142] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:15:54,142] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:15:54,144] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:04,144] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:04,144] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:04,145] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:14,145] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:14,146] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:14,146] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:24,147] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:24,147] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:24,148] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:34,148] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:34,148] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:34,149] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:44,150] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:44,150] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:44,150] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:16:54,151] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:16:54,151] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:16:54,152] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:04,152] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:04,152] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:04,153] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:14,153] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:14,154] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:14,154] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:24,155] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:24,155] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:24,156] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:34,156] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:34,156] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:34,157] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:44,157] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:44,157] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:44,158] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:17:54,158] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:17:54,159] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:17:54,160] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:04,160] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:04,160] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:04,161] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:14,162] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:14,162] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:14,162] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:24,163] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:24,163] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:24,164] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:34,164] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:34,164] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:34,166] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:44,166] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:44,166] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:44,167] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:18:54,168] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:18:54,168] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:18:54,169] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:04,169] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:04,169] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:04,170] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:14,170] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:14,171] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:14,171] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:24,172] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:24,172] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:24,173] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:34,173] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:34,174] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:34,175] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:44,175] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:44,175] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:44,176] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:19:54,177] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:19:54,177] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:19:54,178] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:04,178] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:04,179] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:04,180] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:14,180] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:14,181] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:14,182] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:24,182] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:24,182] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:24,183] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:34,183] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:34,184] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:34,185] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:44,185] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:44,185] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:44,186] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:20:54,186] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:20:54,187] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:20:54,187] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:04,188] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:04,188] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:04,189] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:14,189] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:14,189] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:14,190] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:24,190] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:24,191] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:24,191] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:34,192] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:34,192] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:34,192] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:44,193] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:44,193] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:44,193] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:21:54,194] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:21:54,194] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:21:54,195] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:04,195] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:04,195] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:04,196] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:14,197] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:14,197] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:14,198] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:24,198] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:24,198] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:24,199] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:34,200] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:34,200] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:34,200] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:44,201] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:44,201] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:44,202] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:22:54,202] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:22:54,203] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:22:54,203] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:04,203] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:04,204] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:04,205] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:14,205] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:14,205] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:14,206] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:24,206] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:24,207] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:24,208] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:34,208] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:34,208] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:34,209] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:44,209] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:44,209] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:44,210] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:23:47,736] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:23:47,736] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:23:47,748] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:23:47,748] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:23:47,749] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:23:47,750] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:23:47,750] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:23:47,750] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:23:47,794] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:23:47,794] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:23:47,795] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:23:47,795] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:23:47,795] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:23:47,799] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:23:47,799] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:23:47,799] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:23:47,800] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:23:47,800] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:23:47,800] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:23:47,801] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:23:47,801] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:23:47,803] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:23:47,803] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:24:04,695] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:24:04,706] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:24:04,721] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:24:04,755] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:05,081] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:05,082] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,082] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,082] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,082] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,083] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,084] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:05,284] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:05,284] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,285] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:05,469] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:05,470] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:05,471] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,399] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:06,399] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,399] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,399] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,400] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,401] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,402] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,403] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:06,404] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,404] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,405] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,405] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,405] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,405] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,406] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,407] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,408] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,409] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,410] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,410] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:06,410] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,410] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:06,411] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:06,411] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:06,411] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:06,411] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,411] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,411] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:06,427] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:24:06,429] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:24:06,434] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:24:06,491] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,491] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,491] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,492] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,492] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,492] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:06,492] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:06,492] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:06,492] INFO Kafka startTimeMs: 1596039846492 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:06,729] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:24:06,748] INFO Logging initialized @2705ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:24:06,803] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:24:06,804] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:24:06,812] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:24:06,835] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:24:06,836] INFO Started @2793ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:24:06,854] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:06,855] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:24:06,855] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:06,855] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:24:06,855] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:06,856] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:24:06,866] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:06,867] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:06,867] INFO Kafka startTimeMs: 1596039846866 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:06,982] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:06,983] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:06,991] INFO Kafka Connect standalone worker initialization took 2295ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:24:06,992] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:24:06,993] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:24:06,993] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:24:06,994] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:24:07,001] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:24:07,002] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:24:07,002] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:24:07,042] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:24:07,109] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:24:07,110] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:24:07,111] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:24:07,604] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:24:07,604] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:24:07,604] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:24:07,632] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:07,727] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:07,732] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:07,733] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,733] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:07,736] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:07,737] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:24:07,737] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:24:07,738] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:07,740] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:24:07,741] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:07,742] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:24:07,743] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,747] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:07,749] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:07,750] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,751] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:07,752] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:07,752] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:07,753] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:07,753] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:07,753] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:07,753] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:07,758] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:24:07,766] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:24:07,788] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:07,788] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:07,788] INFO Kafka startTimeMs: 1596039847788 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:07,796] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:24:07,797] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:24:07,797] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:24:07,798] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:07,799] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:07,800] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:07,806] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:07,806] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:07,806] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,806] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:07,807] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:24:07,807] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:24:07,807] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:07,808] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:07,808] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:07,808] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:24:07,808] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,809] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:24:07,809] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:07,810] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:07,810] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,811] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:07,811] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:07,811] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:07,811] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:07,811] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:07,811] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:07,811] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:07,812] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:24:07,812] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:07,812] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:07,819] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:24:07,854] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:07,854] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:07,854] INFO Kafka startTimeMs: 1596039847854 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:07,858] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:07,859] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:24:07,860] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:24:07,860] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:24:07,862] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:24:07,863] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:24:07,871] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:07,872] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:24:07,873] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:07,883] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:24:07,883] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:07,888] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-5d727bf9-1a1a-4cd8-886b-a8687b8f68d5=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:24:07,893] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:24:07,896] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:24:07,905] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:24:07,912] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:24:07,973] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:07,974] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:24:07,977] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:24:07,980] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:24:07,980] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:24:07,980] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:24:07,980] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:07,981] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:24:07,981] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-5d727bf9-1a1a-4cd8-886b-a8687b8f68d5 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:24:10,647] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:24:10,647] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:24:10,653] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:24:10,653] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:24:10,654] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:24:10,655] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:24:10,655] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:24:10,657] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:24:10,657] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:24:10,657] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:24:10,658] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:24:10,669] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:24:10,669] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:10,669] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:24:10,670] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:24:10,674] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:24:10,674] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:24:10,676] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:24:10,676] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:24:10,676] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:24:10,677] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:10,677] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:24:10,677] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:24:10,678] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:24:10,678] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:24:10,679] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:24:10,679] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:24:36,786] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:24:36,792] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:24:36,797] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:24:36,821] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:37,125] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:37,126] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,126] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,127] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,127] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,127] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,128] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:37,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:37,339] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,340] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:37,485] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:37,485] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:37,486] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,531] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,532] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,533] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,534] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,535] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:38,536] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,536] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,536] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,537] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,537] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,537] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,537] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,537] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,538] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,539] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,540] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,541] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,541] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,541] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,541] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:38,541] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,542] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:38,542] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:38,542] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:38,543] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:38,543] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,543] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,543] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:38,556] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:24:38,557] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:24:38,562] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:24:38,615] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,615] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:38,616] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:38,616] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:38,616] INFO Kafka startTimeMs: 1596039878616 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:38,900] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:24:38,918] INFO Logging initialized @2436ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:24:38,970] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:24:38,971] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:24:38,979] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:24:39,006] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:24:39,007] INFO Started @2524ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:24:39,033] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:39,033] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:24:39,033] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:39,033] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:24:39,033] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:39,034] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:24:39,046] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:39,046] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:39,046] INFO Kafka startTimeMs: 1596039879046 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:39,175] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:39,176] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:39,185] INFO Kafka Connect standalone worker initialization took 2397ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:24:39,185] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:24:39,186] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:24:39,186] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:24:39,186] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:24:39,192] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:24:39,192] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:24:39,193] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:24:39,240] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:24:39,319] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:24:39,319] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:24:39,321] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:24:39,851] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:24:39,851] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:24:39,851] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:24:39,910] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:40,005] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:40,011] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:40,012] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,013] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:40,015] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:40,016] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:24:40,016] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:24:40,018] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:40,020] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:24:40,020] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:40,022] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:24:40,023] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,027] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:40,029] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:40,029] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,030] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:40,031] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:40,032] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:40,032] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:40,033] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:40,033] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:40,033] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:40,037] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:24:40,045] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:24:40,068] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:40,068] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:40,069] INFO Kafka startTimeMs: 1596039880068 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:40,076] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:24:40,076] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:24:40,076] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:40,076] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:24:40,077] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:40,077] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:40,082] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:40,083] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:40,083] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,083] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:40,084] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:40,084] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:40,085] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:40,085] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,085] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:24:40,086] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:24:40,086] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:24:40,086] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:40,086] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:24:40,087] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:40,087] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,088] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:40,088] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:40,088] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:40,089] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:40,089] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:40,089] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:40,089] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:40,092] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:24:40,093] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:40,093] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:40,099] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:24:40,131] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:40,131] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:40,131] INFO Kafka startTimeMs: 1596039880131 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:40,135] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:40,136] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:24:40,136] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:24:40,137] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:24:40,139] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:24:40,140] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:24:40,152] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:40,153] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:24:40,155] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:40,164] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:24:40,164] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:40,169] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-3ad30be2-b761-4899-848f-687fac2c11d5=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:24:40,172] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:24:40,175] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:24:40,186] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:24:40,197] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:24:40,261] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:40,262] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:24:40,266] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:24:40,268] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596037527195) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:24:40,269] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:24:40,269] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:24:40,269] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:40,269] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:24:40,270] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-3ad30be2-b761-4899-848f-687fac2c11d5 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:24:41,701] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:24:41,701] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:24:41,706] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:24:41,707] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:24:41,708] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:24:41,708] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:24:41,708] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:24:41,710] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:24:41,710] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:24:41,710] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:24:41,710] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:24:41,741] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:24:41,741] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:41,741] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:24:41,742] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:24:41,745] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:24:41,746] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:24:41,748] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:24:41,748] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:24:41,749] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:24:41,749] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:41,749] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:24:41,750] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:24:41,750] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:24:41,751] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:24:41,751] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:24:41,751] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:24:51,590] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:24:51,596] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:24:51,603] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:24:51,625] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:51,914] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:51,914] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:51,915] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:51,915] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:51,915] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:51,915] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:51,916] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:52,104] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:52,104] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:52,105] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:24:52,271] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:52,272] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:52,273] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,151] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:24:53,151] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,151] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,152] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,153] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,154] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,155] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:24:53,156] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,156] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,156] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,156] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,157] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,158] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,159] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,160] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,160] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,160] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:53,160] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,160] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:53,160] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:53,161] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:53,161] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:24:53,161] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,161] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,161] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:24:53,174] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:24:53,175] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:24:53,178] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:24:53,228] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,228] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,228] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,229] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,229] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,229] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,229] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:24:53,229] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:53,229] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:53,229] INFO Kafka startTimeMs: 1596039893229 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:53,478] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:24:53,496] INFO Logging initialized @2226ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:24:53,548] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:24:53,548] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:24:53,555] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:24:53,593] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:24:53,593] INFO Started @2323ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:24:53,612] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:53,612] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:24:53,612] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:53,613] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:24:53,613] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:24:53,613] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:24:53,626] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:53,626] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:53,626] INFO Kafka startTimeMs: 1596039893625 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:53,737] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:53,738] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:53,745] INFO Kafka Connect standalone worker initialization took 2154ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:24:53,746] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:24:53,746] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:24:53,747] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:24:53,747] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:24:53,753] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:24:53,753] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:24:53,754] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:24:53,796] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:24:53,864] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:24:53,864] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:24:53,865] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:24:54,341] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:24:54,341] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:24:54,341] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:24:54,360] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:54,450] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:54,456] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:54,457] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,457] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:54,461] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:54,462] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:24:54,463] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:24:54,463] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:54,465] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:24:54,465] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:54,466] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:24:54,466] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,472] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:54,474] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:54,474] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,476] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:54,477] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:54,479] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:54,479] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:54,480] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:54,480] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:54,480] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:54,484] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:24:54,489] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:24:54,512] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:54,512] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:54,512] INFO Kafka startTimeMs: 1596039894512 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:54,521] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:24:54,522] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:54,522] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:24:54,522] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:54,523] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:24:54,524] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:54,529] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:24:54,529] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:54,530] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,530] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:24:54,530] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:24:54,531] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:24:54,531] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:54,531] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,532] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:24:54,532] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:24:54,532] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:24:54,533] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:24:54,533] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:24:54,534] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:24:54,534] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,535] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:24:54,535] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:24:54,535] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:24:54,536] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:24:54,536] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:24:54,536] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:24:54,536] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:24:54,537] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:24:54,538] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:24:54,538] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:24:54,545] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:24:54,578] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:24:54,579] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:24:54,579] INFO Kafka startTimeMs: 1596039894578 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:24:54,583] WARN [Producer clientId=connector-producer-jdbc-source-0] Error while fetching metadata with correlation id 3 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:24:54,586] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:24:54,587] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:24:54,588] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:24:54,588] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:24:54,591] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:24:54,591] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:24:54,606] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 2 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:24:54,606] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:24:54,607] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:24:54,609] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:54,617] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:24:54,617] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:24:54,709] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-c9663a12-bcb3-4928-baf5-bc58be78a413=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:24:54,713] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:24:54,716] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:24:54,724] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:24:54,730] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:24:54,755] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:24:54,756] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:24:54,761] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:24:54,763] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:24:54,764] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:24:54,764] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:24:54,764] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:24:54,764] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:24:54,764] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-c9663a12-bcb3-4928-baf5-bc58be78a413 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:25:03,076] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:25:03,076] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:25:03,080] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:25:03,080] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:25:03,081] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:25:03,081] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:25:03,081] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:25:03,082] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:25:03,082] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:25:03,083] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:25:03,083] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:25:03,154] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:25:03,154] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:03,154] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:25:03,154] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:25:03,160] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:25:03,160] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:25:03,162] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:25:03,162] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:25:03,163] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:25:03,163] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:03,163] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:25:03,163] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:25:03,164] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:25:03,164] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:25:03,164] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:25:03,164] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:25:23,561] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:25:23,566] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:25:23,573] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:25:23,596] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:23,872] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:23,873] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:23,873] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:23,873] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:23,873] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:23,873] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:23,874] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:24,078] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:24,079] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:24,079] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:24,207] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:24,208] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:24,209] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,117] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:25,117] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,118] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,119] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,120] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,121] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,122] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,123] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,123] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,123] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:25,123] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,124] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,125] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,126] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,127] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:25,127] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,128] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:25,128] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:25,128] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:25,129] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:25,129] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,129] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,129] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:25,142] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:25:25,143] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:25:25,147] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:25:25,197] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,198] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:25,199] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:25,200] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:25,200] INFO Kafka startTimeMs: 1596039925198 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:25,446] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:25:25,467] INFO Logging initialized @2204ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:25:25,520] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:25:25,521] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:25:25,529] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:25:25,556] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:25:25,556] INFO Started @2293ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:25:25,584] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:25,584] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:25:25,585] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:25,585] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:25:25,585] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:25,586] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:25:25,596] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:25,596] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:25,596] INFO Kafka startTimeMs: 1596039925596 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:25,704] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:25,705] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:25,712] INFO Kafka Connect standalone worker initialization took 2150ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:25:25,712] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:25:25,713] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:25:25,713] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:25:25,713] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:25:25,720] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:25:25,720] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:25:25,720] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:25:25,761] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:25:25,833] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:25:25,833] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:25:25,835] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:25:26,269] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:25:26,269] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:25:26,269] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:25:26,312] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:26,410] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:26,416] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:26,417] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,417] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:25:26,420] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:25:26,421] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:25:26,421] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:25:26,422] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:26,424] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:25:26,424] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:25:26,425] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:25:26,425] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,431] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:25:26,433] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:26,434] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,435] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:25:26,435] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:25:26,436] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:25:26,437] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:25:26,437] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:26,437] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:25:26,437] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:25:26,442] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:25:26,447] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:25:26,469] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:26,469] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:26,469] INFO Kafka startTimeMs: 1596039926469 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:26,477] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:25:26,478] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:25:26,478] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:25:26,479] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:25:26,479] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:25:26,480] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:26,485] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:26,485] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:26,485] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,485] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:25:26,486] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:25:26,486] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:25:26,487] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:25:26,487] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,488] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:25:26,488] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:25:26,489] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:25:26,489] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:25:26,489] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:26,489] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,490] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:25:26,490] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:25:26,490] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:25:26,490] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:25:26,491] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:25:26,491] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:26,491] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:25:26,491] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:25:26,492] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:25:26,492] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:25:26,493] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:26,500] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:25:26,535] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:26,535] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:26,535] INFO Kafka startTimeMs: 1596039926535 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:26,540] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:25:26,542] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:25:26,543] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:25:26,543] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:25:26,545] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:25:26,546] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:25:26,554] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:25:26,555] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:25:26,557] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:25:26,566] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:25:26,566] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:25:26,570] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-2b79916c-b1dd-49d6-9edc-c51d7331cb2c=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:25:26,574] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:25:26,576] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:25:26,585] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:25:26,593] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:25:26,617] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:26,618] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:25:26,622] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema. (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:25:26,624] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Sink connector 'jdbc-sink' is configured with 'delete.enabled=false' and 'pk.mode=none' and therefore requires records with a non-null Struct value and non-null Struct schema, but found record at (topic='users',partition=0,offset=0,timestamp=1596039894691) with a HashMap value and null value schema.
	at io.confluent.connect.jdbc.sink.RecordValidator.lambda$requiresValue$2(RecordValidator.java:83)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:82)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:25:26,624] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:25:26,624] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:25:26,624] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:26,625] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:25:26,625] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-2b79916c-b1dd-49d6-9edc-c51d7331cb2c sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:25:28,855] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:25:28,856] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:25:28,861] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:25:28,862] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:25:28,863] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:25:28,863] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:25:28,863] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:25:28,864] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:25:28,864] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:25:28,865] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:25:28,865] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:25:28,944] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:25:28,944] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:28,945] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:25:28,945] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:25:28,950] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:25:28,950] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:25:28,953] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:25:28,953] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:25:28,953] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:25:28,954] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:28,954] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:25:28,954] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:25:28,955] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:25:28,956] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:25:28,956] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:25:28,956] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:25:40,575] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:25:40,582] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:25:40,587] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:25:40,611] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:40,930] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:40,931] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:40,931] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:40,932] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:40,932] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:40,932] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:40,933] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:41,139] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:41,140] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:41,140] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:25:41,276] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:41,276] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:41,279] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,231] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:25:42,232] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,232] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,232] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,232] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,232] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,233] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,234] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,235] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,236] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,237] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:25:42,238] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,239] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,239] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,240] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,241] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,242] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,243] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:42,243] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,244] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:42,244] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:42,244] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:42,245] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:25:42,245] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,245] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,245] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:25:42,257] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:25:42,258] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:25:42,261] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:25:42,313] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:25:42,314] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:42,314] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:42,315] INFO Kafka startTimeMs: 1596039942314 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:42,565] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:25:42,584] INFO Logging initialized @2324ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:25:42,639] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:25:42,640] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:25:42,649] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:25:42,680] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:25:42,680] INFO Started @2420ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:25:42,697] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:42,697] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:25:42,698] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:42,698] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:25:42,698] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:25:42,698] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:25:42,710] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:42,711] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:42,711] INFO Kafka startTimeMs: 1596039942710 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:42,835] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:42,837] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:42,844] INFO Kafka Connect standalone worker initialization took 2268ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:25:42,844] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:25:42,845] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:25:42,845] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:25:42,846] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:25:42,851] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:25:42,851] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:25:42,851] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:25:42,899] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:25:42,969] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:25:42,969] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:25:42,971] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:25:43,556] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:25:43,556] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:25:43,556] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:25:43,583] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:43,685] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:43,693] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:43,694] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,694] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:25:43,697] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:25:43,698] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:25:43,698] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:25:43,700] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:43,702] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:25:43,702] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:25:43,704] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:25:43,704] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,712] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:25:43,715] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:43,715] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,717] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:25:43,719] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:25:43,721] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:25:43,721] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:25:43,722] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:43,722] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:25:43,722] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:25:43,727] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:25:43,733] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:25:43,768] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:43,768] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:43,768] INFO Kafka startTimeMs: 1596039943768 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:43,776] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:25:43,777] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:25:43,778] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:25:43,777] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:25:43,780] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:25:43,781] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:43,785] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:25:43,786] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:43,786] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,786] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:25:43,787] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:25:43,787] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:25:43,787] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:25:43,788] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,788] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:25:43,789] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:25:43,790] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:25:43,790] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,790] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:25:43,790] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:25:43,791] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:25:43,791] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:25:43,791] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:25:43,791] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:25:43,791] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:25:43,792] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:25:43,792] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:25:43,793] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:25:43,795] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:25:43,795] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:25:43,796] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:25:43,801] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:25:43,848] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:25:43,848] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:25:43,848] INFO Kafka startTimeMs: 1596039943848 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:25:43,852] WARN [Producer clientId=connector-producer-jdbc-source-0] Error while fetching metadata with correlation id 3 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:25:43,855] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:25:43,857] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:25:43,857] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:25:43,858] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:25:43,863] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:25:43,864] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:25:43,890] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:25:43,891] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:25:43,894] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:25:43,906] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:25:43,906] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:25:43,911] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-6a67ef2a-c368-4d09-ba75-e7fbcca6aa20=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:25:43,916] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:25:43,922] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:25:43,932] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:25:43,949] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:25:44,011] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:25:44,012] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:25:44,016] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:25:44,017] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:25:44,018] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:25:44,020] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:25:44,021] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:25:44,025] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:25:44,026] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:25:44,026] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:25:44,026] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:25:44,027] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:25:44,027] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-6a67ef2a-c368-4d09-ba75-e7fbcca6aa20 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:25:53,776] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:25:53,777] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:25:53,786] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 8 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:03,786] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:03,786] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:03,787] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:13,787] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:13,788] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:13,789] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:23,790] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:23,790] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:23,791] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:33,792] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:33,792] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:33,793] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:43,793] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:43,794] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:43,795] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:26:53,796] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:26:53,797] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:26:53,798] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:27:03,799] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:27:03,799] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:27:03,800] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:27:13,734] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:27:13,735] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:27:13,740] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:27:13,741] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:27:13,742] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:27:13,742] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:27:13,742] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:13,744] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:13,744] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:13,744] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:13,744] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:27:13,827] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:27:13,827] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:13,828] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:27:13,828] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:27:13,829] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:27:13,829] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:27:13,832] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:13,832] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:27:13,832] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:27:13,832] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:13,833] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:13,833] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:27:13,833] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:27:13,834] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:27:13,834] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:27:13,834] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:27:15,643] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:27:15,649] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:27:15,653] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:27:15,677] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:15,997] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:15,998] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:15,998] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:15,998] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:15,999] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:15,999] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:16,000] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:16,206] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:16,207] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:16,208] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:16,355] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:16,355] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:16,357] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,261] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:17,261] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,261] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,261] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,261] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,262] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,263] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,264] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,265] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:17,266] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,267] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,267] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,267] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,267] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,267] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,268] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,269] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,270] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,271] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,271] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:17,271] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,271] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:17,271] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:17,271] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:17,272] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:17,272] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,272] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,272] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:17,284] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:27:17,285] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:27:17,288] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:27:17,342] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,342] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,342] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,342] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,342] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,343] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,343] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:17,343] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:17,343] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:17,344] INFO Kafka startTimeMs: 1596040037343 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:17,600] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:27:17,624] INFO Logging initialized @2284ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:27:17,689] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:27:17,690] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:27:17,696] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:27:17,728] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:27:17,728] INFO Started @2388ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:27:17,747] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:17,747] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:27:17,748] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:17,748] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:27:17,748] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:17,748] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:27:17,759] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:17,759] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:17,760] INFO Kafka startTimeMs: 1596040037759 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:17,884] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:17,885] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:17,891] INFO Kafka Connect standalone worker initialization took 2247ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:27:17,892] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:27:17,892] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:27:17,893] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:27:17,893] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:27:17,898] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:27:17,899] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:27:17,899] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:27:17,942] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:27:18,010] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:27:18,011] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:27:18,012] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:27:18,531] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:27:18,532] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:27:18,532] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:27:18,553] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:18,642] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:18,648] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:18,649] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,649] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:27:18,651] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:27:18,652] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:27:18,652] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:27:18,653] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:18,654] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:27:18,654] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:27:18,656] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:27:18,656] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,662] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:27:18,664] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:18,665] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,666] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:27:18,666] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:27:18,667] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:27:18,667] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:27:18,668] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:18,668] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:27:18,668] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:27:18,671] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:27:18,681] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:27:18,707] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:18,707] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:18,707] INFO Kafka startTimeMs: 1596040038707 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:18,715] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:27:18,716] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:27:18,716] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:27:18,717] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:27:18,717] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:18,718] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:27:18,723] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:18,724] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:18,724] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,725] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:27:18,726] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:27:18,726] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:27:18,726] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:27:18,727] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,727] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:27:18,728] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:27:18,728] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:27:18,728] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:27:18,729] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:18,729] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,729] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:27:18,729] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:27:18,730] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:27:18,730] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:27:18,730] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:27:18,730] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:18,730] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:27:18,731] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:27:18,732] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:27:18,733] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:27:18,733] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:18,740] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:27:18,772] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:18,772] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:18,772] INFO Kafka startTimeMs: 1596040038772 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:18,777] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:27:18,779] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:27:18,779] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:27:18,780] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:27:18,783] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:27:18,784] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:27:18,793] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:27:18,794] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:27:18,796] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:27:18,804] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:27:18,804] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:27:18,809] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-5afc82cd-bf93-4b0a-9357-da1017af430c=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:27:18,813] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:27:18,816] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:27:18,824] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:27:18,833] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:27:18,865] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:18,867] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:27:18,871] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:27:18,871] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:27:18,872] INFO Creating table with sql: CREATE TABLE "users" (
"id" INTEGER NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 17:27:18,873] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:27:18,873] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:27:18,875] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:27:18,876] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:27:18,877] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:27:18,879] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:27:18,880] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:27:18,880] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:27:18,880] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:18,881] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:27:18,881] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-5afc82cd-bf93-4b0a-9357-da1017af430c sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:27:20,710] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:27:20,710] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:27:20,714] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:27:20,715] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:27:20,716] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:27:20,716] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:27:20,716] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:20,718] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:20,718] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:20,719] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:20,719] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:27:20,790] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:27:20,790] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:20,790] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:27:20,790] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:27:20,794] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:27:20,794] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:27:20,797] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:20,797] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:27:20,797] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:27:20,797] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:20,798] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:20,798] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:27:20,799] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:27:20,799] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:27:20,800] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:27:20,800] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:27:42,015] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:27:42,021] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:27:42,026] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:27:42,047] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:42,408] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:42,409] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,410] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,410] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,410] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,410] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,411] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:42,669] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:42,669] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,670] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:27:42,819] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:42,819] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:42,821] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,832] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:27:43,832] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,833] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,834] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,835] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,836] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:27:43,837] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,838] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,839] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,840] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,841] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,842] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,842] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,842] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:43,842] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,843] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:43,843] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:43,843] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:43,843] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:27:43,844] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,844] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,844] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:27:43,856] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:27:43,857] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:27:43,861] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:27:43,914] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,914] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:27:43,915] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:43,916] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:43,916] INFO Kafka startTimeMs: 1596040063915 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:44,225] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:27:44,247] INFO Logging initialized @2559ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:27:44,305] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:27:44,305] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:27:44,312] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:27:44,342] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:27:44,342] INFO Started @2654ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:27:44,363] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:44,364] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:27:44,364] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:44,364] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:27:44,364] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:27:44,365] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:27:44,375] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:44,376] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:44,376] INFO Kafka startTimeMs: 1596040064375 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:44,491] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:44,492] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:44,500] INFO Kafka Connect standalone worker initialization took 2484ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:27:44,500] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:27:44,501] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:27:44,501] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:27:44,502] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:27:44,508] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:27:44,509] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:27:44,509] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:27:44,576] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:27:44,653] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:27:44,653] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:27:44,654] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:27:45,097] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:27:45,097] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:27:45,097] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:27:45,116] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:45,203] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:45,209] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:45,209] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,209] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:27:45,212] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:27:45,212] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:27:45,213] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:27:45,213] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:45,215] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:27:45,215] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:27:45,216] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:27:45,217] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,223] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:27:45,225] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:45,225] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,226] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:27:45,227] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:27:45,228] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:27:45,228] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:27:45,228] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:45,229] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:27:45,229] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:27:45,233] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:27:45,238] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:27:45,257] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:45,257] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:45,257] INFO Kafka startTimeMs: 1596040065257 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:45,265] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:27:45,266] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:27:45,266] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:27:45,266] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:27:45,267] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:45,268] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:27:45,273] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:27:45,273] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:45,274] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,274] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:27:45,275] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:27:45,275] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:27:45,276] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:27:45,276] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,277] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:27:45,291] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:27:45,292] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:27:45,292] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,293] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:27:45,293] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:27:45,293] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:27:45,293] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:27:45,293] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:27:45,293] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:27:45,293] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:27:45,293] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:27:45,294] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:27:45,294] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:27:45,295] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:27:45,296] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:27:45,296] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:27:45,305] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:27:45,338] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:27:45,338] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:27:45,338] INFO Kafka startTimeMs: 1596040065338 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:27:45,340] WARN [Producer clientId=connector-producer-jdbc-source-0] Error while fetching metadata with correlation id 3 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:27:45,345] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:27:45,346] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:27:45,346] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:27:45,347] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:27:45,350] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:27:45,351] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:27:45,368] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:27:45,369] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:27:45,371] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:27:45,380] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:27:45,381] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:27:45,385] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-d372419b-175f-45e9-8e64-ce564145c44d=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:27:45,388] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:27:45,392] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:27:45,400] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:27:45,408] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:27:45,479] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:27:45,479] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:27:45,484] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:27:45,484] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:27:45,485] INFO Creating table with sql: CREATE TABLE "users" (
"id" INTEGER NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 17:27:45,485] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:27:45,486] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:27:45,487] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:27:45,488] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:27:45,489] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:27:45,492] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"users"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:275)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:129)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 17:27:45,492] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:27:45,492] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:27:45,492] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:45,493] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:27:45,493] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-d372419b-175f-45e9-8e64-ce564145c44d sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:27:48,384] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:27:48,384] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:27:48,388] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:27:48,388] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:27:48,389] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:27:48,389] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:27:48,389] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:48,391] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:48,391] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:48,391] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:27:48,391] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:27:48,460] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:27:48,460] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:48,461] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:27:48,461] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:27:48,465] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:27:48,465] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:27:48,468] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:27:48,468] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:27:48,468] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:27:48,468] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:27:48,469] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:27:48,469] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:27:48,469] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:27:48,470] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:27:48,470] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:27:48,470] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:28:10,851] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:28:10,857] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:28:10,863] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:28:10,882] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:28:11,165] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:28:11,166] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,166] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,166] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,166] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,167] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,167] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:28:11,365] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:28:11,365] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,365] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:28:11,511] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:28:11,511] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:11,512] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,431] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:28:12,431] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,432] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,433] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,434] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,435] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,436] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:28:12,436] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,436] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,437] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,437] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,437] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,437] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,437] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,438] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,439] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,439] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,439] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,440] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,441] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,442] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:28:12,442] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,442] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:28:12,442] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:28:12,442] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:28:12,442] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:28:12,443] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,443] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,443] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:28:12,458] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:28:12,458] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:28:12,462] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:28:12,515] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,515] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:28:12,516] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:28:12,516] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:28:12,516] INFO Kafka startTimeMs: 1596040092516 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:28:12,773] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:28:12,789] INFO Logging initialized @2236ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:28:12,836] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:28:12,836] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:28:12,845] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:28:12,869] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:28:12,869] INFO Started @2316ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:28:12,889] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:28:12,889] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:28:12,889] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:28:12,889] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:28:12,889] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:28:12,889] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:28:12,898] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:28:12,898] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:28:12,898] INFO Kafka startTimeMs: 1596040092898 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:28:13,004] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:28:13,005] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:28:13,011] INFO Kafka Connect standalone worker initialization took 2158ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:28:13,011] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:28:13,012] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:28:13,012] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:28:13,013] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:28:13,019] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:28:13,019] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:28:13,019] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:28:13,062] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:28:13,138] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:28:13,138] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:28:13,140] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:28:13,662] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:28:13,662] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:28:13,662] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:28:13,684] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:28:13,776] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:28:13,783] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:28:13,783] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,784] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:28:13,786] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:28:13,787] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:28:13,788] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:28:13,788] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:28:13,790] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:28:13,790] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:28:13,791] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:28:13,792] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,796] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:28:13,798] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:28:13,799] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,800] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:28:13,801] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:28:13,802] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:28:13,802] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:28:13,802] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:28:13,802] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:28:13,803] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:28:13,807] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:28:13,813] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:28:13,832] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:28:13,832] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:28:13,832] INFO Kafka startTimeMs: 1596040093832 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:28:13,840] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:28:13,841] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:28:13,841] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:28:13,841] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:28:13,842] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:28:13,842] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:28:13,846] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:28:13,846] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:28:13,846] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,846] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:28:13,847] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:28:13,847] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:28:13,848] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:28:13,848] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,849] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:28:13,849] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:28:13,850] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:28:13,851] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:28:13,851] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,851] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:28:13,851] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:28:13,851] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:28:13,851] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:28:13,851] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:28:13,851] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:28:13,852] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:28:13,852] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:28:13,852] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:28:13,853] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:28:13,853] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:28:13,853] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:28:13,860] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:28:13,899] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:28:13,900] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:28:13,900] INFO Kafka startTimeMs: 1596040093899 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:28:13,905] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:28:13,907] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:28:13,907] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:28:13,907] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:28:13,910] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:28:13,910] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:28:13,921] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:28:13,922] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:28:13,923] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:28:13,930] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:28:13,931] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:28:13,934] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-807ad2ba-3200-45ae-a8f5-498f93a71f1d=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:28:13,938] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:28:13,943] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:28:13,951] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:28:13,960] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:28:13,987] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:28:13,988] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:28:13,992] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:28:13,992] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:28:13,993] INFO Creating table with sql: CREATE TABLE "users" (
"id" INTEGER NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 17:28:13,994] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:28:13,994] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:28:13,996] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:28:13,997] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:28:23,840] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:28:23,840] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:28:23,846] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:28:23,903] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=4, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 17:28:30,752] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:28:30,752] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:28:30,760] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:28:30,760] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:28:30,761] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:28:30,761] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:28:30,762] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:28:30,762] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 17:28:30,766] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:28:30,766] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:28:30,767] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:28:30,767] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-807ad2ba-3200-45ae-a8f5-498f93a71f1d sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:28:30,772] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:28:30,773] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:28:30,773] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:28:30,773] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:28:30,867] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:28:30,868] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:28:30,868] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:28:30,868] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:28:30,869] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:28:30,869] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:28:30,872] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:28:30,872] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:28:30,872] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:28:30,873] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:28:30,873] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:28:30,874] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:28:30,874] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:28:30,875] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:28:30,875] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:28:30,875] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:40:07,352] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:40:07,359] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:40:07,366] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:40:07,393] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:07,687] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:07,688] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,688] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,688] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,688] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,688] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,689] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:07,884] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:07,884] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:07,885] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:08,054] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:08,054] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:08,056] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,013] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:09,013] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,014] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,015] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,016] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,017] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,018] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,019] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,020] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:09,021] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,021] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,021] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,021] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,021] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,022] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,022] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,022] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,022] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,022] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,023] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,024] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,025] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,025] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,025] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,025] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:09,025] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,025] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:09,025] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:09,026] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:09,026] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:09,026] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,026] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,026] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:09,040] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:40:09,041] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:40:09,046] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:40:09,095] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,095] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:09,096] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:09,096] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:09,096] INFO Kafka startTimeMs: 1596040809095 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:09,355] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:40:09,373] INFO Logging initialized @2325ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:40:09,426] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:40:09,426] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:40:09,435] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:40:09,461] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:40:09,462] INFO Started @2413ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:40:09,481] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:09,482] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:40:09,482] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:09,482] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:40:09,483] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:09,483] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:40:09,492] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:09,492] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:09,492] INFO Kafka startTimeMs: 1596040809492 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:09,608] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:09,609] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:09,619] INFO Kafka Connect standalone worker initialization took 2265ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:40:09,619] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:40:09,621] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:40:09,621] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:40:09,622] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:40:09,629] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:40:09,629] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:40:09,630] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:40:09,685] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:40:09,762] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:40:09,763] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:40:09,764] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:40:10,260] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:40:10,260] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:40:10,260] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:40:10,278] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:10,369] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:10,375] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:10,376] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,376] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:10,380] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:10,381] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:40:10,381] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:40:10,383] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:10,384] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:40:10,385] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:10,385] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:40:10,386] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,390] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:10,392] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:10,392] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,394] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:10,394] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:10,395] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:10,395] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:10,396] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:10,396] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:10,396] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:10,401] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:40:10,407] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:40:10,427] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:10,427] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:10,428] INFO Kafka startTimeMs: 1596040810427 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:10,434] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:40:10,435] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:40:10,435] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:10,435] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:40:10,437] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:10,437] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:10,444] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:10,445] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:10,445] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,445] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:10,446] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:10,447] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:40:10,447] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:10,447] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:40:10,447] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:10,447] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:40:10,447] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,449] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:40:10,449] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:10,450] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:10,450] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,451] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:10,451] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:10,452] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:10,452] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:10,452] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:10,452] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:10,453] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:10,454] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:40:10,454] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:10,455] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:10,463] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:40:10,502] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:10,503] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:10,503] INFO Kafka startTimeMs: 1596040810502 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:10,508] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:10,509] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:40:10,509] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:40:10,509] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:40:10,511] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:40:10,512] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:40:10,524] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:10,525] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:40:10,527] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:10,533] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:40:10,533] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:10,538] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 5: {connector-consumer-jdbc-sink-0-84f44cb5-b1b7-46cd-ad79-1f5a7d4bd6e1=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:40:10,542] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:40:10,545] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:40:10,554] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:40:10,588] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:10,589] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:40:10,593] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:10,593] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:10,594] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:40:10,595] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:40:10,599] WARN Write of 1 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)
	at org.sqlite.core.DB.newSQLException(DB.java:941)
	at org.sqlite.core.DB.newSQLException(DB.java:953)
	at org.sqlite.core.DB.throwex(DB.java:918)
	at org.sqlite.core.DB.executeBatch(DB.java:805)
	at org.sqlite.core.CorePreparedStatement.executeBatch(CorePreparedStatement.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:40:10,601] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:10,601] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:40:10,601] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 17:40:13,603] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:13,605] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:40:13,606] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:13,607] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:13,609] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:40:13,609] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:40:13,610] WARN Write of 1 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)
	at org.sqlite.core.DB.newSQLException(DB.java:941)
	at org.sqlite.core.DB.newSQLException(DB.java:953)
	at org.sqlite.core.DB.throwex(DB.java:918)
	at org.sqlite.core.DB.executeBatch(DB.java:805)
	at org.sqlite.core.CorePreparedStatement.executeBatch(CorePreparedStatement.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:40:13,610] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:13,610] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:40:13,610] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 17:40:16,611] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:16,612] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:40:16,613] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:16,614] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:16,615] INFO Creating table with sql: CREATE TABLE "users" (
"id" INTEGER NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 17:40:16,616] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:16,616] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:16,618] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:40:16,618] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:40:16,671] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:40:16,672] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:40:16,676] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:40:16,676] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:40:16,680] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:40:16,680] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:40:16,680] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:16,681] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=7, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 17:40:16,685] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:40:16,685] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:16,686] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:40:16,686] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-84f44cb5-b1b7-46cd-ad79-1f5a7d4bd6e1 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:40:16,693] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:16,693] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:16,693] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:16,694] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:40:16,763] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:40:16,763] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:16,763] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:40:16,763] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:40:16,787] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 24 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:40:16,788] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:40:16,790] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:16,791] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:40:16,791] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:40:16,791] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:16,791] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:16,791] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:40:16,792] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:40:16,792] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:40:16,792] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:40:16,792] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:40:18,393] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:40:18,399] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:40:18,405] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:40:18,430] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:18,735] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:18,736] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,736] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,737] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,737] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,737] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,738] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:18,949] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:18,950] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:18,950] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:19,094] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:19,094] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,095] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,988] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:19,988] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,988] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,988] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,988] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,988] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,989] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,990] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,990] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,990] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,990] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,990] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,991] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,992] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,993] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,994] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,994] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,994] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,994] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,994] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:19,995] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,995] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,996] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,996] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,996] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,996] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,996] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,997] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,998] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:19,999] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:19,999] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:20,000] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:20,000] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:20,000] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:20,000] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:20,001] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:20,001] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:20,001] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:20,011] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:40:20,012] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:40:20,016] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:40:20,065] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,065] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,065] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,065] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,066] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,066] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,066] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:20,066] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:20,066] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:20,066] INFO Kafka startTimeMs: 1596040820066 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:20,308] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:40:20,326] INFO Logging initialized @2240ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:40:20,379] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:40:20,380] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:40:20,387] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:40:20,414] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:40:20,414] INFO Started @2328ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:40:20,433] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:20,433] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:40:20,433] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:20,433] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:40:20,434] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:20,434] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:40:20,443] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:20,443] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:20,444] INFO Kafka startTimeMs: 1596040820443 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:20,553] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:20,555] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:20,561] INFO Kafka Connect standalone worker initialization took 2168ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:40:20,562] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:40:20,563] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:40:20,563] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:40:20,563] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:40:20,568] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:40:20,568] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:40:20,569] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:40:20,608] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:40:20,689] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:40:20,689] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:40:20,690] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:40:21,168] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:40:21,168] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:40:21,168] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:40:21,198] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:21,296] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:21,302] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:21,303] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,303] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:21,305] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:21,306] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:40:21,306] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:40:21,307] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:21,309] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:40:21,309] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:21,310] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:40:21,310] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,315] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:21,317] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:21,317] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,319] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:21,320] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:21,321] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:21,321] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:21,322] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:21,322] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:21,323] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:21,327] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:40:21,332] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:40:21,353] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:21,353] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:21,354] INFO Kafka startTimeMs: 1596040821353 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:21,362] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:40:21,363] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:21,363] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:40:21,363] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:40:21,364] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:21,364] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:21,368] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:21,369] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:21,369] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,369] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:21,370] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:21,370] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:21,371] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:21,371] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,372] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:40:21,372] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:21,372] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:40:21,373] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:40:21,373] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:40:21,373] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:21,373] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,374] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:21,374] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:21,374] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:21,375] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:21,375] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:21,375] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:21,375] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:21,376] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:40:21,376] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:21,377] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:21,384] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:40:21,417] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:21,418] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:21,418] INFO Kafka startTimeMs: 1596040821417 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:21,424] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:21,425] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:40:21,425] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:40:21,425] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:40:21,427] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:40:21,428] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:40:21,439] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:21,440] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:40:21,442] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:21,448] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:40:21,448] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:21,452] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 7: {connector-consumer-jdbc-sink-0-4520113b-068b-456a-b259-e0902fd0acfc=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:40:21,455] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 7 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:40:21,458] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:40:21,469] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:40:21,506] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:21,507] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:40:21,510] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:21,511] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:21,512] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:40:21,513] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:40:31,362] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:40:31,362] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:40:31,369] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 7 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:40:31,422] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 17:40:34,256] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Received unknown topic or partition error in fetch for partition users-0 (org.apache.kafka.clients.consumer.internals.Fetcher:1250)
[2020-07-29 17:40:34,261] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 42 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:40:34,262] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:40:34,262] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:34,372] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 44 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 17:40:34,372] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] The following subscribed topics are not assigned to any members: [users]  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:589)
[2020-07-29 17:40:34,373] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 8: {connector-consumer-jdbc-sink-0-4520113b-068b-456a-b259-e0902fd0acfc=Assignment(partitions=[])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:40:34,375] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 8 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:40:34,376] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:40:34,473] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:40:34,474] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:34,476] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 9: {connector-consumer-jdbc-sink-0-4520113b-068b-456a-b259-e0902fd0acfc=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:40:34,478] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 9 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:40:34,479] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:40:34,481] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:40:34,489] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:40:35,751] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:40:35,751] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:40:35,754] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:40:35,754] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:40:35,755] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:40:35,755] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:40:35,755] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:35,756] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:40:35,756] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:35,756] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:40:35,756] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-4520113b-068b-456a-b259-e0902fd0acfc sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:40:35,762] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:35,763] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:35,763] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:35,763] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:40:35,792] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:40:35,792] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:35,792] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:40:35,792] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:40:35,793] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:40:35,794] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:40:35,797] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:35,797] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:40:35,797] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:40:35,797] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:35,798] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:35,798] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:40:35,798] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:40:35,799] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:40:35,799] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:40:35,799] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:40:37,570] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:40:37,576] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:40:37,581] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:40:37,603] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:37,891] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:37,891] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:37,892] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:37,892] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:37,892] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:37,892] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:37,893] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:38,097] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:38,097] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:38,098] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:40:38,235] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:38,235] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:38,236] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,164] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,165] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,166] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,167] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,168] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,169] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:40:39,170] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,170] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,170] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,170] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,170] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,171] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,172] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,173] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,174] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:39,175] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,175] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:39,175] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:39,176] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:39,176] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:40:39,176] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,176] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,176] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:40:39,191] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:40:39,192] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:40:39,197] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:40:39,254] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,254] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:40:39,255] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:39,255] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:39,255] INFO Kafka startTimeMs: 1596040839254 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:39,513] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:40:39,532] INFO Logging initialized @2269ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:40:39,586] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:40:39,586] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:40:39,593] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:40:39,616] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:40:39,617] INFO Started @2354ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:40:39,637] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:39,637] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:40:39,638] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:39,638] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:40:39,638] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:40:39,638] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:40:39,650] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:39,651] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:39,651] INFO Kafka startTimeMs: 1596040839650 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:39,783] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:39,784] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:39,795] INFO Kafka Connect standalone worker initialization took 2223ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:40:39,795] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:40:39,796] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:40:39,796] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:40:39,797] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:40:39,804] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:40:39,805] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:40:39,805] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:40:39,846] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:40:39,929] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:40:39,929] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:40:39,930] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:40:40,474] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:40:40,474] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:40:40,474] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:40:40,515] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:40,621] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:40,627] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:40,627] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,627] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:40,630] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:40,631] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:40:40,631] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:40:40,632] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:40,634] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:40:40,634] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:40,635] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:40:40,636] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,644] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:40,646] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:40,646] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,647] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:40,648] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:40,649] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:40,650] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:40,650] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:40,650] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:40,651] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:40,655] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:40:40,663] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:40:40,683] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:40,684] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:40,684] INFO Kafka startTimeMs: 1596040840683 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:40,691] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:40:40,692] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:40,692] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:40:40,693] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:40:40,693] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:40,694] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:40,696] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:40:40,696] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:40,696] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,696] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:40:40,697] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:40:40,697] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:40:40,698] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:40,698] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,699] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:40:40,699] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:40:40,700] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:40:40,701] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,701] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:40:40,701] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:40:40,701] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:40:40,702] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:40:40,702] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:40:40,702] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:40:40,703] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:40:40,703] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:40:40,703] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:40:40,703] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:40:40,705] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:40:40,705] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:40:40,705] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:40:40,714] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:40:40,753] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:40:40,754] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:40:40,754] INFO Kafka startTimeMs: 1596040840753 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:40:40,757] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:40:40,759] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:40:40,759] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:40:40,759] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:40:40,762] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:40:40,763] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:40:40,773] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:40:40,774] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:40:40,776] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:40,783] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:40:40,784] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:40:40,788] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 11: {connector-consumer-jdbc-sink-0-5d52727c-9262-4270-a7d9-d207040aa94f=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:40:40,793] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 11 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:40:40,796] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:40:40,805] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 17:40:40,816] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 17:40:40,849] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:40:40,850] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:40:40,853] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:40:40,854] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:40:40,856] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:40:40,857] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:40:50,691] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:40:50,692] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:40:50,699] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 7 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:40:50,756] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 17:40:56,882] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:40:56,882] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:40:56,886] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:40:56,886] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:40:56,890] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:40:56,890] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:40:56,891] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:56,891] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=4, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 17:40:56,894] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:40:56,895] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:56,895] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:40:56,895] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-5d52727c-9262-4270-a7d9-d207040aa94f sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:40:56,902] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:56,903] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:56,903] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:40:56,903] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:40:56,915] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:40:56,915] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:56,916] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:40:56,916] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:40:56,917] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:40:56,918] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:40:56,921] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:40:56,921] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:40:56,921] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:40:56,921] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:40:56,922] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:40:56,922] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:40:56,923] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:40:56,923] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:40:56,923] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:40:56,924] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:43:35,741] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:43:35,748] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:43:35,755] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:43:35,780] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:43:36,055] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:43:36,055] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,055] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,056] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,056] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,056] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,057] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:43:36,265] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:43:36,266] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,266] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:43:36,434] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:43:36,435] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:36,437] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,310] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:43:37,310] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,310] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,310] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,310] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,310] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,311] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,312] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,313] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,314] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:43:37,315] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,315] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,315] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,315] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,315] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,315] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,316] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,317] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,318] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,318] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,318] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,319] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,319] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,319] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,319] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,319] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,320] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,320] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:43:37,320] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,321] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:43:37,321] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:43:37,321] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:43:37,322] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:43:37,322] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,322] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,322] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:43:37,333] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:43:37,334] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:43:37,338] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:43:37,390] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,390] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:43:37,391] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:43:37,391] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:43:37,391] INFO Kafka startTimeMs: 1596041017390 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:43:37,660] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:43:37,681] INFO Logging initialized @2250ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:43:37,745] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:43:37,745] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:43:37,751] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:43:37,778] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:43:37,778] INFO Started @2347ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:43:37,796] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:43:37,796] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:43:37,796] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:43:37,796] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:43:37,797] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:43:37,797] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:43:37,807] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:43:37,807] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:43:37,807] INFO Kafka startTimeMs: 1596041017807 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:43:37,916] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:43:37,918] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:43:37,926] INFO Kafka Connect standalone worker initialization took 2183ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:43:37,926] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:43:37,927] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:43:37,927] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:43:37,927] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:43:37,932] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:43:37,932] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:43:37,932] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:43:37,972] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:43:38,050] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:43:38,050] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:43:38,051] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:43:38,552] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:43:38,552] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:43:38,552] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:43:38,573] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:43:38,662] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:43:38,668] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:43:38,668] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,669] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:43:38,673] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:43:38,673] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:43:38,674] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:43:38,674] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:43:38,676] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:43:38,676] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:43:38,677] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:43:38,677] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,682] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:43:38,684] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:43:38,685] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,686] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:43:38,686] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:43:38,687] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:43:38,687] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:43:38,688] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:43:38,688] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:43:38,688] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:43:38,692] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:43:38,697] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:43:38,717] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:43:38,717] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:43:38,718] INFO Kafka startTimeMs: 1596041018717 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:43:38,726] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:43:38,726] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:43:38,727] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:43:38,727] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:43:38,727] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:43:38,731] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:43:38,732] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:43:38,732] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,732] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:43:38,733] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:43:38,733] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:43:38,733] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:43:38,734] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,735] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:43:38,735] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:43:38,736] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:43:38,736] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,737] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:43:38,737] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:43:38,737] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:43:38,738] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:43:38,738] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:43:38,738] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:43:38,739] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:43:38,741] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:43:38,742] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:43:38,742] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:43:38,749] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:43:38,751] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:43:38,760] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:43:38,761] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:43:38,762] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:43:38,771] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:43:38,771] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:43:38,771] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:245)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown field: name
	at org.apache.kafka.connect.transforms.ExtractField.apply(ExtractField.java:65)
	at org.apache.kafka.connect.runtime.TransformationChain.lambda$apply$0(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 11 more
[2020-07-29 17:43:38,773] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:43:38,773] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:43:38,774] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:43:38,791] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:43:38,791] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:43:38,792] INFO Kafka startTimeMs: 1596041018791 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:43:38,795] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:43:38,797] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:43:38,797] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:43:38,797] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:43:38,801] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:43:38,802] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:43:38,818] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:43:38,819] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:43:38,822] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:43:38,829] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:43:38,829] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:43:38,834] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 13: {connector-consumer-jdbc-sink-0-cb283056-1d3e-4e94-a761-a7609608c4be=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:43:38,838] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 13 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:43:38,842] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:43:38,851] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:43:48,726] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:43:48,726] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:43:58,727] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:43:58,727] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:43:58,803] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:43:58,803] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:43:58,809] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:43:58,810] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:43:58,811] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:43:58,811] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:43:58,811] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:43:58,811] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:43:58,812] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:43:58,812] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-cb283056-1d3e-4e94-a761-a7609608c4be sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:43:58,820] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:43:58,820] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:43:58,821] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:43:58,821] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:43:58,821] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:43:58,821] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:43:58,821] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:43:58,822] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:43:58,822] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:43:58,822] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:43:58,822] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:43:58,823] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:43:58,823] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:44:00,743] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:44:00,748] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:44:00,753] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:44:00,775] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:01,103] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:01,104] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,104] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,106] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:01,304] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:01,304] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,305] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:01,436] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:01,436] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:01,438] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,363] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,364] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,365] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,366] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,367] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,368] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,369] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:02,370] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,370] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,370] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,370] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,370] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,371] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,371] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,371] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,371] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,372] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,373] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,374] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,375] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,375] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,375] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,375] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,375] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:02,375] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,376] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:02,376] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:02,376] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:02,377] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:02,377] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,377] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,377] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:02,392] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:44:02,393] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:44:02,398] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:44:02,446] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,446] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,446] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,447] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,447] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,447] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,447] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:02,447] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:02,448] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:02,448] INFO Kafka startTimeMs: 1596041042447 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:02,704] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:44:02,723] INFO Logging initialized @2295ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:44:02,782] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:44:02,782] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:44:02,788] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:44:02,812] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:44:02,812] INFO Started @2384ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:44:02,833] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:02,833] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:44:02,833] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:02,833] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:44:02,833] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:02,834] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:44:02,845] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:02,846] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:02,846] INFO Kafka startTimeMs: 1596041042845 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:02,963] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:02,964] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:02,971] INFO Kafka Connect standalone worker initialization took 2226ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:44:02,971] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:44:02,972] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:44:02,973] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:44:02,973] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:44:02,981] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:44:02,981] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:44:02,981] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:44:03,027] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:44:03,105] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:44:03,106] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:44:03,107] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:44:03,567] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:44:03,567] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:44:03,567] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:44:03,603] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:03,700] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:03,707] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:03,707] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,708] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:44:03,710] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:44:03,710] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:44:03,711] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:44:03,711] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:44:03,713] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:44:03,713] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:44:03,714] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:44:03,715] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,722] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:44:03,724] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:03,724] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,726] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:44:03,726] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:44:03,727] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:44:03,728] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:44:03,728] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:03,728] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:44:03,728] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:44:03,732] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:44:03,739] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:44:03,763] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:03,763] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:03,763] INFO Kafka startTimeMs: 1596041043763 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:03,770] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:44:03,771] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:44:03,771] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:44:03,771] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:44:03,772] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:44:03,777] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:03,778] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:03,778] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,778] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:44:03,779] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:44:03,780] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:44:03,780] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:44:03,781] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,781] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:44:03,782] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:44:03,783] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:03,783] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,784] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:44:03,784] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:44:03,784] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:44:03,784] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:44:03,785] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:03,785] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:44:03,785] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:44:03,786] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:44:03,786] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:44:03,787] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:03,792] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:44:03,793] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:44:03,801] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:44:03,801] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:44:03,803] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:44:03,813] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:03,813] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:44:03,814] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:245)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown field: name
	at org.apache.kafka.connect.transforms.ExtractField.apply(ExtractField.java:65)
	at org.apache.kafka.connect.runtime.TransformationChain.lambda$apply$0(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 11 more
[2020-07-29 17:44:03,816] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:44:03,816] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:44:03,816] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:44:03,838] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:03,838] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:03,838] INFO Kafka startTimeMs: 1596041043837 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:03,845] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:44:03,846] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:44:03,846] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:44:03,847] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:44:03,849] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:44:03,849] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:44:03,865] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:44:03,866] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:44:03,868] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:44:03,875] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:44:03,876] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:44:03,881] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 15: {connector-consumer-jdbc-sink-0-88a39d40-91a9-4a99-a67e-8758f1f014c6=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:44:03,884] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 15 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:44:03,887] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:44:03,896] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:44:13,770] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:13,770] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:44:23,771] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:23,771] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:44:33,772] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:33,772] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:44:36,331] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:44:36,331] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:44:36,335] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:44:36,336] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:44:36,336] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:44:36,337] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:44:36,337] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:44:36,337] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:44:36,338] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:44:36,338] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-88a39d40-91a9-4a99-a67e-8758f1f014c6 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:44:36,344] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:44:36,345] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:44:36,345] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:44:36,345] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:44:36,345] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:44:36,346] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:44:36,346] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:44:36,346] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:44:36,346] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:44:36,347] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:44:36,347] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:44:36,348] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:44:36,348] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:44:37,902] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:44:37,908] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:44:37,913] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:44:37,936] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:38,262] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:38,263] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,263] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,263] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,263] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,263] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,264] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:38,504] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:38,504] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,505] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:44:38,675] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:38,675] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:38,677] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,640] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,641] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,642] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,643] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,644] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,645] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:44:39,646] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,646] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,646] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,646] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,647] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,648] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,649] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,650] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,650] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,650] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,650] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,650] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:39,651] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,651] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:39,651] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:39,652] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:39,652] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:44:39,652] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,652] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,652] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:44:39,664] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:44:39,665] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:44:39,668] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:44:39,724] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,724] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,724] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,724] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,725] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,725] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,725] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:44:39,725] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:39,725] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:39,726] INFO Kafka startTimeMs: 1596041079725 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:39,988] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:44:40,007] INFO Logging initialized @2441ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:44:40,067] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:44:40,068] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:44:40,074] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:44:40,104] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:44:40,105] INFO Started @2538ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:44:40,129] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:40,130] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:44:40,130] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:40,130] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:44:40,130] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:44:40,131] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:44:40,145] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:40,145] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:40,145] INFO Kafka startTimeMs: 1596041080145 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:40,299] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:40,301] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:40,312] INFO Kafka Connect standalone worker initialization took 2408ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:44:40,313] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:44:40,314] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:44:40,314] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:44:40,315] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:44:40,323] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:44:40,323] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:44:40,323] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:44:40,376] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:44:40,468] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:44:40,468] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:44:40,470] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:44:41,024] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:44:41,024] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:44:41,024] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:44:41,047] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:41,140] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:41,146] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:41,146] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,146] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:44:41,148] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:44:41,149] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:44:41,149] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:44:41,150] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:44:41,152] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:44:41,152] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:44:41,153] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:44:41,153] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,158] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:44:41,162] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:41,162] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,163] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:44:41,164] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:44:41,165] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:44:41,165] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:44:41,165] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:41,165] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:44:41,166] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:44:41,170] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:44:41,175] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:44:41,197] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:41,197] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:41,198] INFO Kafka startTimeMs: 1596041081197 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:41,209] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:44:41,210] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:44:41,210] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:44:41,210] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:44:41,210] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:44:41,215] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:44:41,215] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:41,216] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,216] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:44:41,216] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:44:41,217] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:44:41,217] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:44:41,217] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,218] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:44:41,218] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:44:41,219] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:44:41,220] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,220] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:44:41,221] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:44:41,221] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:44:41,221] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:44:41,222] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:44:41,222] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:44:41,222] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:44:41,223] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:44:41,224] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:44:41,224] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:44:41,230] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:44:41,231] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:44:41,237] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:44:41,238] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:44:41,239] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:44:41,248] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:41,248] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:44:41,248] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:245)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown field: name
	at org.apache.kafka.connect.transforms.ExtractField.apply(ExtractField.java:65)
	at org.apache.kafka.connect.runtime.TransformationChain.lambda$apply$0(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 11 more
[2020-07-29 17:44:41,250] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:44:41,250] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:44:41,250] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:44:41,268] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:44:41,268] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:44:41,268] INFO Kafka startTimeMs: 1596041081268 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:44:41,272] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:44:41,273] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:44:41,274] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:44:41,274] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:44:41,276] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:44:41,276] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:44:41,292] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:44:41,293] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:44:41,294] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:44:41,302] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:44:41,302] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:44:41,306] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 17: {connector-consumer-jdbc-sink-0-ca082a48-4533-46de-beec-5039f1b494bd=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:44:41,309] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 17 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:44:41,312] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:44:41,322] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:44:51,209] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:44:51,210] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:01,210] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:01,211] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:11,211] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:11,212] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:21,212] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:21,213] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:31,213] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:31,214] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:41,214] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:41,215] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:45:51,215] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:45:51,216] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:01,216] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:01,217] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:11,217] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:11,218] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:21,218] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:21,219] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:31,219] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:31,220] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:41,220] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:41,221] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:46:51,221] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:46:51,222] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:01,223] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:01,224] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:11,224] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:11,224] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:21,225] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:21,225] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:31,225] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:31,226] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:41,226] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:41,227] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:47:51,227] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:47:51,228] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:01,228] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:01,228] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:11,229] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:11,229] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:21,230] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:21,230] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:31,231] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:31,231] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:41,232] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:41,232] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:48:51,232] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:48:51,233] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:49:01,233] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:49:01,233] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:49:10,383] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:49:10,383] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:49:10,387] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:49:10,388] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:49:10,388] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:49:10,389] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:49:10,389] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:49:10,389] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:49:10,390] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:49:10,390] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-ca082a48-4533-46de-beec-5039f1b494bd sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:49:10,395] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:49:10,395] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:49:10,395] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:49:10,396] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:49:10,396] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:49:10,396] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:49:10,396] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:49:10,396] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:49:10,397] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:49:10,397] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:49:10,397] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:49:10,398] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:49:10,398] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:49:12,225] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:49:12,232] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:49:12,238] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:49:12,262] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:12,549] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:12,550] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,550] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,550] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,550] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,550] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,551] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:12,748] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:12,748] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,749] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:12,893] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:12,893] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:12,895] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,765] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:13,765] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,765] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,766] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,767] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,768] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,769] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,770] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,771] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,772] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,772] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:13,773] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,773] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,773] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,774] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,774] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,774] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,774] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,774] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,775] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,776] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,777] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:13,777] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,778] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:13,778] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:13,778] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:13,778] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:13,778] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,778] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,778] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:13,793] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:49:13,794] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:49:13,798] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:49:13,851] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,851] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:13,852] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:13,852] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:13,852] INFO Kafka startTimeMs: 1596041353852 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:14,094] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:49:14,117] INFO Logging initialized @2200ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:49:14,172] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:49:14,172] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:49:14,182] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:49:14,211] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:49:14,212] INFO Started @2295ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:49:14,229] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:14,230] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:49:14,230] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:14,230] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:49:14,230] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:14,230] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:49:14,241] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:14,241] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:14,241] INFO Kafka startTimeMs: 1596041354241 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:14,374] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:14,375] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:14,382] INFO Kafka Connect standalone worker initialization took 2155ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:49:14,382] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:49:14,383] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:49:14,383] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:49:14,384] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:49:14,389] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:49:14,389] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:49:14,389] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:49:14,430] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:49:14,506] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:49:14,507] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:49:14,508] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:49:14,982] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:49:14,982] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:49:14,982] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:49:15,002] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:15,090] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:15,096] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:15,096] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,097] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:49:15,100] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:49:15,101] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:49:15,102] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:49:15,103] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:49:15,105] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:49:15,105] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:49:15,106] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:49:15,107] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,111] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:49:15,113] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:15,113] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,115] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:49:15,115] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:49:15,116] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:49:15,116] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:49:15,117] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:15,117] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:49:15,117] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:49:15,123] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:49:15,128] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:49:15,149] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:15,150] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:15,150] INFO Kafka startTimeMs: 1596041355149 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:15,159] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:49:15,160] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:49:15,160] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:49:15,161] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:49:15,161] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:49:15,166] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:15,166] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:15,167] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,167] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:49:15,168] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:49:15,168] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:49:15,168] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:49:15,168] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,169] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:49:15,169] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:49:15,170] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:15,170] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,171] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:49:15,171] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:49:15,171] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:49:15,172] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:49:15,172] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:15,172] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:49:15,172] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:49:15,173] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:49:15,173] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:49:15,173] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:15,180] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:49:15,185] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:49:15,193] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:49:15,193] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:49:15,194] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:49:15,204] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:49:15,204] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:49:15,205] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:245)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown field: name
	at org.apache.kafka.connect.transforms.ExtractField.apply(ExtractField.java:65)
	at org.apache.kafka.connect.runtime.TransformationChain.lambda$apply$0(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 11 more
[2020-07-29 17:49:15,207] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:49:15,207] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:49:15,207] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:49:15,219] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:15,219] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:15,219] INFO Kafka startTimeMs: 1596041355219 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:15,224] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:49:15,225] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:49:15,225] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:49:15,226] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:49:15,228] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:49:15,229] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:49:15,244] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:49:15,245] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:49:15,247] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:49:15,253] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:49:15,253] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:49:15,258] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 19: {connector-consumer-jdbc-sink-0-37f6b0d8-e080-43a5-b2c0-14a7aa498914=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:49:15,262] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 19 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:49:15,265] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:49:15,274] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:49:25,158] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:49:25,159] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:49:28,450] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:49:28,451] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:49:28,457] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:49:28,457] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:49:28,459] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:49:28,459] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:49:28,459] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:49:28,460] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:49:28,460] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:49:28,460] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-37f6b0d8-e080-43a5-b2c0-14a7aa498914 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:49:28,466] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:49:28,467] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:49:28,467] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:49:28,467] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:49:28,467] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:49:28,467] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:49:28,467] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:49:28,468] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:49:28,468] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:49:28,468] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:49:28,469] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:49:28,469] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:49:28,469] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:49:44,417] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:49:44,427] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:49:44,435] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:49:44,465] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:44,830] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:44,832] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:44,833] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:44,833] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:44,834] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:44,834] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:44,835] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:45,136] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:45,136] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:45,136] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:49:45,304] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:45,305] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:45,306] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,491] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,492] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,493] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,494] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,495] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,496] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,496] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,496] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,496] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,496] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,497] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:49:46,498] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,498] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,498] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,498] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,499] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,499] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,499] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,499] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,499] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,500] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,500] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,500] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,500] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,500] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,501] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,502] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,503] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,503] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:46,503] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,503] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:46,504] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:46,504] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:46,504] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:49:46,504] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,504] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,504] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:49:46,516] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:49:46,531] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:49:46,537] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:49:46,615] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,615] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,615] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,616] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,616] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,616] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,616] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:49:46,617] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:46,617] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:46,617] INFO Kafka startTimeMs: 1596041386616 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:46,951] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:49:46,972] INFO Logging initialized @2926ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:49:47,032] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:49:47,033] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:49:47,039] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:49:47,069] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:49:47,070] INFO Started @3024ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:49:47,087] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:47,087] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:49:47,087] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:47,088] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:49:47,088] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:49:47,088] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:49:47,099] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:47,099] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:47,099] INFO Kafka startTimeMs: 1596041387098 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:47,215] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:47,217] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:47,224] INFO Kafka Connect standalone worker initialization took 2804ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:49:47,224] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:49:47,225] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:49:47,225] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:49:47,226] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:49:47,233] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:49:47,233] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:49:47,233] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:49:47,282] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:49:47,371] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:49:47,371] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:49:47,373] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:49:47,956] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:49:47,957] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:49:47,957] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:49:48,025] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:48,121] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:48,127] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:48,128] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,128] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:49:48,131] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:49:48,131] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:49:48,131] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:49:48,132] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:49:48,134] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:49:48,134] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:49:48,135] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:49:48,135] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,141] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:49:48,144] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:48,144] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = name
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,146] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:49:48,147] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:49:48,149] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:49:48,149] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:49:48,149] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:48,150] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:49:48,150] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:49:48,154] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:49:48,160] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:49:48,183] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:48,183] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:48,183] INFO Kafka startTimeMs: 1596041388183 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:48,193] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:49:48,194] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:49:48,195] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:49:48,196] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:49:48,196] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:49:48,202] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:49:48,203] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:48,203] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,203] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:49:48,204] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:49:48,204] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:49:48,205] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:49:48,205] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,206] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:49:48,207] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:49:48,208] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:49:48,208] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,208] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:49:48,209] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:49:48,209] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:49:48,209] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:49:48,210] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:49:48,210] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:49:48,210] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:49:48,211] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:49:48,211] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:49:48,212] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:49:48,219] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:49:48,220] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:49:48,228] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:49:48,228] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:49:48,230] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:49:48,241] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:49:48,241] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:49:48,242] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:320)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:245)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: Unknown field: name
	at org.apache.kafka.connect.transforms.ExtractField.apply(ExtractField.java:65)
	at org.apache.kafka.connect.runtime.TransformationChain.lambda$apply$0(TransformationChain.java:50)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 11 more
[2020-07-29 17:49:48,243] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:49:48,244] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:49:48,244] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:49:48,263] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:49:48,264] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:49:48,264] INFO Kafka startTimeMs: 1596041388263 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:49:48,269] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:49:48,270] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:49:48,270] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:49:48,271] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:49:48,274] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:49:48,275] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:49:48,300] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:49:48,301] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:49:48,303] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:49:48,310] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:49:48,311] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:49:48,315] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 21: {connector-consumer-jdbc-sink-0-92fcb563-1f2e-4485-bdef-10ab87fc5963=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:49:48,319] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 21 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:49:48,323] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:49:48,336] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:49:58,193] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:49:58,193] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:50:08,193] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:50:08,194] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:50:18,194] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:50:18,194] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:50:28,195] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:50:28,195] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:50:35,846] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:50:35,847] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:50:35,852] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:50:35,852] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:50:35,853] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:50:35,853] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:50:35,853] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:50:35,853] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:50:35,854] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:50:35,854] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-92fcb563-1f2e-4485-bdef-10ab87fc5963 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:50:35,860] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:50:35,861] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:50:35,861] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:50:35,861] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:50:35,861] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:50:35,861] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:50:35,862] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:50:35,862] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:50:35,862] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:50:35,862] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:50:35,863] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:50:35,863] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:50:35,863] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:50:37,563] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:50:37,572] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:50:37,585] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:50:37,624] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:50:37,945] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:50:37,945] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:37,945] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:37,946] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:37,946] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:37,946] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:37,947] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:50:38,132] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:50:38,133] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:38,133] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:50:38,287] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:50:38,287] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:38,288] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,225] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:50:39,225] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,225] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,225] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,225] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,225] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,226] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,227] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,228] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,229] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,230] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:50:39,230] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,230] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,231] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,232] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,232] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,232] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,232] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,232] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,233] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,234] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,235] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,235] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,235] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,235] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:50:39,235] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,236] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:50:39,236] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:50:39,236] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:50:39,236] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:50:39,236] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,237] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,237] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:50:39,249] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:50:39,250] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:50:39,256] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:50:39,310] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,310] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:50:39,311] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:50:39,311] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:50:39,311] INFO Kafka startTimeMs: 1596041439310 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:50:39,573] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:50:39,590] INFO Logging initialized @2647ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:50:39,643] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:50:39,643] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:50:39,649] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:50:39,673] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:50:39,674] INFO Started @2732ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:50:39,691] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:50:39,691] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:50:39,691] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:50:39,692] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:50:39,692] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:50:39,692] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:50:39,705] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:50:39,705] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:50:39,705] INFO Kafka startTimeMs: 1596041439704 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:50:39,824] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:50:39,825] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:50:39,831] INFO Kafka Connect standalone worker initialization took 2267ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:50:39,832] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:50:39,833] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:50:39,833] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:50:39,833] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:50:39,840] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:50:39,840] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:50:39,840] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:50:39,885] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:50:39,960] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:50:39,960] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:50:39,961] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:50:40,460] INFO Started o.e.j.s.ServletContextHandler@7af1cd63{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:50:40,460] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:50:40,460] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:50:40,480] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:50:40,569] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:50:40,574] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:50:40,575] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,575] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:50:40,577] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:50:40,578] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:50:40,578] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:50:40,579] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:50:40,581] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:50:40,582] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:50:40,583] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:50:40,583] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,587] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:50:40,589] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:50:40,590] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,592] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:50:40,592] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:50:40,593] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:50:40,594] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:50:40,594] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:50:40,594] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:50:40,594] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:50:40,598] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:50:40,604] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:50:40,624] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:50:40,624] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:50:40,624] INFO Kafka startTimeMs: 1596041440623 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:50:40,631] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:50:40,632] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:50:40,632] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:50:40,632] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:50:40,634] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:50:40,636] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:50:40,636] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:50:40,636] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,637] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:50:40,637] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:50:40,637] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:50:40,638] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:50:40,638] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,639] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:50:40,639] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:50:40,640] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:50:40,640] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,641] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:50:40,641] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:50:40,641] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:50:40,641] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:50:40,642] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:50:40,642] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:50:40,642] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:50:40,643] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:50:40,643] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:50:40,644] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:50:40,651] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:50:40,652] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:50:40,659] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:50:40,659] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:50:40,661] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:50:40,686] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:50:40,686] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:50:40,687] INFO Kafka startTimeMs: 1596041440686 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:50:40,690] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:50:40,691] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:50:40,692] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:50:40,692] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:50:40,694] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:50:40,695] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:50:40,706] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:50:40,709] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:50:40,711] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:50:40,718] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:50:40,718] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:50:40,723] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 23: {connector-consumer-jdbc-sink-0-e281a119-7a71-4e38-86b9-32f601ad3069=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:50:40,727] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 23 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:50:40,731] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:50:40,743] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:50:40,776] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:50:40,779] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 17:50:40,783] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:50:40,783] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:50:40,784] INFO Creating table with sql: CREATE TABLE "users" (
"id" INTEGER NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 17:50:40,784] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 17:50:40,785] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 17:50:40,787] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 17:50:40,787] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=false, allowsNull=false, sqlType=INTEGER}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 17:50:50,632] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:50:50,632] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:50:50,637] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:50:50,689] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=7, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 17:51:00,638] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:00,638] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:51:10,639] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:10,639] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:51:10,693] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 3: {users-0=OffsetAndMetadata{offset=8, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 17:51:20,640] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:20,640] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:51:20,642] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 17:51:30,642] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:30,643] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:51:40,643] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:40,643] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:51:50,644] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:51:50,644] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:00,645] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:00,645] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:10,646] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:10,646] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:20,647] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:20,647] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:30,648] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:30,648] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:40,648] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:40,649] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:52:50,649] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:52:50,649] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:00,650] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:00,650] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:10,651] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:10,651] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:20,651] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:20,652] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:30,652] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:30,652] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:40,653] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:40,653] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:53:50,654] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:53:50,654] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:00,655] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:00,655] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:10,655] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:10,656] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:20,656] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:20,657] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:30,657] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:30,657] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:40,658] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:40,658] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:54:50,659] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:54:50,659] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:00,660] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:00,660] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:10,660] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:10,661] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:20,661] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:20,661] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:30,662] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:30,662] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:40,663] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:40,663] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:47,528] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:55:47,528] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:55:47,532] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:55:47,532] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:55:47,533] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:55:47,533] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:55:47,533] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:55:47,534] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:55:47,534] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:55:47,534] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:55:47,534] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-e281a119-7a71-4e38-86b9-32f601ad3069 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:55:47,540] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:55:47,541] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:55:47,541] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:55:47,542] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:55:47,609] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:55:47,609] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:55:47,610] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:55:47,610] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:55:47,610] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:55:47,612] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:55:47,613] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:55:47,613] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:55:47,613] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:55:47,613] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:55:47,613] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:55:47,614] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:55:47,614] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:55:47,614] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:55:47,615] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:55:49,203] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:55:49,209] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:55:49,214] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:55:49,234] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:55:49,543] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:55:49,544] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,544] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,545] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,545] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,545] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,546] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:55:49,753] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:55:49,753] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,754] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:55:49,902] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:55:49,902] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:49,903] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,862] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,863] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,864] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,865] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,866] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,867] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,867] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:55:50,867] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,867] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,868] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,869] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,870] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,871] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:55:50,872] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,872] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:55:50,872] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:55:50,873] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:55:50,873] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:55:50,873] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,873] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,873] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:55:50,885] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:55:50,886] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:55:50,889] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:55:50,937] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,938] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:55:50,939] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:55:50,939] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:55:50,939] INFO Kafka startTimeMs: 1596041750938 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:55:51,183] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:55:51,202] INFO Logging initialized @2326ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:55:51,258] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:55:51,259] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:55:51,266] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:55:51,292] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:55:51,293] INFO Started @2416ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:55:51,310] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:55:51,310] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:55:51,310] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:55:51,311] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:55:51,311] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:55:51,311] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:55:51,322] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:55:51,322] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:55:51,322] INFO Kafka startTimeMs: 1596041751322 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:55:51,431] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:55:51,433] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:55:51,442] INFO Kafka Connect standalone worker initialization took 2237ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:55:51,443] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:55:51,444] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:55:51,444] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:55:51,445] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:55:51,451] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:55:51,452] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:55:51,452] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:55:51,499] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:55:51,572] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:55:51,572] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:55:51,573] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:55:52,102] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:55:52,102] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:55:52,102] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:55:52,121] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:55:52,216] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:55:52,223] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:55:52,224] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,224] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:55:52,226] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:55:52,227] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:55:52,227] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:55:52,228] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:55:52,229] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:55:52,230] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:55:52,231] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:55:52,231] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,236] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:55:52,238] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:55:52,239] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,241] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:55:52,242] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:55:52,243] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:55:52,243] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:55:52,243] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:55:52,243] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:55:52,244] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:55:52,249] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:55:52,254] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:55:52,274] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:55:52,274] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:55:52,275] INFO Kafka startTimeMs: 1596041752274 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:55:52,282] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:55:52,283] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:55:52,283] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:55:52,285] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:55:52,285] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:55:52,289] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:55:52,290] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:55:52,290] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,290] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:55:52,291] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:55:52,291] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:55:52,291] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:55:52,292] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,293] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:55:52,293] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:55:52,294] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:55:52,294] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,295] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:55:52,295] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:55:52,295] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:55:52,295] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:55:52,296] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:55:52,296] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:55:52,297] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:55:52,298] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:55:52,299] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:55:52,299] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:55:52,306] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:55:52,315] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:55:52,322] INFO Found offset {{table=users}=null, {protocol=1, table=users}={incrementing=4}} for partition {protocol=1, table=users} (io.confluent.connect.jdbc.source.JdbcSourceTask:189)
[2020-07-29 17:55:52,325] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:55:52,325] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:55:52,326] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:55:52,344] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:55:52,344] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:55:52,344] INFO Kafka startTimeMs: 1596041752344 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:55:52,349] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:55:52,351] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:55:52,351] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:55:52,351] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:55:52,353] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:55:52,354] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:55:52,373] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:55:52,373] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:55:52,375] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:55:52,383] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:55:52,383] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:55:52,387] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 25: {connector-consumer-jdbc-sink-0-b3840617-3f99-487c-b659-d53d87fcfa6c=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:55:52,390] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 25 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:55:52,392] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:55:52,404] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:56:02,282] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:02,283] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:12,283] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:12,284] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:22,284] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:22,284] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:32,285] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:32,285] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:42,286] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:42,286] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:52,286] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:52,287] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:58,434] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:56:58,434] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:56:58,440] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:56:58,440] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:56:58,443] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:56:58,443] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:56:58,444] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:56:58,444] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:56:58,445] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:56:58,445] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-b3840617-3f99-487c-b659-d53d87fcfa6c sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:56:58,451] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:56:58,451] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:56:58,451] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:56:58,451] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:56:58,544] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:56:58,544] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:56:58,544] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:56:58,544] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:56:58,545] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:56:58,547] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:56:58,547] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:56:58,548] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:56:58,548] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:56:58,548] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:56:58,548] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:56:58,549] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:56:58,549] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:56:58,550] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:56:58,550] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:56:59,882] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:56:59,888] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:56:59,893] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:56:59,913] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:57:00,226] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:57:00,227] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,228] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,228] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,228] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,228] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,229] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:57:00,446] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:57:00,446] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,447] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:57:00,594] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:57:00,594] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:00,595] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,493] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:57:01,493] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,493] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,494] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,494] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,495] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,495] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,495] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,495] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,495] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,496] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,497] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,498] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,499] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,499] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,499] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,499] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,499] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,500] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,501] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,501] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:57:01,502] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,502] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,502] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,503] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,503] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,503] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,504] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,505] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,506] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:57:01,507] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,507] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:57:01,508] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:57:01,508] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:57:01,508] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:57:01,508] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,508] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,508] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:57:01,520] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:57:01,521] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:57:01,525] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:57:01,575] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,576] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:57:01,577] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:57:01,577] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:57:01,577] INFO Kafka startTimeMs: 1596041821576 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:57:01,819] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:57:01,838] INFO Logging initialized @2276ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:57:01,885] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:57:01,886] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:57:01,892] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:57:01,923] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:57:01,923] INFO Started @2361ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:57:01,943] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:57:01,943] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:57:01,944] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:57:01,944] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:57:01,944] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:57:01,944] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:57:01,953] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:57:01,953] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:57:01,953] INFO Kafka startTimeMs: 1596041821953 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:57:02,072] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:57:02,073] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:57:02,080] INFO Kafka Connect standalone worker initialization took 2196ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:57:02,081] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:57:02,082] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:57:02,082] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:57:02,083] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:57:02,089] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:57:02,089] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:57:02,089] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:57:02,135] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:57:02,220] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:57:02,220] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:57:02,222] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:57:02,723] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:57:02,723] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:57:02,723] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:57:02,744] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:57:02,831] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:57:02,836] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:57:02,837] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,838] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:57:02,841] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:57:02,842] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:57:02,842] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:57:02,843] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:57:02,845] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:57:02,845] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:57:02,846] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:57:02,846] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,850] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:57:02,852] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:57:02,853] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,854] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:57:02,855] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:57:02,856] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:57:02,856] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:57:02,856] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:57:02,857] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:57:02,857] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:57:02,861] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:57:02,867] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:57:02,888] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:57:02,888] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:57:02,888] INFO Kafka startTimeMs: 1596041822888 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:57:02,896] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:57:02,897] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:57:02,897] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:57:02,897] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:57:02,899] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:57:02,905] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:57:02,906] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:57:02,906] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,906] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:57:02,906] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:57:02,907] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:57:02,907] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:57:02,907] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,908] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:57:02,908] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:57:02,909] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:57:02,909] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,910] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:57:02,910] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:57:02,910] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:57:02,910] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:57:02,911] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:57:02,911] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:57:02,911] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:57:02,912] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:57:02,912] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:57:02,913] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:57:02,920] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:57:02,941] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:57:02,947] INFO Found offset {{table=users}=null, {protocol=1, table=users}={incrementing=4}} for partition {protocol=1, table=users} (io.confluent.connect.jdbc.source.JdbcSourceTask:189)
[2020-07-29 17:57:02,949] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 17:57:02,949] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 17:57:02,950] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 17:57:02,957] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:57:02,958] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:57:02,958] INFO Kafka startTimeMs: 1596041822957 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:57:02,963] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:57:02,964] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:57:02,964] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:57:02,964] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:57:02,967] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:57:02,968] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:57:02,984] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:57:02,985] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:57:02,987] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:57:02,993] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:57:02,994] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:57:02,999] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 27: {connector-consumer-jdbc-sink-0-135ca0e4-2c26-4da4-ae5d-a1b598f016ec=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:57:03,003] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 27 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:57:03,006] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:57:03,015] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:57:12,896] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:57:12,897] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:57:22,897] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:57:22,898] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:57:32,898] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:57:32,898] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:57:42,899] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:57:42,899] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:57:52,900] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:57:52,900] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:02,901] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:02,901] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:12,902] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:12,902] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:22,903] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:22,903] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:32,904] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:32,904] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:42,905] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:42,905] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:58:52,905] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:58:52,906] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:02,906] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:59:02,906] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:12,907] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:59:12,907] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:22,555] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:59:22,555] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:59:22,560] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:59:22,560] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:59:22,561] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:59:22,561] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:59:22,562] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:59:22,562] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:59:22,563] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:59:22,563] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-135ca0e4-2c26-4da4-ae5d-a1b598f016ec sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:59:22,569] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:59:22,569] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:59:22,570] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:59:22,570] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:59:22,587] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 17:59:22,587] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:59:22,587] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:59:22,587] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:22,587] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:59:22,589] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:59:22,590] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:59:22,590] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:59:22,590] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:59:22,590] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:59:22,591] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:59:22,591] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:59:22,591] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:59:22,592] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:59:22,592] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 17:59:24,263] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 17:59:24,269] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 17:59:24,274] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 17:59:24,299] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:59:24,625] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:59:24,625] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,626] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,626] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,626] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,626] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,627] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:59:24,842] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:59:24,842] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,843] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 17:59:24,980] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:59:24,981] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:24,982] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,939] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 17:59:25,939] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,939] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,939] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,939] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,939] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,940] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,941] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,941] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,941] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,941] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,941] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,942] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,943] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,944] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,944] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,944] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,944] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,944] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,945] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,945] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,945] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,945] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,945] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,946] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,946] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,946] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,946] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 17:59:25,947] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,947] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,948] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,949] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,950] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,951] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,952] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,952] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,952] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,952] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,952] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:59:25,952] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,953] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:59:25,953] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:59:25,953] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:59:25,953] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 17:59:25,954] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,954] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,954] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 17:59:25,967] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 17:59:25,967] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 17:59:25,972] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 17:59:26,026] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,027] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,027] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,027] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,027] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,027] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,028] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 17:59:26,028] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:59:26,028] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:59:26,028] INFO Kafka startTimeMs: 1596041966028 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:59:26,261] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 17:59:26,276] INFO Logging initialized @2330ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 17:59:26,329] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 17:59:26,329] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 17:59:26,336] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 17:59:26,369] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 17:59:26,369] INFO Started @2423ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 17:59:26,392] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:59:26,393] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 17:59:26,393] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:59:26,393] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 17:59:26,393] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 17:59:26,394] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 17:59:26,405] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:59:26,405] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:59:26,405] INFO Kafka startTimeMs: 1596041966405 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:59:26,520] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:59:26,522] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:59:26,531] INFO Kafka Connect standalone worker initialization took 2266ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 17:59:26,531] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 17:59:26,533] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 17:59:26,533] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 17:59:26,533] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 17:59:26,540] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 17:59:26,541] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 17:59:26,541] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 17:59:26,582] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 17:59:26,653] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 17:59:26,653] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 17:59:26,655] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 17:59:27,185] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 17:59:27,185] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 17:59:27,185] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 17:59:27,204] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:59:27,292] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:59:27,299] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:59:27,300] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,300] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:59:27,303] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:59:27,303] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 17:59:27,304] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 17:59:27,304] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:59:27,306] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 17:59:27,306] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:59:27,307] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 17:59:27,308] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,313] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:59:27,315] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:59:27,316] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,318] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:59:27,319] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:59:27,320] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:59:27,321] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:59:27,321] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:59:27,321] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:59:27,321] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:59:27,325] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 17:59:27,330] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 17:59:27,353] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:59:27,353] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:59:27,353] INFO Kafka startTimeMs: 1596041967352 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:59:27,359] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 17:59:27,360] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 17:59:27,360] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 17:59:27,362] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:59:27,363] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:59:27,368] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 17:59:27,369] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:59:27,369] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,370] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 17:59:27,370] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 17:59:27,371] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 17:59:27,371] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:59:27,371] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,372] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 17:59:27,372] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 17:59:27,373] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 17:59:27,374] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,374] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 17:59:27,374] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 17:59:27,375] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 17:59:27,375] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 17:59:27,375] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 17:59:27,375] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 17:59:27,376] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 17:59:27,377] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 17:59:27,378] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 17:59:27,378] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 17:59:27,386] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 17:59:27,401] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 17:59:27,407] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:59:27,408] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:27,408] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Cannot make incremental queries using timestamp columns [modified] on "users" because all of these columns nullable.
	at io.confluent.connect.jdbc.source.JdbcSourceTask.validateNonNullable(JdbcSourceTask.java:460)
	at io.confluent.connect.jdbc.source.JdbcSourceTask.start(JdbcSourceTask.java:161)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:213)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 17:59:27,411] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 17:59:27,411] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 17:59:27,411] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 17:59:27,428] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 17:59:27,428] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 17:59:27,428] INFO Kafka startTimeMs: 1596041967428 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 17:59:27,434] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 17:59:27,435] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 17:59:27,435] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 17:59:27,436] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 17:59:27,439] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 17:59:27,439] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 17:59:27,455] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 17:59:27,456] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 17:59:27,458] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:59:27,468] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 17:59:27,468] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 17:59:27,472] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 29: {connector-consumer-jdbc-sink-0-08b97d0a-c087-49ba-a472-0ec7d76c0284=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 17:59:27,475] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 29 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 17:59:27,479] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 17:59:27,491] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 17:59:37,360] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 17:59:37,360] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 17:59:43,235] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 17:59:43,235] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 17:59:43,243] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 17:59:43,243] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 17:59:43,244] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 17:59:43,244] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 17:59:43,245] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:59:43,245] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 17:59:43,245] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 17:59:43,246] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-08b97d0a-c087-49ba-a472-0ec7d76c0284 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 17:59:43,252] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:59:43,253] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:59:43,253] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 17:59:43,254] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 17:59:43,254] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 17:59:43,254] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 17:59:43,254] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 17:59:43,254] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 17:59:43,255] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 17:59:43,255] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 17:59:43,255] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 17:59:43,256] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 17:59:43,256] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)

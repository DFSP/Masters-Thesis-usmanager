[2020-07-29 18:16:23,067] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:16:23,074] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:16:23,079] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:16:23,102] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:16:23,410] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:16:23,410] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,411] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,411] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,411] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,411] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,412] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:16:23,620] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:16:23,620] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,620] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:16:23,772] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:16:23,773] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:23,774] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,705] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,706] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,707] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,707] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,707] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,707] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,707] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,708] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,709] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,710] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,711] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,712] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:16:24,713] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,713] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,713] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,713] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,714] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,715] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,716] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,717] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:16:24,717] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,718] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:16:24,718] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:16:24,718] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:16:24,719] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:16:24,719] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,719] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,719] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:16:24,732] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:16:24,733] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:16:24,737] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:16:24,791] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:16:24,792] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:16:24,792] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:16:24,793] INFO Kafka startTimeMs: 1596042984792 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:16:25,040] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:16:25,062] INFO Logging initialized @2309ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:16:25,117] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:16:25,117] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:16:25,124] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:16:25,150] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:16:25,151] INFO Started @2398ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:16:25,171] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:16:25,171] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:16:25,171] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:16:25,171] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:16:25,171] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:16:25,172] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:16:25,179] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:16:25,180] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:16:25,180] INFO Kafka startTimeMs: 1596042985179 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:16:25,301] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:16:25,302] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:16:25,310] INFO Kafka Connect standalone worker initialization took 2240ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:16:25,310] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:16:25,311] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:16:25,311] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:16:25,312] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:16:25,318] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:16:25,318] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:16:25,318] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:16:25,361] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:16:25,443] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:16:25,443] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:16:25,445] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:16:25,989] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:16:25,989] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:16:25,989] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:16:26,008] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:16:26,106] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:16:26,114] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:16:26,115] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,115] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:16:26,117] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:16:26,118] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:16:26,118] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:16:26,119] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:16:26,121] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:16:26,121] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:16:26,122] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:16:26,123] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,127] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:16:26,130] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:16:26,130] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,132] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:16:26,132] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:16:26,134] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:16:26,134] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:16:26,134] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:16:26,134] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:16:26,134] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:16:26,138] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:16:26,145] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:16:26,169] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:16:26,169] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:16:26,169] INFO Kafka startTimeMs: 1596042986169 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:16:26,179] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:16:26,179] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:16:26,179] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = timestamp+incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = [modified]
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:16:26,180] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:16:26,180] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:16:26,186] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:16:26,187] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:16:26,187] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,188] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:16:26,189] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:16:26,189] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:16:26,189] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:16:26,189] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,190] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:16:26,191] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:16:26,192] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:16:26,192] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,193] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:16:26,193] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:16:26,193] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:16:26,194] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:16:26,194] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:16:26,194] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:16:26,194] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:16:26,195] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:16:26,196] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:16:26,196] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:16:26,202] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:16:26,214] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:16:26,220] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:16:26,220] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:16:26,221] ERROR WorkerSourceTask{id=jdbc-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Cannot make incremental queries using timestamp columns [modified] on "users" because all of these columns nullable.
	at io.confluent.connect.jdbc.source.JdbcSourceTask.validateNonNullable(JdbcSourceTask.java:460)
	at io.confluent.connect.jdbc.source.JdbcSourceTask.start(JdbcSourceTask.java:161)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:213)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 18:16:26,223] ERROR WorkerSourceTask{id=jdbc-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 18:16:26,223] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:16:26,223] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:16:26,238] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:16:26,238] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:16:26,238] INFO Kafka startTimeMs: 1596042986238 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:16:26,243] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:16:26,244] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:16:26,244] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:16:26,244] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:16:26,248] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:16:26,249] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:16:26,264] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:16:26,265] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:16:26,267] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:16:26,276] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:16:26,276] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:16:26,280] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 31: {connector-consumer-jdbc-sink-0-d32026aa-f903-443f-92e9-7d8d794a036f=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:16:26,284] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 31 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:16:26,287] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:16:26,298] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:16:36,179] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:16:36,179] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:16:46,179] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:16:46,179] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:16:56,180] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:16:56,180] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:06,181] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:17:06,181] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:16,182] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:17:16,182] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:26,182] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:17:26,182] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:36,183] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:17:36,183] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:46,183] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:17:46,184] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:17:55,457] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:17:55,457] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:17:55,462] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:17:55,463] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:17:55,464] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:17:55,464] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:17:55,464] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:17:55,465] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:17:55,465] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:17:55,466] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-d32026aa-f903-443f-92e9-7d8d794a036f sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:17:55,473] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:17:55,474] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:17:55,474] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:17:55,474] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:17:55,474] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:17:55,474] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:17:55,475] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:17:55,475] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:17:55,475] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:17:55,475] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:17:55,475] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:17:55,476] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:17:55,476] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:17:57,013] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:17:57,018] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:17:57,023] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:17:57,046] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:17:57,338] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:17:57,339] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,339] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,339] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,340] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,340] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,341] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:17:57,560] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:17:57,560] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,561] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:17:57,683] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:17:57,683] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:57,684] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,571] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:17:58,571] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,571] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,571] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,571] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,572] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,573] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,574] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,575] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:17:58,576] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,576] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,576] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,576] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,576] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,577] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,578] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:17:58,579] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,579] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:17:58,580] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:17:58,580] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:17:58,580] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:17:58,580] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,580] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,580] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:17:58,592] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:17:58,593] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:17:58,596] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:17:58,647] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,648] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:17:58,649] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:17:58,649] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:17:58,649] INFO Kafka startTimeMs: 1596043078648 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:17:58,886] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:17:58,903] INFO Logging initialized @2190ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:17:58,960] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:17:58,960] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:17:58,966] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:17:58,990] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:17:58,990] INFO Started @2278ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:17:59,013] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:17:59,014] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:17:59,014] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:17:59,014] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:17:59,014] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:17:59,015] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:17:59,028] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:17:59,028] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:17:59,029] INFO Kafka startTimeMs: 1596043079028 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:17:59,139] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:17:59,141] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:17:59,147] INFO Kafka Connect standalone worker initialization took 2133ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:17:59,148] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:17:59,148] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:17:59,149] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:17:59,149] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:17:59,156] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:17:59,157] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:17:59,157] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:17:59,202] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:17:59,274] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:17:59,274] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:17:59,275] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:17:59,745] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:17:59,746] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:17:59,746] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:17:59,779] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:17:59,877] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:17:59,884] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:17:59,885] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,885] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:17:59,887] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:17:59,888] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:17:59,888] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:17:59,889] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:17:59,891] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:17:59,891] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:17:59,892] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:17:59,893] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,896] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:17:59,899] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:17:59,900] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,901] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:17:59,902] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:17:59,904] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:17:59,904] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:17:59,904] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:17:59,904] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:17:59,905] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:17:59,911] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:17:59,918] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:17:59,940] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:17:59,940] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:17:59,940] INFO Kafka startTimeMs: 1596043079940 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:17:59,948] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:17:59,948] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:17:59,949] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:17:59,949] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:17:59,951] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:17:59,954] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:17:59,954] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:17:59,954] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,954] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:17:59,955] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:17:59,955] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:17:59,956] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:17:59,956] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,956] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:17:59,958] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:17:59,958] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:17:59,959] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,960] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:17:59,960] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:17:59,960] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:17:59,961] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:17:59,961] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:17:59,961] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:17:59,961] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:17:59,962] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:17:59,963] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:17:59,963] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:17:59,971] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:17:59,983] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:17:59,990] INFO Found offset {{table=users}=null, {protocol=1, table=users}={incrementing=4}} for partition {protocol=1, table=users} (io.confluent.connect.jdbc.source.JdbcSourceTask:189)
[2020-07-29 18:17:59,992] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:17:59,992] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:17:59,993] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:18:00,010] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:18:00,011] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:18:00,011] INFO Kafka startTimeMs: 1596043080010 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:18:00,018] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:18:00,019] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:18:00,019] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:18:00,019] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:18:00,022] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:18:00,023] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:18:00,040] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:18:00,041] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:18:00,042] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:18:00,051] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:18:00,051] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:18:00,055] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 33: {connector-consumer-jdbc-sink-0-e5ac420a-6e12-4992-894f-1f2851426d24=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:18:00,060] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 33 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:18:00,063] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:18:00,074] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:18:09,948] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:09,948] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:19,949] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:19,949] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:29,950] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:29,950] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:39,950] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:39,951] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:49,951] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:49,952] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:55,040] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:18:55,041] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:18:55,046] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: [] (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 18:18:55,048] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 18:18:55,049] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 18:18:55,049] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:18:55,049] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:18:55,049] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:18:55,050] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-e5ac420a-6e12-4992-894f-1f2851426d24 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:18:59,952] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:18:59,952] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:18:59,957] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:19:09,957] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:09,958] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:19:19,958] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:19,959] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:19:29,959] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:29,959] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:19:39,960] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:39,960] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:19:49,961] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:49,962] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:19:59,962] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:19:59,962] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:09,963] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:09,964] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:19,964] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:19,965] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:29,965] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:29,966] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:39,966] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:39,966] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:49,967] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:49,967] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:20:59,968] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:20:59,968] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:09,969] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:09,969] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:19,969] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:19,970] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:29,970] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:29,971] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:39,971] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:39,971] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:49,972] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:49,972] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:21:59,973] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:21:59,973] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:09,973] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:09,974] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:19,975] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:19,975] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:29,975] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:29,976] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:39,976] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:39,976] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:49,977] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:49,977] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:22:59,978] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:22:59,978] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:23:09,978] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:23:09,978] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:23:17,525] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:23:17,525] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:23:17,531] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:23:17,531] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:23:17,532] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:23:17,533] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:23:17,533] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:23:17,534] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:23:17,534] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:23:17,535] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:23:17,535] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:23:17,554] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 18:23:17,554] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:23:17,555] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:23:17,555] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:23:17,555] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:23:17,557] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:23:17,558] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:23:17,558] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:23:17,558] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:23:17,558] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:23:17,559] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:23:17,559] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:23:17,559] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:23:17,560] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:23:17,560] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:23:19,141] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:23:19,148] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:23:19,152] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:23:19,176] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:23:19,598] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:23:19,599] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,600] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,600] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,600] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,600] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,602] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:23:19,898] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:23:19,899] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:19,899] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:23:20,077] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:23:20,078] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:20,079] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,246] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:23:21,246] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,246] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,246] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,247] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,248] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,249] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,250] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,251] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,252] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,252] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,252] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,252] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:23:21,253] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,253] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,254] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,254] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,254] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,255] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,255] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,255] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,255] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,255] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,256] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,256] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,256] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,256] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,256] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,257] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,258] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,259] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,259] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,259] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,259] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,259] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:23:21,259] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,260] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:23:21,260] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:23:21,260] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:23:21,260] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:23:21,260] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,260] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,260] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:23:21,275] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:23:21,276] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:23:21,280] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:23:21,331] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,332] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:23:21,333] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:23:21,333] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:23:21,333] INFO Kafka startTimeMs: 1596043401332 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:23:21,613] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:23:21,635] INFO Logging initialized @2809ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:23:21,709] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:23:21,710] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:23:21,722] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:23:21,758] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:23:21,758] INFO Started @2932ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:23:21,787] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:23:21,788] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:23:21,788] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:23:21,788] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:23:21,788] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:23:21,789] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:23:21,804] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:23:21,805] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:23:21,805] INFO Kafka startTimeMs: 1596043401804 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:23:21,968] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:23:21,971] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:23:21,983] INFO Kafka Connect standalone worker initialization took 2840ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:23:21,983] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:23:21,984] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:23:21,984] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:23:21,985] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:23:21,992] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:23:21,992] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:23:21,993] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:23:22,047] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:23:22,142] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:23:22,142] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:23:22,144] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:23:22,800] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:23:22,800] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:23:22,800] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:23:22,824] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:23:22,936] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:23:22,943] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:23:22,944] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:22,944] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:23:22,947] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:23:22,948] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:23:22,949] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:23:22,950] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:23:22,952] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:23:22,952] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:23:22,953] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:23:22,954] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:22,960] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:23:22,963] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:23:22,964] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:22,966] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:23:22,966] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:23:22,968] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:23:22,968] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:23:22,968] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:23:22,968] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:23:22,969] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:23:22,972] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:23:22,980] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:23:23,007] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:23:23,007] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:23:23,007] INFO Kafka startTimeMs: 1596043403006 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:23:23,017] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:23:23,017] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:23:23,018] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:23:23,018] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:23:23,019] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:23:23,023] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:23:23,024] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:23:23,024] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:23,024] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:23:23,026] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:23:23,026] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:23:23,027] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:23:23,027] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:23,028] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:23:23,028] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:23:23,029] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:23:23,030] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:23,031] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:23:23,031] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:23:23,032] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:23:23,032] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:23:23,033] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:23:23,033] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:23:23,033] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:23:23,034] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:23:23,035] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:23:23,035] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:23:23,043] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:23:23,060] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:23:23,069] INFO Found offset {{table=users}=null, {protocol=1, table=users}={incrementing=6}} for partition {protocol=1, table=users} (io.confluent.connect.jdbc.source.JdbcSourceTask:189)
[2020-07-29 18:23:23,071] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:23:23,072] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:23:23,073] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:23:23,092] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:23:23,092] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:23:23,093] INFO Kafka startTimeMs: 1596043403092 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:23:23,097] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:23:23,099] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:23:23,099] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:23:23,099] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:23:23,102] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:23:23,102] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:23:23,123] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:23:23,124] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:23:23,127] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:23:23,134] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:23:23,135] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:23:23,138] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 35: {connector-consumer-jdbc-sink-0-404030d3-23f8-4dad-909c-343c2340fc92=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:23:23,142] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 35 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:23:23,146] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:23:23,156] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:23:23,191] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:23:23,191] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:23:23,196] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: [] (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 18:23:23,198] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 18:23:23,199] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 18:23:23,199] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:23:23,199] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:23:23,200] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:23:23,200] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-404030d3-23f8-4dad-909c-343c2340fc92 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:23:33,017] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:23:33,018] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:23:43,019] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:23:43,019] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:23:53,020] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:23:53,021] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:03,021] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:03,022] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:06,210] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:24:06,210] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:24:06,223] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:24:06,224] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:24:06,227] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:24:06,227] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:24:06,228] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:24:06,232] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:24:06,233] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:24:06,233] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:24:06,234] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:24:06,297] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 18:24:06,298] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:24:06,299] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:06,299] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:06,300] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:24:06,308] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:24:06,309] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:24:06,309] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:24:06,310] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:24:06,311] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:24:06,311] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:24:06,312] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:24:06,313] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:24:06,314] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:24:06,315] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:24:09,376] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:24:09,397] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:24:09,416] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:24:09,508] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:24:10,748] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:24:10,751] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:10,752] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:10,753] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:10,754] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:10,755] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:10,759] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:24:11,250] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:24:11,250] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:11,251] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:24:11,420] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:24:11,421] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:11,423] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,819] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:24:12,820] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,820] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,820] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,820] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,821] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,821] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,823] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,823] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,823] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,824] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,824] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,824] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,825] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,825] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,825] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,825] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,826] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,826] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,826] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,827] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,828] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,829] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,829] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,829] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,829] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,829] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,830] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,830] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,830] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,831] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:24:12,832] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,833] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,833] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,834] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,834] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,834] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,834] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,835] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,835] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,835] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,835] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,836] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,836] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,836] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,836] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,837] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,838] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,838] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,838] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,838] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,838] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,839] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,839] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,839] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,839] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,839] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,840] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:24:12,840] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,840] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:24:12,841] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:24:12,841] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:24:12,841] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:24:12,842] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,842] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,842] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:24:12,863] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:24:12,864] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:24:12,870] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:24:12,976] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,977] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:24:12,978] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:24:12,978] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:24:12,978] INFO Kafka startTimeMs: 1596043452977 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:24:13,428] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:24:13,449] INFO Logging initialized @5266ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:24:13,500] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:24:13,500] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:24:13,510] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:24:13,536] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:24:13,537] INFO Started @5354ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:24:13,554] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:24:13,555] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:24:13,555] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:24:13,555] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:24:13,556] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:24:13,556] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:24:13,570] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:24:13,571] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:24:13,571] INFO Kafka startTimeMs: 1596043453570 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:24:13,700] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:24:13,701] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:24:13,708] INFO Kafka Connect standalone worker initialization took 4326ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:24:13,708] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:24:13,709] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:24:13,710] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:24:13,710] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:24:13,716] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:24:13,717] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:24:13,717] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:24:13,763] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:24:13,840] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:24:13,840] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:24:13,841] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:24:14,599] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:24:14,599] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:24:14,599] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:24:14,623] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:24:14,696] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:24:14,705] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:24:14,706] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,706] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:24:14,709] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:24:14,710] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:24:14,710] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:24:14,711] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:24:14,713] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:24:14,713] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:24:14,714] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:24:14,714] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,720] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:24:14,722] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:24:14,723] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,724] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:24:14,726] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:24:14,727] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:24:14,727] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:24:14,728] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:24:14,728] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:24:14,728] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:24:14,732] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:24:14,738] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:24:14,759] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:24:14,759] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:24:14,759] INFO Kafka startTimeMs: 1596043454759 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:24:14,771] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:24:14,771] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:24:14,777] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:24:14,777] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:24:14,777] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:24:14,778] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:24:14,782] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:24:14,783] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:24:14,783] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,783] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:24:14,784] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:24:14,784] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:24:14,785] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:24:14,785] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,787] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:24:14,787] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:24:14,788] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:24:14,788] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:24:14,787] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:24:14,791] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:24:14,791] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,792] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:24:14,792] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:24:14,792] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:24:14,793] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:24:14,793] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:24:14,793] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:24:14,793] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:24:14,794] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:24:14,794] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:24:14,795] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:24:14,841] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:24:14,919] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:24:14,919] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:24:14,919] INFO Kafka startTimeMs: 1596043454919 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:24:14,923] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:24:14,937] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:24:14,938] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:24:14,939] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = []
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:24:14,942] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:24:14,942] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:24:14,959] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:24:14,961] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:24:14,963] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:24:14,973] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:24:14,974] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:24:14,979] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 37: {connector-consumer-jdbc-sink-0-084cb6c2-3880-4030-8954-8553f8a45080=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:24:14,984] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 37 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:24:14,989] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:24:15,003] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:24:15,046] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:24:15,047] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:24:15,053] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: [] (org.apache.kafka.connect.runtime.WorkerSinkTask:566)
org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 18:24:15,056] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:568)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.ConnectException: Need exactly one PK column defined since the key schema for records is a primitive type, defined columns are: []
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extractRecordKeyPk(FieldsMetadata.java:219)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:100)
	at io.confluent.connect.jdbc.sink.metadata.FieldsMetadata.extract(FieldsMetadata.java:66)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:116)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:66)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	... 10 more
[2020-07-29 18:24:15,057] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 18:24:15,057] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:24:15,057] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:24:15,057] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:24:15,058] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-084cb6c2-3880-4030-8954-8553f8a45080 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:24:24,771] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:24,773] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:24,783] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 10 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:24:34,784] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:34,784] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:34,785] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:24:44,786] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:44,786] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:44,788] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:24:54,789] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:24:54,790] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:24:54,792] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:04,792] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:04,793] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:04,794] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:14,794] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:14,795] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:14,797] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:24,798] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:24,798] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:24,801] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:34,802] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:34,803] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:34,806] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:44,806] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:44,807] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:44,808] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:25:54,808] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:25:54,809] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:25:54,811] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:04,812] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:04,813] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:04,819] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:14,820] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:14,820] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:14,823] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:24,824] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:24,824] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:24,826] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:34,827] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:34,828] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:34,830] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:44,830] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:44,831] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:44,831] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:26:54,832] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:26:54,832] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:26:54,835] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:04,836] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:04,837] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:04,839] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:14,839] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:14,840] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:14,842] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:19,701] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:27:19,702] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:27:19,712] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:27:19,712] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:27:19,713] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:27:19,714] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:27:19,714] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:27:19,715] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:27:19,716] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:27:19,716] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:27:19,716] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:27:19,718] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 18:27:19,718] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:27:19,718] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:19,718] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:19,719] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:19,719] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:27:19,722] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:27:19,722] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:27:19,722] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:27:19,724] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:27:19,725] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:27:19,725] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:27:19,725] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:27:19,726] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:27:19,726] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:27:19,726] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:27:21,905] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:27:21,914] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:27:21,925] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:27:21,955] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:27:22,255] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:27:22,256] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,256] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,256] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,257] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,257] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,258] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:27:22,457] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:27:22,457] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,458] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:27:22,608] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:27:22,608] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:22,609] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,458] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:27:23,458] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,458] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,459] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,460] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,461] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,462] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,463] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,463] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:27:23,463] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,464] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,465] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,466] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,467] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:27:23,467] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,468] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:27:23,468] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:27:23,468] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:27:23,468] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:27:23,468] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,468] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,468] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:27:23,479] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:27:23,480] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:27:23,483] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:27:23,527] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,527] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,527] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,527] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,527] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,528] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,528] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:27:23,528] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:27:23,528] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:27:23,528] INFO Kafka startTimeMs: 1596043643528 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:27:23,752] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:27:23,772] INFO Logging initialized @2388ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:27:23,824] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:27:23,824] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:27:23,833] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:27:23,861] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:27:23,862] INFO Started @2477ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:27:23,882] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:27:23,882] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:27:23,882] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:27:23,883] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:27:23,883] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:27:23,883] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:27:23,894] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:27:23,894] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:27:23,894] INFO Kafka startTimeMs: 1596043643893 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:27:24,008] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:27:24,009] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:27:24,017] INFO Kafka Connect standalone worker initialization took 2110ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:27:24,017] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:27:24,018] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:27:24,018] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:27:24,019] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:27:24,024] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:27:24,025] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:27:24,025] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:27:24,063] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:27:24,130] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:27:24,130] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:27:24,131] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:27:24,631] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:27:24,632] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:27:24,632] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:27:24,651] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:27:24,735] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:27:24,740] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:27:24,741] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,741] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:27:24,744] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:27:24,744] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:27:24,744] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:27:24,745] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:27:24,747] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:27:24,748] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:27:24,748] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:27:24,749] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,752] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:27:24,754] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:27:24,755] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,756] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:27:24,757] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:27:24,759] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:27:24,759] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:27:24,759] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:27:24,759] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:27:24,760] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:27:24,764] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:27:24,769] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:27:24,791] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:27:24,792] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:27:24,792] INFO Kafka startTimeMs: 1596043644791 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:27:24,800] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:27:24,801] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:27:24,801] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:27:24,802] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:27:24,802] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:27:24,803] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:27:24,808] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:27:24,808] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:27:24,809] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,809] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:27:24,810] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:27:24,810] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:27:24,810] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:27:24,810] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:27:24,810] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:27:24,811] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,811] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:27:24,811] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:27:24,811] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:27:24,812] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:27:24,812] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,813] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:27:24,813] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:27:24,813] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:27:24,813] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:27:24,813] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:27:24,813] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:27:24,813] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:27:24,814] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:27:24,814] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:27:24,815] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:27:24,821] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:27:24,858] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:27:24,858] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:27:24,858] INFO Kafka startTimeMs: 1596043644858 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:27:24,863] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:27:24,864] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:27:24,864] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:27:24,865] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:27:24,867] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:27:24,868] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:27:24,878] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:27:24,878] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:27:24,880] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:27:24,887] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:27:24,887] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:27:24,892] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 39: {connector-consumer-jdbc-sink-0-bd935a82-c8ab-4525-9aa6-4d6c6a7ce757=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:27:24,895] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 39 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:27:24,898] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:27:24,906] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:27:24,967] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:27:24,968] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:27:24,972] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 18:27:24,972] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 18:27:24,973] INFO Creating table with sql: CREATE TABLE "users" (
"id" TEXT NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 18:27:24,974] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 18:27:24,974] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 18:27:24,976] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 18:27:24,977] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 18:27:34,801] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:34,802] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:34,811] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 9 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:34,862] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=250, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:27:44,812] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:44,812] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:44,815] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:44,861] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=262, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:27:54,815] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:27:54,816] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:27:54,818] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:27:54,861] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 3: {users-0=OffsetAndMetadata{offset=274, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:04,819] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:04,819] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:04,821] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:04,876] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 4: {users-0=OffsetAndMetadata{offset=286, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:14,822] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:14,823] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:14,825] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:14,877] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 5: {users-0=OffsetAndMetadata{offset=298, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:24,826] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:24,826] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:24,828] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:24,877] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 6: {users-0=OffsetAndMetadata{offset=310, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:34,829] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:34,830] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:34,832] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:34,877] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 7: {users-0=OffsetAndMetadata{offset=322, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:44,832] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:44,833] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:44,835] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:44,878] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 8: {users-0=OffsetAndMetadata{offset=334, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:28:54,835] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:28:54,836] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:28:54,838] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:28:54,879] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 9: {users-0=OffsetAndMetadata{offset=346, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:04,839] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:04,839] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:04,841] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:04,880] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 10: {users-0=OffsetAndMetadata{offset=358, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:14,842] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:14,843] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:14,845] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:14,896] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 11: {users-0=OffsetAndMetadata{offset=370, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:24,845] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:24,846] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:24,847] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:24,897] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 12: {users-0=OffsetAndMetadata{offset=382, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:34,848] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:34,848] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:34,851] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:34,898] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 13: {users-0=OffsetAndMetadata{offset=394, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:44,851] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:44,852] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:44,854] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:44,898] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 14: {users-0=OffsetAndMetadata{offset=406, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:29:54,854] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:29:54,855] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:29:54,857] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:29:54,901] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 15: {users-0=OffsetAndMetadata{offset=418, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:04,857] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:04,858] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:04,860] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:04,902] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 16: {users-0=OffsetAndMetadata{offset=430, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:14,861] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:14,861] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:14,863] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:14,902] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 17: {users-0=OffsetAndMetadata{offset=442, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:24,864] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:24,865] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:24,866] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:24,902] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 18: {users-0=OffsetAndMetadata{offset=454, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:34,867] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:34,868] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:34,870] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:34,908] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 19: {users-0=OffsetAndMetadata{offset=466, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:44,870] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:44,871] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:44,873] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:44,908] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 20: {users-0=OffsetAndMetadata{offset=478, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:30:54,873] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:30:54,873] INFO WorkerSourceTask{id=jdbc-source-0} flushing 2 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:30:54,878] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:30:54,921] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 21: {users-0=OffsetAndMetadata{offset=490, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:31:04,879] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:04,879] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:04,880] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:31:04,921] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 22: {users-0=OffsetAndMetadata{offset=502, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:31:06,770] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:31:06,770] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:31:06,774] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:31:06,774] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:31:06,775] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:31:06,775] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:31:06,776] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:31:06,776] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:31:06,776] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:06,777] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:31:06,777] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-bd935a82-c8ab-4525-9aa6-4d6c6a7ce757 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:31:06,782] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:31:06,783] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:31:06,783] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:31:06,783] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:31:06,878] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 18:31:06,878] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:06,879] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:06,879] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:06,879] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:31:06,882] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:31:06,882] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:31:06,882] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:31:06,882] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:06,883] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:31:06,883] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:31:06,884] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:31:06,885] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:31:06,885] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:31:06,885] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:31:08,472] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:31:08,481] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:31:08,487] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:31:08,507] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:08,783] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:08,784] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,784] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,784] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,784] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,785] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,785] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:08,965] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:08,965] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:08,966] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:09,112] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:09,113] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,114] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,975] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:09,975] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,975] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,976] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,977] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,978] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,979] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,980] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,981] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,981] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:09,982] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,982] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,982] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,982] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,983] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,983] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,983] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,983] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,983] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,984] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,984] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,984] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,984] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,984] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,985] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,986] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:09,987] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,987] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:09,987] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:09,988] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:09,988] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:09,988] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,988] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,988] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:09,999] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:31:10,000] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:31:10,004] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:31:10,049] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:10,049] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:10,050] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:10,050] INFO Kafka startTimeMs: 1596043870049 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:10,294] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:31:10,314] INFO Logging initialized @2139ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:31:10,365] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:31:10,365] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:31:10,372] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:31:10,397] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:31:10,397] INFO Started @2222ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:31:10,415] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:10,415] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:31:10,416] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:10,416] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:31:10,416] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:10,416] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:31:10,427] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:10,428] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:10,428] INFO Kafka startTimeMs: 1596043870427 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:10,556] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:10,558] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:10,565] INFO Kafka Connect standalone worker initialization took 2090ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:31:10,565] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:31:10,566] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:31:10,566] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:31:10,567] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:31:10,575] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:31:10,575] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:31:10,575] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:31:10,615] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:31:10,698] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:31:10,698] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:31:10,700] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:31:11,428] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:31:11,429] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:31:11,429] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:31:11,476] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:11,587] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:11,594] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:11,595] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,595] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:31:11,598] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:31:11,599] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:31:11,599] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:31:11,601] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:11,603] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:31:11,604] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:31:11,605] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:31:11,606] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,610] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:31:11,613] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:11,614] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,616] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:31:11,617] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:31:11,618] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:31:11,619] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:31:11,619] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:11,619] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:31:11,619] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:31:11,625] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:31:11,634] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:31:11,672] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:11,672] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:11,672] INFO Kafka startTimeMs: 1596043871672 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:11,694] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:31:11,694] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:31:11,695] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:31:11,695] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:11,696] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:31:11,699] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:31:11,707] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:11,708] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:11,710] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,712] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:31:11,715] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:31:11,716] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:31:11,717] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:31:11,718] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,720] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:31:11,721] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:31:11,717] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:31:11,722] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:11,722] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:31:11,723] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,723] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:31:11,723] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:31:11,723] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:31:11,724] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:31:11,724] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:31:11,724] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:11,724] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:31:11,725] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:31:11,726] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:31:11,726] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:31:11,726] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:11,738] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:31:11,790] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:11,791] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:11,791] INFO Kafka startTimeMs: 1596043871790 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:11,797] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:31:11,799] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:31:11,799] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:31:11,800] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:31:11,806] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:31:11,807] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:31:11,822] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:31:11,823] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:31:11,825] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:31:11,834] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:31:11,834] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:31:11,839] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 41: {connector-consumer-jdbc-sink-0-ca4c23c7-bd55-40b5-8c9b-48aa0491e9e1=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:31:11,843] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 41 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:31:11,846] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:31:11,857] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=502, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:31:11,901] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:11,903] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:31:11,909] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 18:31:11,909] INFO Using Sqlite dialect TABLE "users" absent (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 18:31:11,910] INFO Creating table with sql: CREATE TABLE "users" (
"id" TEXT NOT NULL,
"name" TEXT NULL,
"country" TEXT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:93)
[2020-07-29 18:31:11,911] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 18:31:11,911] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 18:31:11,912] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 18:31:11,913] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 18:31:16,707] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 18:31:16,707] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 18:31:16,714] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 18:31:16,714] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 18:31:16,715] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 18:31:16,715] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 18:31:16,715] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:31:16,716] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=508, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 18:31:16,719] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 18:31:16,719] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:16,720] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 18:31:16,720] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-ca4c23c7-bd55-40b5-8c9b-48aa0491e9e1 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 18:31:16,725] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:31:16,726] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:31:16,726] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 18:31:16,726] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 18:31:16,739] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 18:31:16,739] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:16,740] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:16,740] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:16,743] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:31:16,743] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 18:31:16,745] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 18:31:16,745] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 18:31:16,746] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 18:31:16,746] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 18:31:16,746] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 18:31:16,746] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 18:31:16,747] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 18:31:16,747] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 18:31:16,748] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 18:31:16,748] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 18:31:18,564] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 18:31:18,569] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 18:31:18,574] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 18:31:18,593] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:18,882] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:18,883] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:18,883] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:18,884] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:18,884] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:18,884] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:18,885] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:19,100] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:19,100] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:19,100] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 18:31:19,233] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:19,233] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:19,234] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,187] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,188] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,189] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,190] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,191] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,192] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 18:31:20,193] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,193] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,193] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,193] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,194] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,194] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,194] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,194] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,194] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,195] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,196] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,197] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,198] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,198] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,198] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,198] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:20,198] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,199] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:20,199] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:20,199] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:20,199] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 18:31:20,199] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,200] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,200] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 18:31:20,212] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 18:31:20,413] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 18:31:20,419] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 18:31:20,483] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,483] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,483] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,483] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,483] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,484] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,484] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 18:31:20,484] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:20,484] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:20,485] INFO Kafka startTimeMs: 1596043880484 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:20,793] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 18:31:20,822] INFO Logging initialized @2558ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 18:31:20,895] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 18:31:20,896] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 18:31:20,906] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 18:31:20,935] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 18:31:20,935] INFO Started @2671ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 18:31:20,963] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:20,964] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 18:31:20,964] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:20,964] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 18:31:20,964] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 18:31:20,965] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 18:31:20,978] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:20,979] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:20,979] INFO Kafka startTimeMs: 1596043880978 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:21,132] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:21,135] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:21,147] INFO Kafka Connect standalone worker initialization took 2582ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 18:31:21,148] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 18:31:21,149] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 18:31:21,150] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 18:31:21,151] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 18:31:21,161] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 18:31:21,161] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 18:31:21,162] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 18:31:21,271] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 18:31:21,411] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 18:31:21,411] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 18:31:21,414] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 18:31:22,044] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 18:31:22,044] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 18:31:22,044] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 18:31:22,065] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:22,160] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:22,166] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:22,168] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,168] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:31:22,172] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:31:22,173] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 18:31:22,173] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 18:31:22,174] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:22,176] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 18:31:22,176] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:31:22,177] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 18:31:22,178] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,183] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:31:22,185] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:22,186] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,188] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:31:22,189] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:31:22,190] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:31:22,191] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:31:22,191] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:22,191] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:31:22,191] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:31:22,196] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 18:31:22,203] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 18:31:22,225] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:22,225] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:22,225] INFO Kafka startTimeMs: 1596043882225 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:22,233] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 18:31:22,234] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 18:31:22,234] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 18:31:22,234] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:31:22,235] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:31:22,235] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:22,239] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 18:31:22,240] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:22,240] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,240] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 18:31:22,241] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 18:31:22,242] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 18:31:22,242] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:31:22,243] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 18:31:22,243] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,243] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 18:31:22,244] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 18:31:22,244] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 18:31:22,244] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 18:31:22,245] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 18:31:22,245] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,245] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 18:31:22,245] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 18:31:22,246] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 18:31:22,246] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 18:31:22,246] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 18:31:22,246] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 18:31:22,246] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 18:31:22,247] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 18:31:22,247] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 18:31:22,248] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 18:31:22,256] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 18:31:22,294] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 18:31:22,295] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 18:31:22,295] INFO Kafka startTimeMs: 1596043882294 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 18:31:22,302] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 18:31:22,303] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 18:31:22,303] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 18:31:22,304] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 18:31:22,306] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 18:31:22,307] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 18:31:22,318] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 18:31:22,318] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 18:31:22,321] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:31:22,329] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 18:31:22,329] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 18:31:22,334] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 43: {connector-consumer-jdbc-sink-0-bbaeb15f-592d-476e-a12f-d19b5988d4ed=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 18:31:22,336] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 43 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 18:31:22,339] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 18:31:22,348] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=508, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 18:31:22,378] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 18:31:22,379] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 18:31:22,383] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 18:31:22,383] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 18:31:22,385] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 18:31:22,387] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 18:31:32,233] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:32,233] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:32,237] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:31:32,298] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=526, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:31:42,237] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:42,238] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:42,240] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:31:42,299] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=538, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:31:52,241] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:31:52,242] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:31:52,244] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:31:52,300] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 3: {users-0=OffsetAndMetadata{offset=550, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:02,245] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:02,245] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:02,246] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:02,301] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 4: {users-0=OffsetAndMetadata{offset=562, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:12,246] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:12,247] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:12,249] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:12,302] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 5: {users-0=OffsetAndMetadata{offset=574, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:22,250] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:22,251] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:22,253] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:22,302] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 6: {users-0=OffsetAndMetadata{offset=586, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:32,253] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:32,254] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:32,255] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:32,301] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 7: {users-0=OffsetAndMetadata{offset=598, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:42,256] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:42,257] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:42,258] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:42,301] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 8: {users-0=OffsetAndMetadata{offset=610, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:32:52,259] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:32:52,260] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:32:52,261] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:32:52,302] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 9: {users-0=OffsetAndMetadata{offset=622, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:02,262] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:02,262] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:02,265] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:02,303] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 10: {users-0=OffsetAndMetadata{offset=634, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:12,265] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:12,266] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:12,267] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:12,315] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 11: {users-0=OffsetAndMetadata{offset=646, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:22,268] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:22,268] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:22,269] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:22,316] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 12: {users-0=OffsetAndMetadata{offset=658, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:32,270] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:32,270] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:32,272] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:32,326] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 13: {users-0=OffsetAndMetadata{offset=670, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:42,272] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:42,273] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:42,275] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:42,327] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 14: {users-0=OffsetAndMetadata{offset=682, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:33:52,276] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:33:52,276] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:33:52,278] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:33:52,327] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 15: {users-0=OffsetAndMetadata{offset=694, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:02,279] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:02,279] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:02,282] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:02,328] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 16: {users-0=OffsetAndMetadata{offset=706, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:12,283] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:12,283] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:12,284] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:12,329] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 17: {users-0=OffsetAndMetadata{offset=718, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:22,284] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:22,285] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:22,287] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:22,329] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 18: {users-0=OffsetAndMetadata{offset=730, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:32,287] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:32,288] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:32,288] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:32,329] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 19: {users-0=OffsetAndMetadata{offset=742, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:42,289] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:42,289] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:42,290] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:42,335] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 20: {users-0=OffsetAndMetadata{offset=754, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:34:52,290] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:34:52,291] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:34:52,292] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:34:52,336] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 21: {users-0=OffsetAndMetadata{offset=766, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:02,292] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:02,292] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:02,293] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:02,336] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 22: {users-0=OffsetAndMetadata{offset=778, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:12,294] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:12,294] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:12,296] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:12,336] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 23: {users-0=OffsetAndMetadata{offset=790, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:22,297] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:22,297] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:22,299] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:22,336] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 24: {users-0=OffsetAndMetadata{offset=802, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:32,301] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:32,301] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:32,303] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:32,337] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 25: {users-0=OffsetAndMetadata{offset=814, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:42,304] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:42,304] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:42,306] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:42,350] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 26: {users-0=OffsetAndMetadata{offset=826, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:35:52,307] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:35:52,307] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:35:52,309] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:35:52,351] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 27: {users-0=OffsetAndMetadata{offset=838, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:02,310] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:02,310] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:02,312] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:02,351] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 28: {users-0=OffsetAndMetadata{offset=850, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:12,313] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:12,314] INFO WorkerSourceTask{id=jdbc-source-0} flushing 3 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:12,320] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:12,351] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 29: {users-0=OffsetAndMetadata{offset=862, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:22,321] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:22,321] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:22,322] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:22,352] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 30: {users-0=OffsetAndMetadata{offset=874, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:32,322] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:32,323] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:32,324] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:32,363] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 31: {users-0=OffsetAndMetadata{offset=886, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:42,325] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:42,325] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:42,325] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:42,363] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 32: {users-0=OffsetAndMetadata{offset=898, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:36:52,326] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:36:52,326] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:36:52,327] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:36:52,363] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 33: {users-0=OffsetAndMetadata{offset=910, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:02,328] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:02,328] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:02,329] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:02,364] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 34: {users-0=OffsetAndMetadata{offset=922, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:12,330] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:12,331] INFO WorkerSourceTask{id=jdbc-source-0} flushing 4 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:12,332] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:12,364] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 35: {users-0=OffsetAndMetadata{offset=934, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:22,333] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:22,333] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:22,334] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:22,365] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 36: {users-0=OffsetAndMetadata{offset=946, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:32,334] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:32,335] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:32,337] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:32,364] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 37: {users-0=OffsetAndMetadata{offset=958, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:42,337] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:42,337] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:42,338] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:42,365] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 38: {users-0=OffsetAndMetadata{offset=970, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:37:52,338] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:37:52,339] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:37:52,339] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:37:52,370] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 39: {users-0=OffsetAndMetadata{offset=982, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:02,340] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:02,340] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:02,341] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:02,376] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 40: {users-0=OffsetAndMetadata{offset=994, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:12,341] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:12,342] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:12,342] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:12,380] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 41: {users-0=OffsetAndMetadata{offset=1006, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:22,343] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:22,343] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:22,345] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:22,383] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 42: {users-0=OffsetAndMetadata{offset=1018, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:32,346] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:32,346] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:32,347] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:32,384] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 43: {users-0=OffsetAndMetadata{offset=1030, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:42,347] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:42,348] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:42,349] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:42,384] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 44: {users-0=OffsetAndMetadata{offset=1042, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:38:52,349] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:38:52,349] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:38:52,351] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:38:52,385] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 45: {users-0=OffsetAndMetadata{offset=1054, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:02,351] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:02,351] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:02,353] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:02,386] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 46: {users-0=OffsetAndMetadata{offset=1066, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:12,353] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:12,353] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:12,354] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:12,386] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 47: {users-0=OffsetAndMetadata{offset=1078, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:22,355] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:22,355] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:22,356] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:22,387] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 48: {users-0=OffsetAndMetadata{offset=1090, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:32,356] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:32,357] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:32,358] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:32,387] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 49: {users-0=OffsetAndMetadata{offset=1102, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:42,358] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:42,359] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:42,361] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:42,389] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 50: {users-0=OffsetAndMetadata{offset=1114, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:39:52,361] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:39:52,361] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:39:52,362] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:39:52,389] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 51: {users-0=OffsetAndMetadata{offset=1126, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:02,363] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:02,363] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:02,364] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:02,399] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 52: {users-0=OffsetAndMetadata{offset=1138, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:12,364] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:12,365] INFO WorkerSourceTask{id=jdbc-source-0} flushing 5 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:12,374] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 10 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:12,400] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 53: {users-0=OffsetAndMetadata{offset=1150, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:22,374] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:22,374] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:22,375] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:22,400] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 54: {users-0=OffsetAndMetadata{offset=1162, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:32,376] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:32,376] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:32,377] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:32,403] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 55: {users-0=OffsetAndMetadata{offset=1174, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:42,377] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:42,378] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:42,378] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:42,403] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 56: {users-0=OffsetAndMetadata{offset=1186, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:40:52,379] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:40:52,379] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:40:52,380] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:40:52,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 57: {users-0=OffsetAndMetadata{offset=1198, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:02,380] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:02,380] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:02,381] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:02,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 58: {users-0=OffsetAndMetadata{offset=1210, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:12,381] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:12,382] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:12,382] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:12,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 59: {users-0=OffsetAndMetadata{offset=1222, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:22,382] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:22,383] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:22,384] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:22,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 60: {users-0=OffsetAndMetadata{offset=1234, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:32,384] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:32,385] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:32,385] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:32,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 61: {users-0=OffsetAndMetadata{offset=1246, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:42,386] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:42,386] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:42,387] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:42,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 62: {users-0=OffsetAndMetadata{offset=1258, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:41:52,387] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:41:52,387] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:41:52,388] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:41:52,409] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 63: {users-0=OffsetAndMetadata{offset=1270, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:02,388] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:02,389] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:02,389] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:02,417] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 64: {users-0=OffsetAndMetadata{offset=1282, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:12,390] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:12,390] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:12,391] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:12,417] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 65: {users-0=OffsetAndMetadata{offset=1294, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:22,392] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:22,392] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:22,392] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:22,418] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 66: {users-0=OffsetAndMetadata{offset=1306, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:32,393] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:32,393] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:32,394] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:32,418] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 67: {users-0=OffsetAndMetadata{offset=1318, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:42,395] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:42,395] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:42,396] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:42,418] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 68: {users-0=OffsetAndMetadata{offset=1330, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:42:52,396] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:42:52,396] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:42:52,397] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:42:52,419] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 69: {users-0=OffsetAndMetadata{offset=1342, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:02,398] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:02,398] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:02,399] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:02,419] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 70: {users-0=OffsetAndMetadata{offset=1354, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:12,399] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:12,399] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:12,400] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:12,427] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 71: {users-0=OffsetAndMetadata{offset=1366, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:22,401] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:22,401] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:22,402] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:22,428] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 72: {users-0=OffsetAndMetadata{offset=1378, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:32,402] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:32,402] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:32,403] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:32,428] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 73: {users-0=OffsetAndMetadata{offset=1390, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:42,403] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:42,404] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:42,404] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:42,429] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 74: {users-0=OffsetAndMetadata{offset=1402, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:43:52,405] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:43:52,405] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:43:52,407] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:43:52,428] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 75: {users-0=OffsetAndMetadata{offset=1414, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:02,407] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:02,408] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:02,408] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:02,434] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 76: {users-0=OffsetAndMetadata{offset=1426, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:12,409] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:12,409] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:12,410] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:12,436] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 77: {users-0=OffsetAndMetadata{offset=1438, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:22,410] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:22,410] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:22,411] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:22,436] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 78: {users-0=OffsetAndMetadata{offset=1450, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:32,412] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:32,412] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:32,413] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:32,436] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 79: {users-0=OffsetAndMetadata{offset=1462, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:42,413] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:42,413] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:42,414] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:42,436] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 80: {users-0=OffsetAndMetadata{offset=1474, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:44:52,414] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:44:52,414] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:44:52,415] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:44:52,440] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 81: {users-0=OffsetAndMetadata{offset=1486, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:02,415] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:02,416] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:02,416] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:02,440] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 82: {users-0=OffsetAndMetadata{offset=1498, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:12,417] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:12,417] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:12,418] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:12,440] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 83: {users-0=OffsetAndMetadata{offset=1510, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:22,418] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:22,418] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:22,419] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:22,443] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 84: {users-0=OffsetAndMetadata{offset=1522, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:32,420] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:32,420] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:32,421] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:32,444] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 85: {users-0=OffsetAndMetadata{offset=1534, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:42,421] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:42,421] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:42,422] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:42,444] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 86: {users-0=OffsetAndMetadata{offset=1546, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:45:52,422] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:45:52,423] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:45:52,424] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:45:52,445] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 87: {users-0=OffsetAndMetadata{offset=1558, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:02,424] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:02,424] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:02,425] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:02,446] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 88: {users-0=OffsetAndMetadata{offset=1570, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:12,426] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:12,426] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:12,427] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:12,448] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 89: {users-0=OffsetAndMetadata{offset=1582, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:22,427] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:22,428] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:22,429] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:22,470] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 90: {users-0=OffsetAndMetadata{offset=1594, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:32,429] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:32,429] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:32,429] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:32,471] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 91: {users-0=OffsetAndMetadata{offset=1606, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:42,430] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:42,430] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:42,431] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:42,472] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 92: {users-0=OffsetAndMetadata{offset=1618, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:46:52,431] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:46:52,432] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:46:52,433] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:46:52,473] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 93: {users-0=OffsetAndMetadata{offset=1630, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:02,433] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:02,433] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:02,434] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:02,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 94: {users-0=OffsetAndMetadata{offset=1642, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:12,434] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:12,435] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:12,436] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:12,475] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 95: {users-0=OffsetAndMetadata{offset=1654, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:22,437] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:22,437] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:22,438] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:22,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 96: {users-0=OffsetAndMetadata{offset=1666, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:32,438] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:32,438] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:32,439] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:32,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 97: {users-0=OffsetAndMetadata{offset=1678, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:42,439] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:42,439] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:42,440] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:42,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 98: {users-0=OffsetAndMetadata{offset=1690, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:47:52,440] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:47:52,440] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:47:52,441] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:47:52,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 99: {users-0=OffsetAndMetadata{offset=1702, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:02,441] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:02,442] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:02,442] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:02,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 100: {users-0=OffsetAndMetadata{offset=1714, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:12,443] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:12,443] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:12,444] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:12,474] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 101: {users-0=OffsetAndMetadata{offset=1726, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:22,444] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:22,444] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:22,446] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:22,475] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 102: {users-0=OffsetAndMetadata{offset=1738, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:32,447] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:32,447] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:32,448] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:32,475] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 103: {users-0=OffsetAndMetadata{offset=1750, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:42,448] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:42,448] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:42,449] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:42,475] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 104: {users-0=OffsetAndMetadata{offset=1762, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:48:52,449] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:48:52,449] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:48:52,450] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:48:52,478] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 105: {users-0=OffsetAndMetadata{offset=1774, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:02,450] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:02,450] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:02,451] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:02,479] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 106: {users-0=OffsetAndMetadata{offset=1786, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:12,451] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:12,451] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:12,452] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:12,480] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 107: {users-0=OffsetAndMetadata{offset=1798, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:22,452] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:22,453] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:22,453] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:22,481] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 108: {users-0=OffsetAndMetadata{offset=1810, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:32,453] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:32,454] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:32,455] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:32,482] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 109: {users-0=OffsetAndMetadata{offset=1822, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:42,455] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:42,455] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:42,456] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:42,483] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 110: {users-0=OffsetAndMetadata{offset=1834, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:49:52,457] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:49:52,457] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:49:52,457] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:49:52,483] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 111: {users-0=OffsetAndMetadata{offset=1846, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:02,458] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:02,458] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:02,459] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:02,482] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 112: {users-0=OffsetAndMetadata{offset=1858, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:12,459] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:12,459] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:12,460] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:12,483] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 113: {users-0=OffsetAndMetadata{offset=1870, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:22,460] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:22,460] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:22,461] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:22,483] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 114: {users-0=OffsetAndMetadata{offset=1882, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:32,461] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:32,462] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:32,463] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:32,490] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 115: {users-0=OffsetAndMetadata{offset=1894, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:42,463] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:42,463] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:42,464] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:42,492] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 116: {users-0=OffsetAndMetadata{offset=1906, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:50:52,464] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:50:52,465] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:50:52,465] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:50:52,492] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 117: {users-0=OffsetAndMetadata{offset=1918, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:02,466] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:02,466] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:02,467] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:02,493] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 118: {users-0=OffsetAndMetadata{offset=1930, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:12,467] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:12,468] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:12,469] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:12,496] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 119: {users-0=OffsetAndMetadata{offset=1942, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:22,469] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:22,470] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:22,470] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:22,497] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 120: {users-0=OffsetAndMetadata{offset=1954, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:32,471] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:32,471] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:32,472] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:32,498] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 121: {users-0=OffsetAndMetadata{offset=1966, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:42,472] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:42,473] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:42,474] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:42,498] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 122: {users-0=OffsetAndMetadata{offset=1978, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:51:52,474] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:51:52,475] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:51:52,476] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:51:52,501] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 123: {users-0=OffsetAndMetadata{offset=1990, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:02,476] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:02,476] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:02,477] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:02,501] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 124: {users-0=OffsetAndMetadata{offset=2002, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:12,478] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:12,478] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:12,479] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:12,501] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 125: {users-0=OffsetAndMetadata{offset=2014, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:22,480] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:22,480] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:22,481] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:22,504] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 126: {users-0=OffsetAndMetadata{offset=2026, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:32,482] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:32,482] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:32,483] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:32,505] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 127: {users-0=OffsetAndMetadata{offset=2038, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:42,483] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:42,483] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:42,484] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:42,504] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 128: {users-0=OffsetAndMetadata{offset=2050, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:52:52,484] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:52:52,484] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:52:52,485] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:52:52,504] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 129: {users-0=OffsetAndMetadata{offset=2062, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:02,485] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:02,486] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:02,486] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:02,516] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 130: {users-0=OffsetAndMetadata{offset=2074, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:12,487] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:12,487] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:12,488] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:12,517] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 131: {users-0=OffsetAndMetadata{offset=2086, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:22,488] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:22,488] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:22,489] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:22,517] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 132: {users-0=OffsetAndMetadata{offset=2098, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:32,490] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:32,490] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:32,491] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:32,517] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 133: {users-0=OffsetAndMetadata{offset=2110, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:42,491] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:42,491] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:42,492] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:42,518] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 134: {users-0=OffsetAndMetadata{offset=2122, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:53:52,492] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:53:52,493] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:53:52,494] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:53:52,518] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 135: {users-0=OffsetAndMetadata{offset=2134, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:02,495] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:02,495] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:02,496] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:02,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 136: {users-0=OffsetAndMetadata{offset=2142, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:12,496] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:12,497] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:12,497] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:12,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 137: {users-0=OffsetAndMetadata{offset=2158, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:22,498] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:22,498] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:22,499] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:22,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 138: {users-0=OffsetAndMetadata{offset=2170, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:32,499] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:32,499] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:32,500] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:32,579] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 139: {users-0=OffsetAndMetadata{offset=2182, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:42,500] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:42,500] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:42,501] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:42,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 140: {users-0=OffsetAndMetadata{offset=2194, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:54:52,502] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:54:52,502] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:54:52,502] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:54:52,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 141: {users-0=OffsetAndMetadata{offset=2206, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:02,503] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:02,503] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:02,507] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:02,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 142: {users-0=OffsetAndMetadata{offset=2218, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:12,507] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:12,508] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:12,509] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:12,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 143: {users-0=OffsetAndMetadata{offset=2230, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:22,509] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:22,509] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:22,510] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:22,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 144: {users-0=OffsetAndMetadata{offset=2242, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:32,510] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:32,511] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:32,512] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:32,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 145: {users-0=OffsetAndMetadata{offset=2254, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:42,512] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:42,513] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:42,514] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:42,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 146: {users-0=OffsetAndMetadata{offset=2266, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:55:52,514] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:55:52,514] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:55:52,515] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:55:52,578] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 147: {users-0=OffsetAndMetadata{offset=2278, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:02,515] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:02,515] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:02,516] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:02,579] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 148: {users-0=OffsetAndMetadata{offset=2290, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:12,516] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:12,516] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:12,517] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:12,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 149: {users-0=OffsetAndMetadata{offset=2302, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:22,517] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:22,518] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:22,518] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:22,579] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 150: {users-0=OffsetAndMetadata{offset=2314, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:32,519] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:32,519] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:32,520] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:32,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 151: {users-0=OffsetAndMetadata{offset=2326, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:42,520] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:42,521] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:42,522] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:42,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 152: {users-0=OffsetAndMetadata{offset=2338, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:56:52,522] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:56:52,522] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:56:52,523] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:56:52,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 153: {users-0=OffsetAndMetadata{offset=2350, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:02,523] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:02,523] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:02,524] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:02,581] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 154: {users-0=OffsetAndMetadata{offset=2362, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:12,524] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:12,525] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:12,526] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:12,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 155: {users-0=OffsetAndMetadata{offset=2374, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:22,526] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:22,526] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:22,527] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:22,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 156: {users-0=OffsetAndMetadata{offset=2386, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:32,527] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:32,527] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:32,528] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:32,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 157: {users-0=OffsetAndMetadata{offset=2398, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:42,529] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:42,529] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:42,530] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:42,581] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 158: {users-0=OffsetAndMetadata{offset=2410, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:57:52,530] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:57:52,530] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:57:52,531] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:57:52,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 159: {users-0=OffsetAndMetadata{offset=2422, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:02,532] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:02,532] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:02,532] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:02,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 160: {users-0=OffsetAndMetadata{offset=2434, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:12,533] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:12,533] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:12,534] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:12,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 161: {users-0=OffsetAndMetadata{offset=2446, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:22,534] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:22,534] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:22,535] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:22,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 162: {users-0=OffsetAndMetadata{offset=2458, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:32,535] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:32,535] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:32,536] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:32,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 163: {users-0=OffsetAndMetadata{offset=2470, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:42,536] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:42,536] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:42,537] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:42,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 164: {users-0=OffsetAndMetadata{offset=2482, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:58:52,537] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:58:52,538] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:58:52,539] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:58:52,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 165: {users-0=OffsetAndMetadata{offset=2494, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:02,539] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:02,539] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:02,540] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:02,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 166: {users-0=OffsetAndMetadata{offset=2506, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:12,541] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:12,541] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:12,542] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:12,581] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 167: {users-0=OffsetAndMetadata{offset=2518, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:22,542] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:22,542] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:22,545] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:22,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 168: {users-0=OffsetAndMetadata{offset=2530, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:32,546] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:32,546] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:32,547] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:32,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 169: {users-0=OffsetAndMetadata{offset=2542, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:42,547] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:42,547] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:42,548] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:42,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 170: {users-0=OffsetAndMetadata{offset=2554, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 18:59:52,549] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 18:59:52,549] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 18:59:52,550] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 18:59:52,580] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 171: {users-0=OffsetAndMetadata{offset=2566, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)

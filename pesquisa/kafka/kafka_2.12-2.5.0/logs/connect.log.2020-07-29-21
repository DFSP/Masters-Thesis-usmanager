[2020-07-29 21:00:00,861] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:00,862] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:00,862] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:01,159] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 356: {users-0=OffsetAndMetadata{offset=4786, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:00:10,863] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:10,863] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:10,869] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:11,185] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 357: {users-0=OffsetAndMetadata{offset=4798, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:00:20,869] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:20,874] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:20,875] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:21,185] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 358: {users-0=OffsetAndMetadata{offset=4810, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:00:30,876] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:30,876] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:30,879] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:31,185] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 359: {users-0=OffsetAndMetadata{offset=4822, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:00:40,879] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:40,880] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:40,881] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:41,186] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 360: {users-0=OffsetAndMetadata{offset=4834, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:00:50,882] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:00:50,886] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:00:50,888] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:00:51,187] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 361: {users-0=OffsetAndMetadata{offset=4846, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:00,890] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:00,890] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:00,892] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:01,188] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 362: {users-0=OffsetAndMetadata{offset=4858, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:10,893] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:10,894] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:10,896] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:11,214] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 363: {users-0=OffsetAndMetadata{offset=4870, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:20,897] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:20,897] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:20,905] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 8 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:21,214] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 364: {users-0=OffsetAndMetadata{offset=4882, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:30,905] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:30,906] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:30,907] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:31,215] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 365: {users-0=OffsetAndMetadata{offset=4894, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:40,908] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:40,908] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:40,909] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:41,214] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 366: {users-0=OffsetAndMetadata{offset=4906, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:01:50,910] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:01:50,910] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:01:50,911] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:01:51,215] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 367: {users-0=OffsetAndMetadata{offset=4918, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:00,912] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:00,913] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:00,914] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:01,215] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 368: {users-0=OffsetAndMetadata{offset=4930, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:10,915] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:10,916] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:10,917] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:11,215] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 369: {users-0=OffsetAndMetadata{offset=4942, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:20,918] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:20,918] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:20,921] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:21,216] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 370: {users-0=OffsetAndMetadata{offset=4954, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:30,922] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:30,923] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:30,925] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:31,217] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 371: {users-0=OffsetAndMetadata{offset=4966, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:40,925] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:40,925] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:40,926] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:41,218] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 372: {users-0=OffsetAndMetadata{offset=4978, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:02:50,927] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:02:50,927] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:02:50,928] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:02:51,219] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 373: {users-0=OffsetAndMetadata{offset=4990, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:00,928] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:00,928] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:00,929] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:01,219] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 374: {users-0=OffsetAndMetadata{offset=5002, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:10,930] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:10,930] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:10,933] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:11,241] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 375: {users-0=OffsetAndMetadata{offset=5014, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:20,934] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:20,935] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:20,936] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:21,242] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 376: {users-0=OffsetAndMetadata{offset=5026, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:30,937] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:30,937] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:30,939] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:31,243] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 377: {users-0=OffsetAndMetadata{offset=5038, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:40,940] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:40,940] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:40,941] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:41,243] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 378: {users-0=OffsetAndMetadata{offset=5050, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:03:50,942] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:03:50,942] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:03:50,943] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:03:51,243] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 379: {users-0=OffsetAndMetadata{offset=5062, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:00,943] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:00,943] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:00,944] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:01,244] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 380: {users-0=OffsetAndMetadata{offset=5074, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:10,944] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:10,944] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:10,945] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:11,244] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 381: {users-0=OffsetAndMetadata{offset=5086, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:20,946] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:20,946] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:20,951] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:21,244] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 382: {users-0=OffsetAndMetadata{offset=5098, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:30,951] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:30,952] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:30,956] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:31,245] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 383: {users-0=OffsetAndMetadata{offset=5110, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:40,974] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:40,975] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:40,976] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:41,244] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 384: {users-0=OffsetAndMetadata{offset=5122, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:04:50,977] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:04:50,978] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:04:50,979] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:04:51,244] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 385: {users-0=OffsetAndMetadata{offset=5134, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:00,980] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:00,980] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:00,980] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:01,245] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 386: {users-0=OffsetAndMetadata{offset=5146, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:10,981] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:10,981] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:10,982] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:11,246] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 387: {users-0=OffsetAndMetadata{offset=5158, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:20,983] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:20,984] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:20,985] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:21,246] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 388: {users-0=OffsetAndMetadata{offset=5170, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:30,986] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:30,986] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:30,988] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:31,246] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 389: {users-0=OffsetAndMetadata{offset=5182, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:40,989] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:40,989] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:40,990] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:41,246] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 390: {users-0=OffsetAndMetadata{offset=5194, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:05:50,990] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:05:50,990] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:05:50,991] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:05:51,247] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 391: {users-0=OffsetAndMetadata{offset=5206, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:00,991] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:00,991] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:00,992] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:01,247] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 392: {users-0=OffsetAndMetadata{offset=5218, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:10,992] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:10,993] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:10,994] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:11,247] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 393: {users-0=OffsetAndMetadata{offset=5230, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:20,995] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:20,995] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:20,997] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:21,248] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 394: {users-0=OffsetAndMetadata{offset=5242, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:31,013] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:31,013] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:31,016] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:31,257] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 395: {users-0=OffsetAndMetadata{offset=5254, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:41,016] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:41,017] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:41,019] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:41,257] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 396: {users-0=OffsetAndMetadata{offset=5266, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:06:51,020] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:06:51,021] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:06:51,022] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:06:51,258] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 397: {users-0=OffsetAndMetadata{offset=5278, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:01,023] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:01,023] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:01,025] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:01,258] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 398: {users-0=OffsetAndMetadata{offset=5290, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:11,026] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:11,026] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:11,026] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:11,259] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 399: {users-0=OffsetAndMetadata{offset=5302, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:21,027] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:21,027] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:21,027] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:21,260] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 400: {users-0=OffsetAndMetadata{offset=5314, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:31,028] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:31,028] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:31,029] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:31,260] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 401: {users-0=OffsetAndMetadata{offset=5326, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:41,030] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:41,030] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:41,031] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:41,261] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 402: {users-0=OffsetAndMetadata{offset=5338, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:07:51,031] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:07:51,031] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:07:51,032] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:07:51,262] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 403: {users-0=OffsetAndMetadata{offset=5350, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:01,032] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:01,032] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:01,033] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:01,263] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 404: {users-0=OffsetAndMetadata{offset=5362, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:11,033] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:11,034] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:11,035] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:11,263] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 405: {users-0=OffsetAndMetadata{offset=5374, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:21,035] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:21,036] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:21,036] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:21,264] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 406: {users-0=OffsetAndMetadata{offset=5386, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:31,036] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:31,037] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:31,037] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:31,264] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 407: {users-0=OffsetAndMetadata{offset=5398, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:41,037] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:41,038] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:41,038] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:41,264] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 408: {users-0=OffsetAndMetadata{offset=5410, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:08:51,038] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:08:51,039] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:08:51,039] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:08:51,265] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 409: {users-0=OffsetAndMetadata{offset=5422, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:01,040] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:01,040] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:01,040] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:01,266] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 410: {users-0=OffsetAndMetadata{offset=5434, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:11,041] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:11,041] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:11,041] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:11,266] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 411: {users-0=OffsetAndMetadata{offset=5446, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:21,042] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:21,042] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:21,042] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:21,266] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 412: {users-0=OffsetAndMetadata{offset=5458, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:31,043] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:31,043] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:31,044] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:31,267] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 413: {users-0=OffsetAndMetadata{offset=5470, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:41,044] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:41,044] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:41,045] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:41,267] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 414: {users-0=OffsetAndMetadata{offset=5482, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:09:51,045] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:09:51,046] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:09:51,046] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:09:51,268] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 415: {users-0=OffsetAndMetadata{offset=5494, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:01,047] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:01,047] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:01,047] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:01,267] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 416: {users-0=OffsetAndMetadata{offset=5506, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:11,048] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:11,048] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:11,049] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:11,267] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 417: {users-0=OffsetAndMetadata{offset=5518, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:21,049] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:21,049] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:21,050] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:21,268] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 418: {users-0=OffsetAndMetadata{offset=5530, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:31,050] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:31,050] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:31,051] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:31,268] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 419: {users-0=OffsetAndMetadata{offset=5542, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:41,051] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:41,051] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:41,052] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:41,268] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 420: {users-0=OffsetAndMetadata{offset=5554, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:10:51,052] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:10:51,053] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:10:51,053] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:10:51,269] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 421: {users-0=OffsetAndMetadata{offset=5566, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:01,054] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:01,054] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:01,055] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:01,270] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 422: {users-0=OffsetAndMetadata{offset=5578, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:11,055] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:11,055] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:11,056] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:11,271] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 423: {users-0=OffsetAndMetadata{offset=5590, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:21,056] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:21,057] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:21,057] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:21,272] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 424: {users-0=OffsetAndMetadata{offset=5602, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:31,058] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:31,058] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:31,059] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:31,273] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 425: {users-0=OffsetAndMetadata{offset=5614, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:41,059] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:41,059] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:41,060] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:41,274] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 426: {users-0=OffsetAndMetadata{offset=5626, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:11:51,060] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:11:51,060] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:11:51,061] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:11:51,275] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 427: {users-0=OffsetAndMetadata{offset=5638, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:01,061] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:01,061] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:01,062] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:01,275] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 428: {users-0=OffsetAndMetadata{offset=5650, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:11,062] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:11,062] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:11,063] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:11,276] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 429: {users-0=OffsetAndMetadata{offset=5662, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:21,063] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:21,063] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:21,064] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:21,276] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 430: {users-0=OffsetAndMetadata{offset=5674, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:31,064] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:31,064] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:31,065] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:31,277] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 431: {users-0=OffsetAndMetadata{offset=5686, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:41,065] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:41,066] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:41,066] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:41,278] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 432: {users-0=OffsetAndMetadata{offset=5698, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:12:51,066] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:12:51,067] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:12:51,068] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:12:51,279] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 433: {users-0=OffsetAndMetadata{offset=5710, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:01,068] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:01,069] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:01,070] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:01,279] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 434: {users-0=OffsetAndMetadata{offset=5722, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:11,070] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:11,071] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:11,072] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:11,280] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 435: {users-0=OffsetAndMetadata{offset=5734, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:21,072] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:21,072] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:21,073] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:21,281] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 436: {users-0=OffsetAndMetadata{offset=5746, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:31,073] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:31,073] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:31,074] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:31,282] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 437: {users-0=OffsetAndMetadata{offset=5758, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:41,074] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:41,075] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:41,075] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:41,283] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 438: {users-0=OffsetAndMetadata{offset=5770, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:13:51,075] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:13:51,076] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:13:51,076] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:13:51,284] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 439: {users-0=OffsetAndMetadata{offset=5782, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:01,077] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:01,077] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:01,077] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:01,283] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 440: {users-0=OffsetAndMetadata{offset=5794, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:11,078] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:11,078] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:11,078] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:11,284] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 441: {users-0=OffsetAndMetadata{offset=5806, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:21,079] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:21,079] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:21,079] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:21,285] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 442: {users-0=OffsetAndMetadata{offset=5818, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:31,080] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:31,080] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:31,081] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:31,286] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 443: {users-0=OffsetAndMetadata{offset=5830, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:41,081] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:41,081] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:41,082] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:41,286] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 444: {users-0=OffsetAndMetadata{offset=5842, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:14:51,082] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:14:51,083] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:14:51,083] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:14:51,287] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 445: {users-0=OffsetAndMetadata{offset=5854, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:01,084] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:01,084] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:01,085] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:01,288] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 446: {users-0=OffsetAndMetadata{offset=5866, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:11,085] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:11,085] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:11,086] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:11,289] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 447: {users-0=OffsetAndMetadata{offset=5878, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:21,086] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:21,086] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:21,087] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:21,290] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 448: {users-0=OffsetAndMetadata{offset=5890, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:31,087] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:31,088] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:31,088] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:31,291] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 449: {users-0=OffsetAndMetadata{offset=5902, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:41,088] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:41,089] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:41,090] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:41,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 450: {users-0=OffsetAndMetadata{offset=5914, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:15:51,090] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:15:51,090] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:15:51,091] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:15:51,293] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 451: {users-0=OffsetAndMetadata{offset=5926, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:01,091] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:01,091] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:01,092] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:01,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 452: {users-0=OffsetAndMetadata{offset=5938, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:11,092] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:11,093] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:11,094] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:11,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 453: {users-0=OffsetAndMetadata{offset=5950, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:21,094] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:21,094] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:21,095] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:21,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 454: {users-0=OffsetAndMetadata{offset=5962, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:31,096] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:31,096] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:31,096] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:31,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 455: {users-0=OffsetAndMetadata{offset=5974, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:41,097] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:41,097] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:41,097] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:41,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 456: {users-0=OffsetAndMetadata{offset=5986, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:16:51,098] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:16:51,098] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:16:51,099] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:16:51,292] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 457: {users-0=OffsetAndMetadata{offset=5998, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:01,099] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:01,099] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:01,100] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:01,293] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 458: {users-0=OffsetAndMetadata{offset=6010, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:11,100] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:11,100] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:11,101] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:11,293] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 459: {users-0=OffsetAndMetadata{offset=6022, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:21,101] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:21,101] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:21,102] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:21,293] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 460: {users-0=OffsetAndMetadata{offset=6034, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:31,102] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:31,103] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:31,103] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:31,294] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 461: {users-0=OffsetAndMetadata{offset=6046, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:41,104] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:41,104] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:41,104] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:41,294] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 462: {users-0=OffsetAndMetadata{offset=6058, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:17:51,105] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:17:51,105] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:17:51,105] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:17:51,294] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 463: {users-0=OffsetAndMetadata{offset=6070, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:01,106] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:01,106] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:01,107] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:01,294] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 464: {users-0=OffsetAndMetadata{offset=6082, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:11,107] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:11,108] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:11,108] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:11,294] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 465: {users-0=OffsetAndMetadata{offset=6094, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:21,109] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:21,109] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:21,110] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:21,295] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 466: {users-0=OffsetAndMetadata{offset=6106, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:31,110] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:31,110] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:31,111] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:31,295] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 467: {users-0=OffsetAndMetadata{offset=6118, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:41,112] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:41,112] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:41,113] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:41,295] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 468: {users-0=OffsetAndMetadata{offset=6130, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:18:51,113] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:18:51,113] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:18:51,114] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:18:51,295] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 469: {users-0=OffsetAndMetadata{offset=6142, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:19:01,114] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:01,114] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:01,115] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:01,296] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 470: {users-0=OffsetAndMetadata{offset=6154, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:19:11,115] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:11,115] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:11,116] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:11,297] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 471: {users-0=OffsetAndMetadata{offset=6166, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:19:21,116] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:21,117] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:21,117] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:21,298] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 472: {users-0=OffsetAndMetadata{offset=6178, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:19:24,692] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Received unknown topic or partition error in fetch for partition users-0 (org.apache.kafka.clients.consumer.internals.Fetcher:1250)
[2020-07-29 21:19:24,697] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 12280 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 21:19:24,699] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:19:24,699] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:19:24,816] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 12282 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 21:19:24,817] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] The following subscribed topics are not assigned to any members: [users]  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:589)
[2020-07-29 21:19:24,817] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 44: {connector-consumer-jdbc-sink-0-bbaeb15f-592d-476e-a12f-d19b5988d4ed=Assignment(partitions=[])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:19:24,819] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 44 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:19:24,819] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:19:24,918] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:19:24,918] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:19:24,920] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 45: {connector-consumer-jdbc-sink-0-bbaeb15f-592d-476e-a12f-d19b5988d4ed=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:19:24,922] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 45 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:19:24,923] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:19:24,924] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 21:19:24,932] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 21:19:27,019] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:19:27,020] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:19:27,026] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:19:27,026] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:19:27,028] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:19:27,028] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:19:27,028] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:19:27,029] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 474: {users-0=OffsetAndMetadata{offset=6, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 21:19:27,031] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:19:27,032] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:27,033] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:19:27,033] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-bbaeb15f-592d-476e-a12f-d19b5988d4ed sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:19:27,038] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:19:27,039] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:19:27,039] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:19:27,039] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:19:27,088] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:19:27,088] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:27,089] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:27,089] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:27,089] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:27,089] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:19:27,091] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:19:27,092] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:19:27,092] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:19:27,092] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:27,093] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:19:27,093] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:19:27,093] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:19:27,094] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:19:27,094] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:19:27,094] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:19:29,196] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:19:29,203] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:19:29,216] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:19:29,243] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:19:29,570] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:19:29,572] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,572] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,572] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,572] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,573] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,574] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:19:29,788] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:19:29,789] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,789] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:19:29,935] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:19:29,936] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:29,937] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,994] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,995] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,996] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,997] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,998] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,998] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,998] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:19:30,998] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:30,999] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,000] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,001] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,002] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,002] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,002] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,002] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:19:31,002] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,002] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:19:31,002] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:19:31,003] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:19:31,003] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:19:31,003] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,003] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,003] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:19:31,015] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:19:31,016] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:19:31,019] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:19:31,068] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,068] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,068] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,068] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,068] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,069] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,069] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:19:31,069] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:19:31,069] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:19:31,069] INFO Kafka startTimeMs: 1596053971069 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:19:31,324] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:19:31,343] INFO Logging initialized @2463ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:19:31,402] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:19:31,403] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:19:31,410] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:19:31,439] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:19:31,440] INFO Started @2559ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:19:31,459] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:19:31,459] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:19:31,460] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:19:31,460] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:19:31,460] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:19:31,460] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:19:31,470] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:19:31,471] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:19:31,471] INFO Kafka startTimeMs: 1596053971470 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:19:31,579] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:19:31,581] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:19:31,587] INFO Kafka Connect standalone worker initialization took 2389ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:19:31,587] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:19:31,588] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:19:31,588] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:19:31,589] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:19:31,596] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:19:31,596] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:19:31,596] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:19:31,638] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:19:31,704] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:19:31,705] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:19:31,706] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:19:32,230] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:19:32,230] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:19:32,230] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:19:32,249] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:19:32,341] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:19:32,348] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:19:32,349] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,349] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:19:32,353] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:19:32,353] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:19:32,354] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:19:32,355] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:19:32,356] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:19:32,357] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:19:32,359] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:19:32,360] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,364] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:19:32,366] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:19:32,366] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,367] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:19:32,368] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:19:32,369] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:19:32,370] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:19:32,370] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:19:32,370] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:19:32,371] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:19:32,376] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:19:32,381] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:19:32,402] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:19:32,402] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:19:32,403] INFO Kafka startTimeMs: 1596053972402 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:19:32,414] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:19:32,414] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:19:32,414] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:19:32,415] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:19:32,416] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:19:32,417] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:19:32,420] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:19:32,421] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:19:32,421] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,421] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:19:32,422] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:19:32,423] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:19:32,423] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:19:32,424] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,424] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:19:32,425] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:19:32,425] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:19:32,425] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:19:32,426] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:19:32,426] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:19:32,426] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,427] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:19:32,427] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:19:32,428] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:19:32,428] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:19:32,428] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:19:32,429] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:19:32,429] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:19:32,430] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:19:32,431] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:19:32,431] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:19:32,441] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:19:32,484] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:19:32,484] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:19:32,484] INFO Kafka startTimeMs: 1596053972484 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:19:32,491] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:19:32,492] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:19:32,492] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:19:32,492] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:19:32,495] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:19:32,496] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:19:32,505] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:19:32,506] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:19:32,508] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:19:32,515] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:19:32,516] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:19:32,519] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 47: {connector-consumer-jdbc-sink-0-aae17ea2-15bb-4336-9029-064df5da9293=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:19:32,522] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 47 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:19:32,525] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:19:32,534] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 21:19:32,576] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:19:32,577] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:19:32,582] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:19:32,582] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:19:32,585] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:19:32,586] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:19:42,413] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:42,414] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:42,418] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:42,488] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:19:47,595] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:19:47,595] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:19:47,599] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:19:47,599] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:19:47,600] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:19:47,600] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:19:47,600] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:19:47,600] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets synchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=30, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:335)
[2020-07-29 21:19:47,603] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:19:47,603] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:47,604] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:19:47,604] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-aae17ea2-15bb-4336-9029-064df5da9293 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:19:47,610] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:19:47,610] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:19:47,611] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:19:47,611] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:19:47,644] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:19:47,644] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:47,644] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:19:47,644] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:19:47,645] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:19:47,646] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:19:47,647] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:19:47,648] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:19:47,648] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:19:47,648] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:19:47,648] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:19:47,648] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:19:47,649] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:19:47,649] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:19:47,649] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:19:47,649] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:29:04,639] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:29:04,645] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:29:04,650] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:29:04,670] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:04,952] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:04,953] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:04,953] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:04,954] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:04,954] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:04,954] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:04,955] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:05,148] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:05,148] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:05,149] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:05,279] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:05,280] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:05,281] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,212] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:06,212] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,212] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,212] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,212] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,213] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,213] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,213] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,213] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,213] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,214] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,215] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,216] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,217] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,218] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,219] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,219] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:06,220] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,220] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,220] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,220] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,221] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,222] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,223] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,224] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,225] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,225] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,225] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:06,225] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,226] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:06,226] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:06,226] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:06,226] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:06,226] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,227] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,227] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:06,240] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:29:06,241] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:29:06,245] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:29:06,301] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,301] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:06,302] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:06,302] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:06,302] INFO Kafka startTimeMs: 1596054546301 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:06,550] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:29:06,567] INFO Logging initialized @2228ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:29:06,618] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:29:06,619] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:29:06,626] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:29:06,656] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:29:06,657] INFO Started @2317ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:29:06,682] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:06,682] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:29:06,682] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:06,683] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:29:06,683] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:06,683] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:29:06,694] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:06,695] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:06,695] INFO Kafka startTimeMs: 1596054546694 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:06,809] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:06,810] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:06,818] INFO Kafka Connect standalone worker initialization took 2177ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:29:06,818] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:29:06,819] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:29:06,819] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:29:06,819] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:29:06,825] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:29:06,825] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:29:06,825] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:29:06,868] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:29:06,948] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:29:06,948] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:29:06,950] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:29:07,513] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:29:07,514] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:29:07,514] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:29:07,535] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:07,631] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:07,637] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:07,638] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,638] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:29:07,642] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:29:07,642] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:29:07,643] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:29:07,644] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:29:07,646] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:29:07,646] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:29:07,647] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:29:07,648] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,654] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:29:07,656] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:07,656] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,658] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:29:07,659] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:29:07,660] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:29:07,660] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:29:07,661] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:07,661] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:29:07,661] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:29:07,666] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:29:07,676] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:29:07,702] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:07,702] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:07,702] INFO Kafka startTimeMs: 1596054547702 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:07,712] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:29:07,714] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:29:07,714] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:29:07,714] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:29:07,714] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:29:07,715] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:29:07,718] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:07,718] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:07,719] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,719] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:29:07,719] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:29:07,720] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:29:07,720] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:29:07,721] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,722] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:29:07,723] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:29:07,724] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:29:07,724] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:29:07,724] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:07,725] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:29:07,725] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,726] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:29:07,726] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:29:07,726] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:29:07,727] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:29:07,727] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:07,727] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:29:07,728] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:29:07,729] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:29:07,729] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:29:07,729] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:07,736] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:29:07,773] WARN [Producer clientId=connector-producer-jdbc-source-0] Error while fetching metadata with correlation id 3 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 21:29:07,775] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:07,776] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:07,776] INFO Kafka startTimeMs: 1596054547775 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:07,780] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:29:07,781] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:29:07,781] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:29:07,782] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:29:07,784] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:29:07,785] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:29:07,802] WARN [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Error while fetching metadata with correlation id 2 : {users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1070)
[2020-07-29 21:29:07,802] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:29:07,803] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:29:07,805] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:29:07,816] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:29:07,816] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:29:07,908] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 1: {connector-consumer-jdbc-sink-0-ae7ef930-95be-4080-a6b3-37e3a2d3bcbd=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:29:07,911] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:29:07,914] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:29:07,922] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Found no committed offset for partition users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1299)
[2020-07-29 21:29:07,932] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Resetting offset for partition users-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:383)
[2020-07-29 21:29:07,963] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:29:07,964] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:29:07,968] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:29:07,968] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:29:07,971] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:29:07,972] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:29:17,712] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:29:17,713] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:29:17,718] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:29:17,797] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:29:27,719] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:29:27,719] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:29:27,720] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:29:27,797] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:29:37,721] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:29:37,721] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:29:37,722] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:29:37,798] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 3: {users-0=OffsetAndMetadata{offset=14, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:29:47,723] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:29:47,723] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:29:47,724] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:29:47,799] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 4: {users-0=OffsetAndMetadata{offset=18, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:29:54,730] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:29:54,730] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:29:54,734] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:29:54,735] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:29:54,736] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:29:54,736] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:29:54,736] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:29:55,749] WARN Write of 1 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)
	at org.sqlite.core.DB.newSQLException(DB.java:941)
	at org.sqlite.core.DB.newSQLException(DB.java:953)
	at org.sqlite.core.DB.throwex(DB.java:918)
	at org.sqlite.core.DB.executeBatch(DB.java:805)
	at org.sqlite.core.CorePreparedStatement.executeBatch(CorePreparedStatement.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 21:29:55,755] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:29:55,755] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:29:55,755] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 21:29:55,756] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:29:55,756] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:29:55,756] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-ae7ef930-95be-4080-a6b3-37e3a2d3bcbd sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:29:55,762] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:29:55,762] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:29:55,762] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:29:55,763] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:29:55,845] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:29:55,846] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:29:55,846] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:29:55,846] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:29:55,847] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:29:55,848] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:29:55,852] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:29:55,852] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:29:55,852] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:29:55,853] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:29:55,854] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:29:55,854] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:29:55,855] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:29:55,856] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:29:55,856] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:29:55,856] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:29:56,849] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:29:56,855] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:29:56,861] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:29:56,883] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:57,203] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:57,204] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,205] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,205] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,205] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,205] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,206] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:57,399] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:57,400] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,400] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:29:57,546] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:57,546] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:57,548] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,414] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:29:58,414] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,414] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,415] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,416] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,417] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,418] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,419] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,420] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:29:58,420] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,420] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,421] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,422] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,422] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,422] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,422] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,422] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,423] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,424] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,425] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,425] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,425] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,425] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,425] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:58,425] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,426] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:58,426] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:58,426] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:58,426] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:29:58,427] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,427] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,427] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:29:58,440] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:29:58,441] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:29:58,445] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:29:58,497] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,497] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:29:58,498] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:58,498] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:58,498] INFO Kafka startTimeMs: 1596054598498 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:58,756] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:29:58,777] INFO Logging initialized @2232ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:29:58,840] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:29:58,840] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:29:58,847] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:29:58,879] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:29:58,879] INFO Started @2335ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:29:58,898] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:58,898] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:29:58,898] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:58,898] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:29:58,899] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:29:58,899] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:29:58,908] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:58,908] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:58,908] INFO Kafka startTimeMs: 1596054598908 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:59,023] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:59,025] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:59,035] INFO Kafka Connect standalone worker initialization took 2184ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:29:59,035] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:29:59,036] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:29:59,036] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:29:59,037] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:29:59,045] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:29:59,045] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:29:59,045] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:29:59,100] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:29:59,177] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:29:59,177] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:29:59,179] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:29:59,700] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:29:59,700] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:29:59,701] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:29:59,725] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:59,819] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:59,824] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:59,825] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,825] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:29:59,829] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:29:59,830] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:29:59,830] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:29:59,831] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:29:59,833] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:29:59,834] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:29:59,834] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:29:59,835] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,840] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:29:59,842] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:59,843] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,844] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:29:59,845] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:29:59,846] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:29:59,847] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:29:59,847] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:59,847] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:29:59,847] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:29:59,852] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:29:59,859] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:29:59,884] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:59,884] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:59,884] INFO Kafka startTimeMs: 1596054599884 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:59,896] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:29:59,897] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:29:59,897] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:29:59,897] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:29:59,897] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:29:59,898] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:29:59,902] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:29:59,902] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:59,902] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,903] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:29:59,903] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:29:59,904] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:29:59,904] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:29:59,904] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,905] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:29:59,906] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:29:59,907] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:29:59,907] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,908] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:29:59,908] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:29:59,908] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:29:59,908] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:29:59,909] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:29:59,909] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:29:59,910] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:29:59,911] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:29:59,911] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:29:59,911] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:29:59,909] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:29:59,913] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:29:59,914] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:29:59,920] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:29:59,960] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:29:59,961] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:29:59,961] INFO Kafka startTimeMs: 1596054599960 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:29:59,966] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:29:59,967] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:29:59,968] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:29:59,968] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:29:59,972] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:29:59,973] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:29:59,983] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:29:59,984] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:29:59,988] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:29:59,997] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:29:59,997] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:30:00,002] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 3: {connector-consumer-jdbc-sink-0-19ddb750-ad50-4051-8127-32141dbfa0c1=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:30:00,006] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:30:00,011] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:30:00,020] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 21:30:00,060] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:30:00,061] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:30:00,066] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:30:00,066] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:30:00,068] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:30:00,070] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:30:00,075] WARN Write of 4 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)
	at org.sqlite.core.DB.newSQLException(DB.java:941)
	at org.sqlite.core.DB.newSQLException(DB.java:953)
	at org.sqlite.core.DB.throwex(DB.java:918)
	at org.sqlite.core.DB.executeBatch(DB.java:805)
	at org.sqlite.core.CorePreparedStatement.executeBatch(CorePreparedStatement.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 21:30:00,078] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:30:00,078] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:30:00,078] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 21:30:03,080] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:30:03,081] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:30:03,082] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:30:03,082] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:30:03,083] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:30:03,084] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:30:03,084] WARN Write of 4 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:76)
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)
	at org.sqlite.core.DB.newSQLException(DB.java:941)
	at org.sqlite.core.DB.newSQLException(DB.java:953)
	at org.sqlite.core.DB.throwex(DB.java:918)
	at org.sqlite.core.DB.executeBatch(DB.java:805)
	at org.sqlite.core.CorePreparedStatement.executeBatch(CorePreparedStatement.java:86)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:219)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:185)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:72)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:74)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2020-07-29 21:30:03,085] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:30:03,085] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:30:03,085] ERROR WorkerSinkTask{id=jdbc-sink-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:559)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:95)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:546)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:326)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Exception chain:
org.sqlite.SQLiteException: [SQLITE_BUSY]  The database file is locked (database is locked)

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:86)
	... 11 more
[2020-07-29 21:30:03,410] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:30:03,410] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:30:03,415] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:30:03,415] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:30:03,416] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:30:03,416] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:30:03,416] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:30:03,417] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:30:03,417] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:30:03,418] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-19ddb750-ad50-4051-8127-32141dbfa0c1 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:30:03,424] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:30:03,424] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:30:03,425] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:30:03,425] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:30:03,473] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:30:03,473] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:30:03,473] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:30:03,473] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:30:03,477] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:30:03,477] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:30:03,480] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:30:03,480] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:30:03,480] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:30:03,480] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:30:03,481] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:30:03,481] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:30:03,481] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:30:03,482] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:30:03,482] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:30:03,482] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:30:12,931] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:30:12,937] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:30:12,942] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:30:12,971] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:30:13,279] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:30:13,280] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,281] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,281] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,281] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,281] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,282] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:30:13,484] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:30:13,484] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,485] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:30:13,628] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:30:13,628] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:13,630] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,505] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,506] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,507] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,508] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,509] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:30:14,510] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,510] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,510] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,510] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,511] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,512] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,513] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:30:14,513] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,514] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:30:14,514] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:30:14,514] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:30:14,514] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:30:14,514] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,514] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,514] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:30:14,527] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:30:14,527] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:30:14,531] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:30:14,577] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,577] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:30:14,578] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:30:14,578] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:30:14,579] INFO Kafka startTimeMs: 1596054614578 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:30:14,834] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:30:14,851] INFO Logging initialized @2232ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:30:14,900] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:30:14,900] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:30:14,908] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:30:14,937] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:30:14,938] INFO Started @2319ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:30:14,959] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:30:14,959] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:30:14,960] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:30:14,960] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:30:14,960] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:30:14,960] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:30:14,971] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:30:14,972] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:30:14,972] INFO Kafka startTimeMs: 1596054614971 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:30:15,093] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:30:15,095] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:30:15,102] INFO Kafka Connect standalone worker initialization took 2169ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:30:15,102] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:30:15,103] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:30:15,104] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:30:15,105] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:30:15,113] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:30:15,113] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:30:15,113] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:30:15,159] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:30:15,237] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:30:15,237] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:30:15,239] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:30:15,759] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:30:15,760] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:30:15,760] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:30:15,794] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:30:15,895] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:30:15,901] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:30:15,902] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,902] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:30:15,904] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:30:15,905] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:30:15,905] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:30:15,906] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:30:15,909] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:30:15,909] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:30:15,910] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:30:15,911] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,915] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:30:15,917] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:30:15,918] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,919] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:30:15,920] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:30:15,921] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:30:15,921] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:30:15,922] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:30:15,922] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:30:15,922] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:30:15,927] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:30:15,933] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:30:15,955] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:30:15,956] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:30:15,956] INFO Kafka startTimeMs: 1596054615955 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:30:15,962] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:30:15,963] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:30:15,963] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:30:15,963] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:30:15,964] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:30:15,964] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:30:15,968] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:30:15,968] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:30:15,969] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,969] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:30:15,970] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:30:15,970] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:30:15,971] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:30:15,971] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,972] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:30:15,973] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:30:15,974] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:30:15,974] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,975] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:30:15,976] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:30:15,976] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:30:15,976] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:30:15,977] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:30:15,977] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:30:15,977] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:30:15,978] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:30:15,978] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:30:15,978] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:30:15,978] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:30:15,979] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:30:15,979] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:30:15,988] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:30:16,027] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:30:16,027] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:30:16,028] INFO Kafka startTimeMs: 1596054616027 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:30:16,033] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:30:16,034] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:30:16,034] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:30:16,034] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:30:16,037] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:30:16,037] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:30:16,046] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:30:16,047] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:30:16,053] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:30:16,061] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:30:16,061] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:30:16,066] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 5: {connector-consumer-jdbc-sink-0-555a0e55-0773-4ede-ae6f-46870dbcd962=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:30:16,070] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:30:16,073] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:30:16,082] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 21:30:16,115] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:30:16,116] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:30:16,120] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:30:16,120] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:30:16,122] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:30:16,123] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:30:25,963] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:30:25,963] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:30:25,969] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 6 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:30:26,031] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 1: {users-0=OffsetAndMetadata{offset=28, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:30:35,969] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:30:35,970] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:30:35,972] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:30:36,032] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 2: {users-0=OffsetAndMetadata{offset=32, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:30:45,972] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:30:45,973] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:30:45,974] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:30:46,033] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 3: {users-0=OffsetAndMetadata{offset=35, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:30:55,975] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:30:55,975] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:30:55,976] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:30:56,033] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 4: {users-0=OffsetAndMetadata{offset=37, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:05,977] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:05,977] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:05,978] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:06,033] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 5: {users-0=OffsetAndMetadata{offset=39, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:15,978] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:15,979] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:15,980] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:16,033] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 6: {users-0=OffsetAndMetadata{offset=41, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:25,980] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:25,981] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:25,983] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:26,036] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 7: {users-0=OffsetAndMetadata{offset=45, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:35,983] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:35,984] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:35,985] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:36,037] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 8: {users-0=OffsetAndMetadata{offset=48, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:45,986] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:45,986] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:45,987] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:46,037] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 9: {users-0=OffsetAndMetadata{offset=50, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:31:55,988] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:31:55,988] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:31:55,990] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:31:56,037] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 10: {users-0=OffsetAndMetadata{offset=52, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:32:05,990] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:05,991] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:32:05,992] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:32:06,038] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 11: {users-0=OffsetAndMetadata{offset=54, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:32:10,115] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:32:10,116] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:32:10,120] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:32:10,120] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:32:10,121] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:32:10,121] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:32:10,121] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:32:10,121] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:32:10,121] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:32:10,122] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:32:10,122] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-555a0e55-0773-4ede-ae6f-46870dbcd962 sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:32:10,126] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:32:10,126] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:32:10,126] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:32:10,127] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:32:10,212] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:32:10,212] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:32:10,213] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:10,213] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:32:10,214] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:32:10,214] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:32:10,218] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:32:10,218] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:32:10,218] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:32:10,219] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:32:10,219] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:32:10,219] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:32:10,220] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:32:10,220] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:32:10,220] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:32:10,220] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:32:11,706] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:32:11,713] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:32:11,718] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:32:11,741] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:32:12,071] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:32:12,072] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,072] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,073] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,073] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,073] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,074] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:32:12,280] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:32:12,281] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,281] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:32:12,429] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:32:12,429] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:12,431] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,485] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,486] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,487] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,488] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,489] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,490] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:32:13,491] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,492] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,492] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,492] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,493] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,493] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,493] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,493] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,493] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,494] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,494] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,494] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,494] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,494] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,495] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,495] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,495] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,495] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,495] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,496] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,497] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:32:13,497] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,498] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:32:13,498] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:32:13,498] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:32:13,498] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:32:13,498] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,498] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,498] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:32:13,511] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:32:13,512] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:32:13,516] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:32:13,581] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,581] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,581] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,581] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,582] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,582] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,582] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:32:13,582] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:32:13,583] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:32:13,583] INFO Kafka startTimeMs: 1596054733582 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:32:13,878] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:32:13,899] INFO Logging initialized @2500ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:32:13,953] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:32:13,953] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:32:13,962] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:32:13,990] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:32:13,990] INFO Started @2591ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:32:14,011] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:32:14,012] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:32:14,012] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:32:14,012] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:32:14,013] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:32:14,013] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:32:14,022] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:32:14,023] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:32:14,023] INFO Kafka startTimeMs: 1596054734022 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:32:14,144] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:32:14,146] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:32:14,157] INFO Kafka Connect standalone worker initialization took 2449ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:32:14,157] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:32:14,158] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:32:14,158] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:32:14,159] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:32:14,167] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:32:14,167] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:32:14,167] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:32:14,215] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:32:14,297] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:32:14,297] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:32:14,299] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:32:14,897] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:32:14,897] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:32:14,897] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:32:14,927] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:32:15,022] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:32:15,028] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:32:15,029] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,030] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:32:15,033] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:32:15,034] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:32:15,035] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:32:15,036] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:32:15,037] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:32:15,038] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:32:15,038] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:32:15,039] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,044] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:32:15,047] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:32:15,048] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,051] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:32:15,053] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:32:15,055] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:32:15,055] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:32:15,056] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:32:15,056] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:32:15,056] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:32:15,060] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:32:15,067] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:32:15,091] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:32:15,091] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:32:15,092] INFO Kafka startTimeMs: 1596054735091 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:32:15,101] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:32:15,102] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:32:15,103] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:32:15,103] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:32:15,102] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:32:15,111] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:32:15,112] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:32:15,113] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,113] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:32:15,113] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:32:15,114] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:32:15,114] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:32:15,114] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,115] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:32:15,116] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:32:15,117] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:32:15,117] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,118] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:32:15,118] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:32:15,119] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:32:15,119] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:32:15,120] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:32:15,120] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:32:15,120] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:32:15,121] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:32:15,121] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:32:15,122] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:32:15,131] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:32:15,140] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:32:15,153] INFO Found offset {{table=users}=null, {protocol=1, table=users}={incrementing=6}} for partition {protocol=1, table=users} (io.confluent.connect.jdbc.source.JdbcSourceTask:189)
[2020-07-29 21:32:15,155] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:32:15,155] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:32:15,156] INFO Begin using SQL query: SELECT * FROM "users" WHERE "users"."id" > ? ORDER BY "users"."id" ASC (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:32:15,177] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:32:15,178] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:32:15,178] INFO Kafka startTimeMs: 1596054735177 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:32:15,182] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:32:15,184] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:32:15,184] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:32:15,185] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:32:15,188] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:32:15,189] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:32:15,210] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:32:15,211] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:32:15,213] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:32:15,220] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:32:15,220] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:32:15,223] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 7: {connector-consumer-jdbc-sink-0-728cf544-4dfa-4111-ab88-83c22017a49f=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:32:15,227] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 7 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:32:15,232] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:32:15,244] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=54, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 21:32:25,101] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:25,102] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:32:35,102] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:35,103] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:32:45,103] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:45,104] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:32:55,104] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:32:55,105] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:05,105] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:05,105] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:15,106] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:15,106] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:25,107] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:25,107] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:35,108] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:35,108] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:40,210] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:33:40,211] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:49)
[2020-07-29 21:33:40,215] INFO Checking Sqlite dialect for existence of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:548)
[2020-07-29 21:33:40,216] INFO Using Sqlite dialect TABLE "users" present (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:556)
[2020-07-29 21:33:40,218] INFO Checking Sqlite dialect for type of TABLE "users" (io.confluent.connect.jdbc.dialect.SqliteDatabaseDialect:818)
[2020-07-29 21:33:40,219] INFO Setting metadata for table "users" to Table{name='"users"', type=TABLE columns=[Column{'country', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'name', isPrimaryKey=false, allowsNull=true, sqlType=TEXT}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=TEXT}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2020-07-29 21:33:45,108] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:45,109] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:33:45,114] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:33:45,191] INFO WorkerSinkTask{id=jdbc-sink-0} Committing offsets asynchronously using sequence number 9: {users-0=OffsetAndMetadata{offset=56, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:349)
[2020-07-29 21:33:55,115] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:33:55,115] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:05,116] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:05,116] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:15,117] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:15,118] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:25,118] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:25,119] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:35,119] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:35,120] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:45,120] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:45,120] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:34:55,121] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:34:55,121] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:05,122] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:05,123] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:05,539] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:492)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:469)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:325)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.DataException: JsonConverter with schemas.enable requires "schema" and "payload" fields and may not contain additional fields. If you are trying to deserialize plain JSON data, set schemas.enable=false in your converter configuration.
	at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:359)
	at org.apache.kafka.connect.storage.Converter.toConnectData(Converter.java:87)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$2(WorkerSinkTask.java:492)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 13 more
[2020-07-29 21:35:05,545] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 21:35:05,545] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:35:05,545] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:35:05,547] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:35:05,547] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-728cf544-4dfa-4111-ab88-83c22017a49f sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:35:15,123] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:15,124] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:25,124] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:25,125] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:28,697] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:35:28,697] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:35:28,709] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:35:28,710] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:35:28,711] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:35:28,711] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:35:28,711] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:35:28,713] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:35:28,713] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:35:28,714] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:35:28,714] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:35:28,800] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:35:28,800] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:35:28,800] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:28,800] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:28,800] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:35:28,804] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:35:28,804] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:35:28,805] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:35:28,805] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:35:28,806] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:35:28,806] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:35:28,807] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:35:28,808] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:35:28,808] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:35:28,808] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:35:30,715] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:35:30,734] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:35:30,751] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:35:30,792] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:35:31,105] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:35:31,106] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,106] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,106] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,106] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,107] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,108] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:35:31,367] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:35:31,367] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,368] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:35:31,504] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:35:31,504] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:31,505] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,526] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:35:32,526] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,527] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,528] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,529] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,530] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,530] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,530] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,530] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,530] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,531] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,532] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,533] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,533] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,533] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,533] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:35:32,534] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,534] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,535] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,535] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,535] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,535] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,535] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,536] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,536] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,536] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,536] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,536] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,537] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,538] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:35:32,539] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,539] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:35:32,539] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:35:32,539] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:35:32,539] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:35:32,539] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,539] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,540] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:35:32,556] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:35:32,558] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:35:32,564] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:35:32,627] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,628] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:35:32,629] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:35:32,629] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:35:32,629] INFO Kafka startTimeMs: 1596054932628 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:35:32,874] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:35:32,897] INFO Logging initialized @2872ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:35:32,957] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:35:32,958] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:35:32,965] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:35:32,994] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:35:32,994] INFO Started @2969ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:35:33,012] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:35:33,012] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:35:33,012] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:35:33,012] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:35:33,013] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:35:33,013] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:35:33,024] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:35:33,024] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:35:33,024] INFO Kafka startTimeMs: 1596054933024 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:35:33,142] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:35:33,143] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:35:33,150] INFO Kafka Connect standalone worker initialization took 2432ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:35:33,150] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:35:33,151] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:35:33,152] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:35:33,152] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:35:33,159] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:35:33,159] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:35:33,159] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:35:33,205] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:35:33,294] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:35:33,294] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:35:33,295] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:35:33,836] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:35:33,837] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:35:33,837] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:35:33,878] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:35:33,977] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:35:33,982] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:35:33,983] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:33,983] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:35:33,985] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:35:33,986] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:35:33,987] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:35:33,988] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:35:33,990] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:35:33,991] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:35:33,991] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:35:33,992] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:33,998] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:35:34,000] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:35:34,001] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:34,002] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:35:34,003] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:35:34,004] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:35:34,004] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:35:34,005] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:35:34,005] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:35:34,005] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:35:34,010] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:35:34,015] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:35:34,036] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:35:34,036] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:35:34,036] INFO Kafka startTimeMs: 1596054934036 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:35:34,043] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:35:34,043] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:35:34,043] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:35:34,044] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:35:34,044] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:35:34,046] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:35:34,047] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:35:34,048] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:35:34,048] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:34,048] INFO Creating connector jdbc-sink of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:35:34,049] INFO Instantiated connector jdbc-sink with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:35:34,050] INFO Finished creating connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:35:34,050] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:35:34,051] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:34,052] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:44)
[2020-07-29 21:35:34,052] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:35:34,052] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:35:34,052] INFO Creating task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:35:34,053] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:35:34,053] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:35:34,053] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:34,054] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:35:34,054] INFO Instantiated task jdbc-sink-0 with version null of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:35:34,054] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:35:34,054] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:35:34,054] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:35:34,054] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:35:34,055] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:35:34,055] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:529)
[2020-07-29 21:35:34,056] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:347)
[2020-07-29 21:35:34,056] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-sink
	tasks.max = 1
	topics = [users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:35:34,061] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = connector-consumer-jdbc-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-jdbc-sink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-07-29 21:35:34,098] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:35:34,098] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:35:34,098] INFO Kafka startTimeMs: 1596054934098 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:35:34,104] INFO Created connector jdbc-sink (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:35:34,105] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Subscribed to topic(s): users (org.apache.kafka.clients.consumer.KafkaConsumer:974)
[2020-07-29 21:35:34,105] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:44)
[2020-07-29 21:35:34,106] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-worker/manager-worker
	connection.user = sa
	db.timezone = UTC
	delete.enabled = true
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:347)
[2020-07-29 21:35:34,109] INFO Initializing writer using SQL dialect: SqliteDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:57)
[2020-07-29 21:35:34,110] INFO WorkerSinkTask{id=jdbc-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:306)
[2020-07-29 21:35:34,124] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:35:34,125] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Discovered group coordinator daniel:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:797)
[2020-07-29 21:35:34,127] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:35:34,137] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
[2020-07-29 21:35:34,138] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:552)
[2020-07-29 21:35:34,143] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Finished assignment for group at generation 9: {connector-consumer-jdbc-sink-0-3097c18d-b094-4a3b-b337-6a1b26d59c5b=Assignment(partitions=[users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2020-07-29 21:35:34,146] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Successfully joined group with generation 9 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:503)
[2020-07-29 21:35:34,151] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Adding newly assigned partitions: users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:273)
[2020-07-29 21:35:34,163] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Setting offset for partition users-0 to the committed offset FetchPosition{offset=56, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[daniel:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:792)
[2020-07-29 21:35:34,198] ERROR WorkerSinkTask{id=jdbc-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:186)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:178)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:104)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:492)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:469)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:325)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:228)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:196)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:184)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:234)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.connect.errors.DataException: JsonConverter with schemas.enable requires "schema" and "payload" fields and may not contain additional fields. If you are trying to deserialize plain JSON data, set schemas.enable=false in your converter configuration.
	at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:359)
	at org.apache.kafka.connect.storage.Converter.toConnectData(Converter.java:87)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.lambda$convertAndTransformRecord$2(WorkerSinkTask.java:492)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry(RetryWithToleranceOperator.java:128)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndHandleError(RetryWithToleranceOperator.java:162)
	... 13 more
[2020-07-29 21:35:34,200] ERROR WorkerSinkTask{id=jdbc-sink-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:187)
[2020-07-29 21:35:34,200] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:107)
[2020-07-29 21:35:34,201] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Revoke previously assigned partitions users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:292)
[2020-07-29 21:35:34,201] INFO [Consumer clientId=connector-consumer-jdbc-sink-0, groupId=connect-jdbc-sink] Member connector-consumer-jdbc-sink-0-3097c18d-b094-4a3b-b337-6a1b26d59c5b sending LeaveGroup request to coordinator daniel:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:979)
[2020-07-29 21:35:44,043] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:44,043] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:44,051] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 8 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:35:54,052] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:35:54,052] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:35:54,054] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:04,054] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:04,055] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:04,056] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:14,056] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:14,057] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:14,058] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:24,058] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:24,059] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:24,060] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:34,060] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:34,060] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:34,062] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:44,062] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:44,062] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:44,064] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:36:54,064] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:36:54,064] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:36:54,066] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:04,067] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:04,067] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:04,069] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:14,070] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:14,071] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:14,072] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:24,072] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:24,072] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:24,073] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:34,073] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:34,074] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:34,075] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:44,075] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:44,075] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:44,077] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:37:54,077] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:37:54,077] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:37:54,079] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:04,079] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:38:04,079] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:38:04,080] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:14,080] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:38:14,081] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:38:14,083] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:24,083] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:38:24,084] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:38:24,085] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:34,086] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:38:34,086] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:38:34,087] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:43,751] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2020-07-29 21:38:43,751] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-07-29 21:38:43,757] INFO Stopped http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:380)
[2020-07-29 21:38:43,758] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-07-29 21:38:43,758] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-07-29 21:38:43,758] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:100)
[2020-07-29 21:38:43,759] INFO Stopping task jdbc-sink-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:38:43,760] INFO Stopping connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:38:43,760] INFO Stopped connector jdbc-sink (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:38:43,760] INFO Stopping task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-07-29 21:38:43,760] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:313)
[2020-07-29 21:38:43,794] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:320)
[2020-07-29 21:38:43,794] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:38:43,794] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:38:43,795] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:38:43,796] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:38:43,796] INFO [Producer clientId=connector-producer-jdbc-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1182)
[2020-07-29 21:38:43,798] INFO Stopping connector jdbc-source (org.apache.kafka.connect.runtime.Worker:358)
[2020-07-29 21:38:43,799] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:174)
[2020-07-29 21:38:43,799] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:134)
[2020-07-29 21:38:43,799] INFO Closing connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:118)
[2020-07-29 21:38:43,799] INFO Stopped connector jdbc-source (org.apache.kafka.connect.runtime.Worker:374)
[2020-07-29 21:38:43,800] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-07-29 21:38:43,800] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2020-07-29 21:38:43,801] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-07-29 21:38:43,801] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:117)
[2020-07-29 21:38:43,801] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2020-07-29 21:39:05,632] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2020-07-29 21:39:05,638] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_241, 25.241-b07
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.5.0.jar:bin/../libs/connect-basic-auth-extension-2.5.0.jar:bin/../libs/connect-file-2.5.0.jar:bin/../libs/connect-json-2.5.0.jar:bin/../libs/connect-mirror-2.5.0.jar:bin/../libs/connect-mirror-client-2.5.0.jar:bin/../libs/connect-runtime-2.5.0.jar:bin/../libs/connect-transforms-2.5.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.2.jar:bin/../libs/jackson-core-2.10.2.jar:bin/../libs/jackson-databind-2.10.2.jar:bin/../libs/jackson-dataformat-csv-2.10.2.jar:bin/../libs/jackson-datatype-jdk8-2.10.2.jar:bin/../libs/jackson-jaxrs-base-2.10.2.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:bin/../libs/jackson-module-paranamer-2.10.2.jar:bin/../libs/jackson-module-scala_2.12-2.10.2.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javassist-3.26.0-GA.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.24.v20191120.jar:bin/../libs/jetty-continuation-9.4.24.v20191120.jar:bin/../libs/jetty-http-9.4.24.v20191120.jar:bin/../libs/jetty-io-9.4.24.v20191120.jar:bin/../libs/jetty-security-9.4.24.v20191120.jar:bin/../libs/jetty-server-9.4.24.v20191120.jar:bin/../libs/jetty-servlet-9.4.24.v20191120.jar:bin/../libs/jetty-servlets-9.4.24.v20191120.jar:bin/../libs/jetty-util-9.4.24.v20191120.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.5.0.jar:bin/../libs/kafka_2.12-2.5.0-sources.jar:bin/../libs/kafka-clients-2.5.0.jar:bin/../libs/kafka-log4j-appender-2.5.0.jar:bin/../libs/kafka-streams-2.5.0.jar:bin/../libs/kafka-streams-examples-2.5.0.jar:bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:bin/../libs/kafka-streams-test-utils-2.5.0.jar:bin/../libs/kafka-tools-2.5.0.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.7.1.jar:bin/../libs/maven-artifact-3.6.3.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.1.jar:bin/../libs/reflections-0.9.12.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.3.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.30.jar:bin/../libs/slf4j-log4j12-1.7.30.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.4-7.jar
	os.spec = Linux, amd64, 5.4.0-42-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-07-29 21:39:05,643] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2020-07-29 21:39:05,664] INFO Loading plugin from: /home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:39:05,964] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/mongodb-kafka-connect-mongodb-1.2.0/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:39:05,965] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:05,965] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:05,965] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:05,965] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:05,966] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:05,966] INFO Loading plugin from: /home/daniel/plugins/avroconverter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:39:06,191] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/avroconverter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:39:06,192] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:06,192] INFO Loading plugin from: /home/daniel/plugins/jdbcconnector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:239)
[2020-07-29 21:39:06,326] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/daniel/plugins/jdbcconnector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:39:06,326] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:06,328] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,211] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:262)
[2020-07-29 21:39:07,211] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,211] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,211] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,211] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,212] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,213] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,214] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,215] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,216] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,217] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,217] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,217] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,217] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,217] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:191)
[2020-07-29 21:39:07,218] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,218] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,219] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,219] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,219] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,219] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,219] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,220] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,221] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,222] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,223] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,223] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,223] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:39:07,223] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,223] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:39:07,224] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:39:07,224] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:39:07,224] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:416)
[2020-07-29 21:39:07,224] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,224] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,225] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:419)
[2020-07-29 21:39:07,237] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [/home/daniel/plugins]
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.client.auth = none
	task.shutdown.graceful.timeout.ms = 5000
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:347)
[2020-07-29 21:39:07,238] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-07-29 21:39:07,241] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-07-29 21:39:07,294] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,294] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-07-29 21:39:07,295] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:39:07,295] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:39:07,295] INFO Kafka startTimeMs: 1596055147295 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:39:07,570] INFO Kafka cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-07-29 21:39:07,588] INFO Logging initialized @2256ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-07-29 21:39:07,648] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-07-29 21:39:07,648] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-07-29 21:39:07,658] INFO jetty-9.4.24.v20191120; built: 2019-11-20T21:37:49.771Z; git: 363d5f2df3a8a28de40604320230664b9c793c16; jvm 1.8.0_241-b07 (org.eclipse.jetty.server.Server:359)
[2020-07-29 21:39:07,687] INFO Started http_8083@138fe6ec{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:330)
[2020-07-29 21:39:07,688] INFO Started @2357ms (org.eclipse.jetty.server.Server:399)
[2020-07-29 21:39:07,708] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:39:07,708] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-07-29 21:39:07,709] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:39:07,709] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-07-29 21:39:07,709] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-07-29 21:39:07,710] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-07-29 21:39:07,720] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:39:07,721] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:39:07,721] INFO Kafka startTimeMs: 1596055147720 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:39:07,838] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:39:07,839] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:39:07,845] INFO Kafka Connect standalone worker initialization took 2211ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2020-07-29 21:39:07,845] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2020-07-29 21:39:07,846] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:93)
[2020-07-29 21:39:07,846] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-07-29 21:39:07,847] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2020-07-29 21:39:07,853] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-07-29 21:39:07,853] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:95)
[2020-07-29 21:39:07,853] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-07-29 21:39:07,897] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-07-29 21:39:07,985] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-07-29 21:39:07,985] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-07-29 21:39:07,987] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-07-29 21:39:08,562] INFO Started o.e.j.s.ServletContextHandler@4351171a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:825)
[2020-07-29 21:39:08,563] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-07-29 21:39:08,563] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2020-07-29 21:39:08,582] INFO AbstractConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:39:08,676] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:347)
[2020-07-29 21:39:08,681] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:39:08,682] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:39:08,683] INFO Creating connector jdbc-source of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-07-29 21:39:08,685] INFO Instantiated connector jdbc-source with version 5.5.1 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-07-29 21:39:08,686] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:69)
[2020-07-29 21:39:08,686] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:347)
[2020-07-29 21:39:08,687] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:39:08,689] INFO Starting thread to monitor tables. (io.confluent.connect.jdbc.source.TableMonitorThread:73)
[2020-07-29 21:39:08,690] INFO Finished creating connector jdbc-source (org.apache.kafka.connect.runtime.Worker:273)
[2020-07-29 21:39:08,691] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-07-29 21:39:08,692] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:39:08,696] INFO Creating task jdbc-source-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-07-29 21:39:08,698] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-07-29 21:39:08,699] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = jdbc-source
	tasks.max = 1
	transforms = [createKey, extractInt]
	transforms.createKey.fields = [id]
	transforms.createKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.extractInt.field = id
	transforms.extractInt.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-07-29 21:39:08,700] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-07-29 21:39:08,701] INFO Instantiated task jdbc-source-0 with version 5.5.1 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-07-29 21:39:08,702] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:347)
[2020-07-29 21:39:08,703] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-07-29 21:39:08,703] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-07-29 21:39:08,703] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-07-29 21:39:08,703] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task jdbc-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-07-29 21:39:08,707] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ValueToKey, org.apache.kafka.connect.transforms.ExtractField$Key} (org.apache.kafka.connect.runtime.Worker:514)
[2020-07-29 21:39:08,713] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-jdbc-source-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-07-29 21:39:08,734] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-07-29 21:39:08,734] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-07-29 21:39:08,734] INFO Kafka startTimeMs: 1596055148734 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-07-29 21:39:08,741] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:81)
[2020-07-29 21:39:08,741] INFO Created connector jdbc-source (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2020-07-29 21:39:08,741] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlite:/home/daniel/master-thesis/usmanager/manager/manager-master/manager-master
	connection.user = sa
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = ["users"]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 500
	timestamp.initial = null
	topic.prefix = 
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:347)
[2020-07-29 21:39:08,742] INFO Using JDBC dialect Sqlite (io.confluent.connect.jdbc.source.JdbcSourceTask:98)
[2020-07-29 21:39:08,743] INFO [Producer clientId=connector-producer-jdbc-source-0] Cluster ID: BhLEO5jJQD6ABY_BGQH6Jg (org.apache.kafka.clients.Metadata:280)
[2020-07-29 21:39:08,743] INFO Attempting to open connection #1 to Sqlite (io.confluent.connect.jdbc.util.CachedConnectionProvider:92)
[2020-07-29 21:39:08,750] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:257)
[2020-07-29 21:39:08,751] INFO WorkerSourceTask{id=jdbc-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:214)
[2020-07-29 21:39:08,751] INFO Begin using SQL query: SELECT * FROM "users" (io.confluent.connect.jdbc.source.TableQuerier:164)
[2020-07-29 21:39:18,741] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:39:18,742] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:39:18,749] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 8 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:39:28,750] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:39:28,750] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:39:28,752] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:39:38,752] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:39:38,753] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:39:38,754] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:39:48,755] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:39:48,755] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:39:48,756] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:39:58,757] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:39:58,757] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:39:58,758] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:08,759] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:08,759] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:08,761] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:18,761] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:18,762] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:18,763] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:28,765] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:28,765] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:28,767] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:38,767] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:38,768] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:38,769] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:48,769] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:48,770] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:48,772] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)
[2020-07-29 21:40:58,773] INFO WorkerSourceTask{id=jdbc-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:424)
[2020-07-29 21:40:58,773] INFO WorkerSourceTask{id=jdbc-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:441)
[2020-07-29 21:40:58,775] INFO WorkerSourceTask{id=jdbc-source-0} Finished commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask:523)

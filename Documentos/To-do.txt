---------- casos de estudo ----------
procurar microserviços (e.g. na área da saúde, agricultura, streaming, gaming, etc), que beneficiem de local managers:
1. face recognition surveillance cameras (1910.07660)
2. Augmented reality (needs low latency), Insulin pump, Mental health care (1908.01153)
3. Mixal app (p25-jindal)
weather forecasting and traffic monitoring, medical,
transportation, and communication fields (6421607)
- smart city (license plate reader on edge, database/registry lookup to validate the license plate) (record Traffic congestion on edge, analise patterns/etc on cloud)

---------- arquitetura ----------

associar Service Level Objectives aos serviços. ter em consideração esses SLOs ao migrar/replicar serviços
((1) requests success rate being higher than
the threshold and (2) the response time for 90% of requests being
lower than the threshold.
Requests success rate (RSR) is a ratio of the user requests
successfully completed within a given time to the overall number
of the requests submitted by the users within the same time.
90%tile response time (P90RT) is such a value of the response
time for a time intervalT that 90% of the requests that arrived during
interval T received the response in the given time. P90RT is used
throughout the paper because the behavior of the tail latency can
significantly differ from the mean response time which can result
in sub-optimal resource allocation and degraded performance.)

considerar latency, energy, communication cost and financial cost como resource otimization (GDWXT6-08031490)
considerar For example, Fan et al. [29] consider the cost of VM migration (GDWXT6-08031490)

usar coordenadas para encontrar o melhor edge host disponivel

Adicionar um algoritmo de performance modeling ao adicionar um novo microserviço ao sistema

cada local manager controla 1 swarm e comunica com o master manager atrvés de kafka, ou é um swarm node manager e tem um estado distribuido por todos os managers

pedir por mais informação ao registar um edge node (cpu clock, storage size, network capacity, mac address, ip address)

usar 'public_ip/private_ip' como chave de um edge node

usar o docker swarm service, usando constraints para controlar o local de deployment
https://success.docker.com/article/using-contraints-and-labels-to-control-the-placement-of-containers
resolve o problema do service discovery, usando o dns incorporado no docker swarm

ver se é possivel e se se justifica ter mais do que 1 nó por máquina

usar microservice capacity no algoritmo de gestão? (p25-jindal - To characterize the behavior of a microservice application which is appropriate for the user, we define a MicroService Capacity (MSC) as a maximal rate of requests that can be served without violating SLO)
pode não ser muito útil visto que o msc calculado apenas funciona para uma tipo de máquina (e.g. 2gb ram, 10mb/s bandwidth, etc)

colocar uma flag nos serviços para diferenciar entre serviços cloud e serviços edge. e.g. serviços cloud usam demasiados recursos e não necessitam de estar proximos dos utilizadores.
1 aplicação pode ser composta por serviços cloud e serviços edge

Justificação para uma web ui elaborada: juntar todas as configurações/ações manuais num único website, de forma a ter um local único e uniforme para controlar o sistema de gestão, monitorização e base de dados.

sistemas adaptativos:
(1910.07660)
A typical self-adaptation
control loop consists of four main activities, namely Mon-
itor, Analyze, Plan, and Execute, all sharing a common
Knowledge base, usually referred to as the MAPE-K refer-
ence model [1]. (J. O. Kephart and D. M. Chess, “The vision of autonomic computing,” Computer, vol. 36, no. 1, pp. 41–50, 2003.)
Control loops can be designed and deployed
according to different control strategies, from a single cen-
tralized control component managing the whole system, to
multiple control components managing different parts of the
system and organized in a hierarchical or fully decentralized
manner [2]. (D. Weyns, Software Engineering of Self-Adaptive Systems: An Organised Tour and Future Challenges. Springer, 2017)
For instance, control loops for each of
the video surveillance application services could be de-
ployed in a fully decentralized fashion, which would in-
crease their overall reliability and scalability. However, this strategy would also make it harder to enforce application-
wide adaptation constraints, as this would require each
control loop to coordinate its actions with the other control
loops, thus reducing their decision autonomy. Similarly,
deploying control loops at the infrastructure level would
help to promote a better separation between business and
management services at run time, thus facilitating their
reuse. However, this would also make them much harder
to customize for specific adaptation needs, e.g., managing
the expected accuracy of ML services, as most control loops
provided at the infrastructure level support only a restricted
set of adaptation models and mechanisms
 
usar a informação anterior para desenvolver control loops distribuidos?


usar as seguintes metricas de containers (1-s2.0-S016412121730256X-main, 
According to the literature ( Stankovski et al., 2016; Preeth et al.,
2015; Beserra et al., 2016; Vangeepuram, 2016; Dusia et al., 2015): 
rx_bytes
rx_packets
tx_bytes
tx_packets
cpu_usage
memory_usage
io_service_bytes_read
io_service_bytes_write

quando se escolhe o host: considerar bandwidth, latency, and energy constraints

migrar os containers, em vez de ser apenas iniciar o container com a mesma imagem, e parar o anterior

ver a utilidade do Docker Universal Control Plane (DUCP): is a tool to manage, de-
ploy, configure and monitor distributed applications built using
Docker containers

algoritmos de gestão:
- ver se calculos/formulas para determinar os valores necessários à realização da distribuição de workload em -s2.0-S0167739X18331868-main são uteis

usar metricas do nivel aplicacional (response time, application throughput, and for video streaming - frames per second, dropped frames and video quality) e justificar com o seguinte:
"importância do uso de metricas a nivel da aplicação:
The authors claim that monitoring only
infrastructure-level metrics such as memory and bandwidth with-
out taking into account how application performance is behaving
(application-level monitoring) at runtime would complicate the re-
source provisioning problem due to the lack of detailed measure-
ment (Rao et al. (2011))", de 1-s2.0-S016412121730256X-main

APPLICATION CASE STUDIES (from 1908.01153):
Augmented reality, Insulin pump, Mental health care

incluir no trabalho relacionado:
- Stankovski et al. (2016) proposed a distributed self-adaptive ar-
chitecture that applies the edge computing concept with container-
based technologies such as Docker and Kubernetes to ensure the
QoS for time-critical applications
- MAPO: A Multi-Objective Model for IoT Application Placement in a Fog Environment. we apply a
genetic multi-objective optimization algorithm that considers
three conflicting criteria (i.e., completion time, energy con-
sumption and economic cost) to approximate the Pareto set of
optimized placements of the application components on the
available Fog devices. On top of it, we implement a decision
making strategy for selecting a single placement solution from
the Pareto set based on the applications requirements. (1908.01153)
- dynamic resource allocation method, named DRAM, for load balancing in fog environment (6421607)


incluir como referencias de vms vs containers (em -s2.0-S0167739X18331868-main) - Preeth et al. (2015), Beserra et al. (2016), Vangeepuram (2016)


Service Mesh: Challenges, State of the Art, and Future Research Opportunities
sose2019.pdf

- ver se o jenkins pode ser util
- ver a possibilidade de usar as funcionalides do service mesh para detetar/construir o gráfo de dependencias entre microserviços
- [15] N. C. Mendonça, D. Garlan, B. Schmerl, and J. Cámara, “Generality
vs. Reusability in Architecture-based Self-adaptation: The Case for Self-
adaptive Microservices,” in Proceedings of the 12th European Confer-
ence on Software Architecture: Companion Proceedings, ser. ECSA ’18.
ACM, 2018, pp. 18:1–18:6.
[16] H.-L. Truong, L. Gao, and M. Hammerer, “Service Architectures and
Dynamic Solutions for Interoperability of IoT, Network Functions and
Cloud Resources,” in Proceedings of the 12th European Conference on
Software Architecture: Companion Proceedings. ACM, 2018, p. 2.
[17] A. Khan, “Key Characteristics of a Container Orchestration Platform
to Enable a Modern Application,” IEEE Cloud Computing, no. 5, pp.
42–48, 2017.
[18] S. Esparrachiari, T. Reilly, and A. Rentz, “Tracking and Controlling
Microservice Dependencies,” Queue, ACM, vol. 16, no. 4, p. 10, 2018.
[Online]. Available: https://queue.acm.org/detail.cfm?id=3277541


---------- register-go ---------
alterar algoritmo de escolha de replicas para ser baseado em geolocalização (eurekaops/util)

---------- web-manager ---------- 
loadbalancer 502 bad gateway
new container erroring
launch load balancer at aws not working

---------- master-manager ---------- 
rename all manager exceptions to MasterManagerException, when applied
add assertEntityDoesntExist on every add method and compare every query 'name' with lower function
NodesController return new SimpleNodes
choose node based on geocoding https://developers.google.com/maps/documentation/geocoding/start?csw=1

master manager tem a capacidade de gerir local managers, mas não os containers/nós geridos individualmente por cada local manager. local manager apenas gere um conjunto de edge machines, e nunca cloud

---------- docker ---------- 
fix master-manager dockerfile

manager:
ufw allow 22/tcp
ufw allow 2376/tcp
ufw allow 2377/tcp
ufw allow 7946/tcp
ufw allow 7946/udp
ufw allow 4789/udp
ufw allow http
ufw allow https
ufw reload
ufw enable
systemctl restart docker

workers:
ufw allow 22/tcp
ufw allow 2376/tcp
ufw allow 7946/tcp 
ufw allow 7946/udp 
ufw allow 4789/udp 
ufw reload
ufw enable
systemctl restart docker

TCP port 2377 for cluster management communications
TCP and UDP port 7946 for communication among nodes
UDP port 4789 for overlay network traffic

---------- test ---------- 
reload every single page with empty state
try to delete/update/insert entities after saving

- Cloud-only placement - All microservices of the application
are placed within Cloud layer.
- Edge-ward placement proposed in [9] - In this algorithm
horizontal placement of the microservices across Fog node clusters is not considered. If a microservice placed on a cer-
tain Fog device does not have enough resources to handle
the load, that microservice gets moved up the Fog hierarchy
until a device that can handle the load is met. (ucc19)

- Incluir vários tipos de máquinas (e.g. 1 vcpu/1gb ram, 2 vcpu/2gb ram, 4 vcpu/4gb ram, 4 vcpu/8gb ram)

---------- local managers ----------

Moreover, in centralized management all requests are sent to-
wards a central scheduler node. Thus, as the number of sensors
increases, the number of placement requests that needs to be pro-
cessed by the centralized scheduler is higher than that of each Fog
node in decentralized case (ucc19)

são colocados em servidores/cloudlets/etc entre a edge e a cloud, ao que se normalmente dá o nome de fog.

(1910.07660)
From a control loop deployment perspective, as discussed
in the context of challenges C5 and C6, a microservice
system’s control components should ideally be deployed in
a fully decentralized fashion, with each microservice being
managed by its own local controller. However, this solution
would make it harder for the local controllers to monitor
and manage application-wide quality attributes. Having a
centralized controller dedicated to managing application-
level quality concerns would be a more straightforward
solution in that regard, but this would also have the down-
side of creating a single point of failure and ultimately
could compromise the application’s overall availability. In
practice, microservice developers may choose from a variety
of intermediate solutions between those two extremes, e.g.,
by logically grouping services according to their business
and/or quality affinity, and then having those services be-
ing collectively managed by independent yet application-
aware group controllers organized in a hierarchical or fully
decentralized structure.

mape-k distribuido

Beneficios de existirem local managers:

1. Os dados sao transferidos por uma distancia menor, reduzindo o nº total de bytes transferidos na rede. O local manager tem a capacidade de filtrar os dados, e apenas enviar para o master manager o que achar relevante para a gestão global do sistema.

2. A proximidade dos local managers aos microserviços que gere, implica um tempo de resposta menor, e consequente adaptação mais rápida, às alterações detetadas. 

3. Flexibilidade em caso de falha de um local manager, com a possiblidade de ser atribuido outro local manager, na proximidade, aos containers e máquinas geridos pelo primeiro.

4. Federação de máquinas e privacidade. Cada local manager pode controlar um certo conjunto de máquinas que, por razões de segurança, ou outras, não são diretamente controláveis pelo master-manager. Por exemplo, um local-manager na FCT controlaria os containers e nós nos computadores da fct, não estando estes diretamente acessiveis ao master-manager na cloud.

5. Os local-managers podem ter a capacidade para funcionar apenas na edge, não sendo obrigatório enviarem e receberem instruções do master-manager, garantindo uma orquestração localizada e leve de nós e containers.

6. Maior escabilidade. Ao adicionar mais local-managers ao sistema, é possivel gerir um número maior de máquinas e containers. Assim, o sistema não é totalmente dependente do master-manager. Embora para ser feita a orquestração global (e.g. migração de containers), seja necessaria a intervenção de um master-manager.

Desavantagens:

1. Maior complexidade da arquitetura

2. Necessidade de comunicação entre os local managers e o master manager, com a introdução do rabbitmq para servir de message broker entre os componentes.

3. Mais recursos usados na edge, com a inclusão dos containers local-manager e rabbitmq.

https://imgur.com/a/U8otupj


---------- documento ---------- 

1. docker swarm 
https://docs.docker.com/engine/swarm/
https://docs.docker.com/engine/swarm/admin_guide/
https://docs.docker.com/engine/swarm/key-concepts/
1. ver porque docker e kubernets scheduling não resolve o nosso problema
https://blog.scottlogic.com/2016/06/17/docker-swarm.html (não usar esta referencia, procurar uma oficial mas semelhante)
2. o docker swarm contem um service discovery, mas apenas se for usado o 'docker service' para iniciar e gerir containers, (funciona através da configuração de uma overlay network). o que implica o uso do docker swarm scheduling, que não é util para o nosso caso

3. kubernetes vs docker swarm
lightweight kubernetes - https://k3s.io/

4. razões para usar o docker swarm service:
 - dns (service discovery) integrado
 - fail recovery
 - image updates

descrição de self-adaptive system: "A self-adaptive system can dynamically monitor and adapt its behavior to preserve or enhance its quality attributes under
uncertain operating conditions" (1910.07660)

em 2006.00876 um dos algoritmos vistos (referencia 17), diz que o a politica onde era usada a menor latencia para atribuir o workload, foi a mais eficaz. Referir isso para explicar o uso de um sistema que tenta colocar os serviços o mais próximo possível dos utilizadores 

B. Varghese and R. Buyya, “Next Generation Cloud Computing:
New Trends and Research Directions,” Future Generation Computer
Systems, vol. 79, pp. 849 – 861, 2018. como referência para o aumento do nº de dispositivos iot

ver algoritmos da imagem 2 em 1810.00305, nomeadamente load-balancing, placement


container engines: LXC linuxcontainers.org, Docker www.docker.com, rkt coreos.com/rkt

service discovery: ZooKeeper zookeeper.apache.org, Eureka github.com/Netflix/eureka, etcd coreos.com/etcd, Synapse github.com/airbnb/synapse, Consul www.consul.io

Container orchestration: Mesos mesos.apache.org, Kubernetes kubernetes.io, Docker Swarm docs.docker.com/engine/swarm , Amazon Elastic Container Service aws.amazon.com/ecs, Nomad www.nomadproject.io

Sidecar: SmartStack nerds.airbnb.com/smartstack-service-discovery-cloud, Prana github.com/Netflix/Prana, Envoy www.envoyproxy.io

Service mesh:  Linkerd linkerd.io, Istio istio.io, Conduit conduit.io

research:
referir os 3 tipos de monitorização (host, container, app) referidos em 1-s2.0-S016412121730256X-main
referir os desafios na monitorização na edge:
1. mobility management
2. scalability and resource availability at the edge
3. prior knowledge
4. data management
5. coorindated decentralization
6. saving expense, time and energy
7. interoperability and avoiding vendor lock-in
8. optimal resource scheduling among edge nodes
9. fault tolerance
10. proactive computing
11. replication of services
12. container security
13. non specific edge nodes
para ajudar a explicar as metricas usadas na gestão de nós e containers, e quais dos desafios este projeto está focado

referenciar "However, their native scaling approaches are princi-
pally based on CPU usage; no matter for example how workload
intensity or application performance is behaving" para explicar que mecanismos como o orquestrador do docker swarm não têm em consideração a maior parte das métricas (apenas cpu) (1-s2.0-S016412121730256X-main)

na parte do kubernetes vs docker swarm:
- mudança para kubernetes poderia colocar em causa a compatibilidade com os componentes desenvolvidos nas outras dissertações de mestrado (base de dados/monitorização)

ver se "created elaborate scenarios based on a simulated fog environment (https://github.com/vindem/sleipnir)" pode ser util para simular os testes

incluir p25-jindal Performance Modeling for Cloud Microservice Applications como potencial forma de melhorar os algoritmos de gestão

na parte do self adaptivity:

boa explicação em 1912.05058, secção 2.2

referenciar e explicar o uso do algoritmo MAPE-K loop (1912.058058) (N. M. Villegas, H. A. Muller, G. Tamura, L. Duchien, R. Casallas, A
framework for evaluating quality-driven self-adaptive software systems, in:
Proceedings of 6th International Symposium on Software Engineering for
Adaptive and Self-Managing Systems (SEAMS), 2011, pp. 80–89.)

- pro-active adaptations or MAPE-K adaptation process (1912.058058)

trabalho futuro:
para além da gestão de nos/serviços, o sistema poderia incluir algoritmos para fazer distribuição de carga entre nṍs edge/cloud, sendo portanto parcialmente peer-to-peer



Substituir o Service Discovery eureka pelo pilot do istio, e o componente de descoberta de serviços pelos envoy proxy do istio. 
Usar a capacidade de load balancer do pilot+envoy para substituir o nginx load balancer?
Substituir o prometheus pelo mixer, se o tipo de métricas for o mesmo?

Ter os componentes core do istio a executar na cloud

Vantagem de usar o service mesh:
Para além das configurações ao service mesh, aplicadas pelo sistema, os developers das aplicações podem aplicar as suas próprias configurações.


Nodes edge nodes com menos recursos podem executar apenas os containers com o microserviço + proxy envoy.


testes:
simuladores (CloudSim/SAd-CloudSim,SAw-CloudSim(1912.05058)/EdgeCloudSim/IotNetSim/iFogSim) ou physical testbeds (aws/gcloud/azure/grid5000/OpenNebula) para simulação de testes?
https://github.com/Cloudslab/cloudsim
https://github.com/m-salama/SAdSAwCloudSim (empty)
https://github.com/CagataySonmez/EdgeCloudSim
https://github.com/m-salama/IotNetSim (https://arxiv.org/abs/1911.03527)
https://github.com/Cloudslab/iFogSim
H. Gupta, A. V. Dastjerdi, S. K. Gosh, and R. Buyya. (2016,
June) iFogSim: A toolkit for modeling and simulation of resource
management techniques in internet of things, edge and fog computing
environments. [Online]. Available: https://arxiv.org/abs/1606.02007v1
https://www.grid5000.fr/
https://opennebula.io/

. perguntar pela dissertação que gere as bases de dados

Relevante:

usar o docker swarm service, https://docs.docker.com/engine/reference/commandline/service_create/, para lançar containers nos nós do swarm
usando a opção --constrains para controlar onde seriam iniciadas as replicas
porque o docker swarm já inclui um serviço dns para encontrar containers, o que podia substituir o eureka server
e também um routing mesh, https://docs.docker.com/engine/swarm/ingress, para, caso seja preciso, expor replicas ao exterior do swarm

Since microservices that
make up an application have data dependencies amongst them, an
IoT application is depicted as a Directed Acyclic Graph (DAG). each microservice is represented by vertices of the
DAG, whereas edges between vertices represent data dependencies
among microservices.

usar algoritmo demonstrado em ucc19 para lançar uma aplicação, e.g. sock shop

Improving_microservice-based_applications_with_run considera uma métrica (affinity) para relacionar os microserviços

stateful flag para serviços com estado (não devem migrar)

We define affinity between
two microservices using the number of messages and the
amount of data exchanged between them. We use a ratio
(weight) in the affinity calculation to steer the Analyzer
execution

Algoritmos comuns de placement (Improving_microservice-based_applications_with_run):
- Spread strategy. The management tool places a minimum number of microservices per host in the cluster
- Bin-pack strategy. The management tool uses the minimum number of hosts
- Labeled strategy. In addition to the resource requirements, microservices can be annotated with attributes used to guide host selection
- Random strategy. The management tool selects a host to deploy a microservice randomly

Começar com Spread strategy e depois passar para labeled (para influenciar onde são colocados os microserviços baseado nas métricas)

1. Incluir mais demos de aplicações compostas por microserviços (Mixal app (p25-jindal))

2. Em vez de standalone containers, usar o docker swarm service, recorrendo à opção --constraints para controlar onde são colocadas as réplicas. A vantagem é ter um dns incluido no swarm, sendo desnecessário o uso do eureka server. Outra vantagem é o failsafe que o docker swarm disponibiliza (e.g. se o container falhar, o docker lança automaticamente outra réplica para o substituir).

3. Usar local managers com algoritmo mape-k distríbuido. O nó do host onde está cada local manager é um nó manager (limitação de 7 ou 9 local managers). Para suportar mais, cada local manager tem que formar um swarm, contendo um conjunto de hosts associado a si (federação). Com a desvantagem de ser preciso transmitir o seu estado e as suas ações ao master manager (através de kafka?).

4. Em vez de ser usado o continente/região/pais/cidade, usar coordenadas, no algoritmo da escolha do nó.

5. incluir as seguintes métricas: bandwidth, latency, and
energy constraint

6. Incluir métricas do nível aplicacional (response time, application throughput, and for video streaming - frames per second, dropped frames and video quality)

7. Incluir as seguintes métricas do nível container:
- rx_bytes
- rx_packets
- tx_bytes
- tx_packets
- cpu_usage
- memory_usage
- io_service_bytes_read
- io_service_bytes_write

8. Usar uma flag nos serviços para diferenciar entre serviços cloud e serviços edge. Serviços cloud usam demasiados recursos e não necessitam de estar próximos dos utilizadores.
Uma aplicação pode ser composta tanto por serviços cloud, como por serviços edge.

9. Suportar migração de containers, incluindo copia do estado e volumes
https://stackoverflow.com/questions/28734086/how-to-move-docker-containers-between-different-hosts
https://stackoverflow.com/a/53068212

10. Ver se é possivel e se se justifica ter mais do que 1 nó por máquina.

11. Simular a energia usada (e custo associado) de uma máquina edge. Ter em conta este fator na altura de escolha do nó para onde migrar/replicar.

Múltiplas instâncias de um serviço. Funcionalidade para permitir a replica-
ção de várias instâncias do mesmo serviço, em locais diferentes simultanea-
mente;

a taxa de
ocupação da rede, a distribuição de carga, e o custo de utilização do dispositivo
físico

Dependências entre serviços e ações de gestão pro-ativas. Adaptar a inter-
face de gestão para permitir a definição das dependências entre serviços e
implementar as ações de gestão pro-ativas (rever p93-klinaku CAUS: An Elasticity Controller for a Containerized Microservice)

Antecipação de acontecimentos e ações de gestão adaptativas. Adaptação
com base em eventos pré-definidos. Incorporar a possibilidade de reconfigu-
ração dinâmica com base na definição de eventos pré-definidos que envolvam
um elevado volume de acessos, tendo em atenção o local e a data onde ocorrem;

Possível trabalho futuro:

12. Incluir um algoritmo de modelação de serviços para obter um modelo de como se comporta o microserviço quando lançado no sistema. Permite estimar o ram/cpu usado para um certo workload e especificação de máquina. (E, abordado em p25-jindal, MSC as a maximal rate of requests that can be served without violating SLO).
Um problema detetado é o tempo que a modelação pode demorar, mas como só é executado uma vez por cada tipo de workload e especificação de máquina, pode náo ser relevante. Outro problema está relacionado com a heterogeneidade das máquinas na edge, porque uma modelação só é correta para um certo tipo de máquina (e.g. 2gb ram, 3.5ghz cpu), e com o workload dinâmico na edge (i.e o nº de pedidos tanto pode ser muito baixo como muito alto).

13. Incluir um algoritmo de placement (e.g. 1908.01153) para, ao iniciar o sistema, distribuir os containers pelos hosts disponíveis. Um problema detetado é o facto de ser impossível distribuir os containers consoante o workload e origem dos pedidos. Mas ao longo do tempo, os serviços deverão, eventualmente, distribuir-se consoante essas métricas.






https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html

https://www.rabbitmq.com/tutorials/tutorial-one-go.html